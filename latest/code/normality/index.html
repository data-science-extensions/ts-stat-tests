
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A Python library for performing statistical tests on time series data.">
      
      
        <meta name="author" content="[Chris Mahoney](mailto:chris@mahoneyconsultingservices.com)">
      
      
      
        <link rel="prev" href="../regularity/">
      
      
      
        
      
      
      <link rel="icon" href="../../assets/icons/1205526.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Normality - Time Series Statistical Tests</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/style.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/admonitions.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/code_chunks.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/shortcodes.css">
    
      <link rel="stylesheet" href="https://site-assets.fontawesome.com/releases/v6.4.2/css/all.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#test-the-normality-of-a-given-time-series-dataset" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),base=new URL("../.."),outdated=__md_get("__outdated",sessionStorage,base);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Time Series Statistical Tests" class="md-header__button md-logo" aria-label="Time Series Statistical Tests" data-md-component="logo">
      
  <img src="../../assets/icons/1205526.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Time Series Statistical Tests
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Normality
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/data-science-extensions/ts-stat-tests" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </div>
  <div class="md-source__repository">
    ts-stat-tests
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../usage/overview/" class="md-tabs__link">
          
  
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Modules

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Time Series Statistical Tests" class="md-nav__button md-logo" aria-label="Time Series Statistical Tests" data-md-component="logo">
      
  <img src="../../assets/icons/1205526.svg" alt="logo">

    </a>
    Time Series Statistical Tests
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/data-science-extensions/ts-stat-tests" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </div>
  <div class="md-source__repository">
    ts-stat-tests
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Usage
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Usage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/changelog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Change Log
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Modules
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Modules
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../correlation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Correlation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regularity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Regularity
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Normality
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Normality
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normality-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Normality Tests
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normality Tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;normality
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â normality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;normality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.is_normal" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_normal
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normality-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Normality Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normality Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;normality
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â normality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;normality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.is_normal" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_normal
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;normality
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â normality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.jb" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;jb
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.ob" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ob
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.sw" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sw
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.dp" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;dp
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.ad" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ad
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normality-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Normality Tests
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normality Tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;normality
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â normality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;normality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.is_normal" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_normal
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normality-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Normality Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normality Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;normality
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â normality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;normality
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.normality.is_normal" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_normal
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;normality
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â normality">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.jb" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;jb
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.ob" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ob
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.sw" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sw
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.dp" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;dp
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.normality.ad" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;ad
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/data-science-extensions/ts-stat-tests/edit/main/docs/code/normality.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/data-science-extensions/ts-stat-tests/raw/main/docs/code/normality.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="test-the-normality-of-a-given-time-series-dataset">Test the <code>normality</code> of a given Time-Series Dataset<a class="headerlink" href="#test-the-normality-of-a-given-time-series-dataset" title="Permanent link">ðŸ”—</a></h1>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">ðŸ”—</a></h2>
<div class="admonition abstract">
<p class="admonition-title">Summary</p>
<div class="admonition quote">
<p class="admonition-title">As stated by the <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35.htm">NIST/SEMATECH e-Handbook of Statistical Methods</a>:</p>
<p>Normal distributions are important in statistics and are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known. Their importance is partly due to the central limit theorem.</p>
<hr />
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 15V9h8V4.16L19.84 12 12 19.84V15z"/></svg></span> For more info, see: <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm">Engineering Statistics Handbook: Measures of Skewness and Kurtosis</a>.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>The normality test is used to determine whether a data set is well-modeled by a normal distribution. In time series forecasting, we primarily test the residuals (errors) of a model for normality. If the residuals follow a normal distribution, it suggests that the model has successfully captured the systematic patterns in the data, and the remaining errors are random white noise.</p>
<p>If the residuals are not normally distributed, it may indicate that the model is missing important features, such as seasonal patterns or long-term trends, or that a transformation of the data (e.g., Log or Box-Cox) is required before modeling.</p>
<hr />
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 15V9h8V4.16L19.84 12 12 19.84V15z"/></svg></span> For more info, see: <a href="https://otexts.com/fpp3/residuals.html">Hyndman &amp; Athanasopoulos: Forecasting: Principles and Practice</a>.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Source Library</p>
<p>The <a href="https://scipy.org/"><code>scipy</code></a> and <a href="https://www.statsmodels.org/"><code>statsmodels</code></a> packages were chosen because they provide standard, reliable implementations of classical statistical tests. <code>scipy.stats</code> provides implementations for Shapiro-Wilk, D'Agostino-Pearson, and Anderson-Darling tests, while <code>statsmodels</code> provides the Jarque-Bera and Omnibus tests.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Source Module</p>
<p>All of the source code can be found within these modules:</p>
<ul>
<li><a href="https://github.com/data-science-extensions/ts-stat-tests/blob/main/src/ts_stat_tests/algorithms/normality.py"><code>ts_stat_tests.algorithms.normality</code></a>.</li>
<li><a href="https://github.com/data-science-extensions/ts-stat-tests/blob/main/src/ts_stat_tests/tests/normality.py"><code>ts_stat_tests.tests.normality</code></a>.</li>
</ul>
</div>
</div>
<h2 id="normality-tests">Normality Tests<a class="headerlink" href="#normality-tests" title="Permanent link">ðŸ”—</a></h2>


<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.tests.normality" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.tests.normality</span>


<a href="#ts_stat_tests.tests.normality" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains convenience functions and tests for normality measures, allowing for easy access to different normality algorithms.</p>
</div>










  <div class="doc doc-children">



























































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.normality.normality" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">normality</span>


<a href="#ts_stat_tests.tests.normality.normality" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">normality</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Perform a normality test on the given data.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is a convenience wrapper around the five underlying algorithms:<br>
- <a class="autorefs autorefs-internal" title="            jb" href="#ts_stat_tests.algorithms.normality.jb"><code>jb()</code></a><br>
- <a class="autorefs autorefs-internal" title="            ob" href="#ts_stat_tests.algorithms.normality.ob"><code>ob()</code></a><br>
- <a class="autorefs autorefs-internal" title="            sw" href="#ts_stat_tests.algorithms.normality.sw"><code>sw()</code></a><br>
- <a class="autorefs autorefs-internal" title="            dp" href="#ts_stat_tests.algorithms.normality.dp"><code>dp()</code></a><br>
- <a class="autorefs autorefs-internal" title="            ad" href="#ts_stat_tests.algorithms.normality.ad"><code>ad()</code></a></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which normality algorithm to use.<br>
- <code>jb()</code>: <code>["jb", "jarque", "jarque-bera"]</code><br>
- <code>ob()</code>: <code>["ob", "omni", "omnibus"]</code><br>
- <code>sw()</code>: <code>["sw", "shapiro", "shapiro-wilk"]</code><br>
- <code>dp()</code>: <code>["dp", "dagostino", "dagostino-pearson"]</code><br>
- <code>ad()</code>: <code>["ad", "anderson", "anderson-darling"]</code><br>
Defaults to <code>"dp"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;dp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis along which to compute the test. Default is <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_policy</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_DP_NAN_POLICY_OPTIONS">VALID_DP_NAN_POLICY_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Defines how to handle when input contains <code>NaN</code>.<br>
- <code>propagate</code>: returns <code>NaN</code><br>
- <code>raise</code>: throws an error<br>
- <code>omit</code>: performs the calculations ignoring <code>NaN</code> values<br>
Defaults to <code>"propagate"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;propagate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dist</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_AD_DIST_OPTIONS">VALID_AD_DIST_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of distribution to test against.<br>
Only relevant when <code>algorithm=anderson</code>.<br>
Defaults to <code>"norm"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;norm&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>When the given value for <code>algorithm</code> is not valid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result of the normality test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>Calculations are performed by <code>scipy.stats</code> and <code>statsmodels.stats</code>.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>normality</code> with <code>dagostino-pearson</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.normality</span><span class="w"> </span><span class="kn">import</span> <span class="n">normality</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">normality</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;dp&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></p>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">normality</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Perform a normality test on the given data.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function is a convenience wrapper around the five underlying algorithms:&lt;br&gt;</span>
<span class="sd">        - [`jb()`][ts_stat_tests.algorithms.normality.jb]&lt;br&gt;</span>
<span class="sd">        - [`ob()`][ts_stat_tests.algorithms.normality.ob]&lt;br&gt;</span>
<span class="sd">        - [`sw()`][ts_stat_tests.algorithms.normality.sw]&lt;br&gt;</span>
<span class="sd">        - [`dp()`][ts_stat_tests.algorithms.normality.dp]&lt;br&gt;</span>
<span class="sd">        - [`ad()`][ts_stat_tests.algorithms.normality.ad]</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str):</span>
<span class="sd">            Which normality algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `jb()`: `[&quot;jb&quot;, &quot;jarque&quot;, &quot;jarque-bera&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ob()`: `[&quot;ob&quot;, &quot;omni&quot;, &quot;omnibus&quot;]`&lt;br&gt;</span>
<span class="sd">            - `sw()`: `[&quot;sw&quot;, &quot;shapiro&quot;, &quot;shapiro-wilk&quot;]`&lt;br&gt;</span>
<span class="sd">            - `dp()`: `[&quot;dp&quot;, &quot;dagostino&quot;, &quot;dagostino-pearson&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ad()`: `[&quot;ad&quot;, &quot;anderson&quot;, &quot;anderson-darling&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;dp&quot;`.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis along which to compute the test. Default is `0`.</span>
<span class="sd">        nan_policy (VALID_DP_NAN_POLICY_OPTIONS):</span>
<span class="sd">            Defines how to handle when input contains `NaN`.&lt;br&gt;</span>
<span class="sd">            - `propagate`: returns `NaN`&lt;br&gt;</span>
<span class="sd">            - `raise`: throws an error&lt;br&gt;</span>
<span class="sd">            - `omit`: performs the calculations ignoring `NaN` values&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;propagate&quot;`.</span>
<span class="sd">        dist (VALID_AD_DIST_OPTIONS):</span>
<span class="sd">            The type of distribution to test against.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=anderson`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;norm&quot;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: When the given value for `algorithm` is not valid.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Any):</span>
<span class="sd">            The result of the normality test.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        Calculations are performed by `scipy.stats` and `statsmodels.stats`.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        `normality` with `dagostino-pearson` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.normality import normality</span>
<span class="sd">        &gt;&gt;&gt; data = np.random.normal(0, 1, 100)</span>
<span class="sd">        &gt;&gt;&gt; result = normality(data, algorithm=&quot;dp&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;jb&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;jb&quot;</span><span class="p">,</span> <span class="s2">&quot;jarque&quot;</span><span class="p">,</span> <span class="s2">&quot;jarque-bera&quot;</span><span class="p">),</span>
        <span class="s2">&quot;ob&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;ob&quot;</span><span class="p">,</span> <span class="s2">&quot;omni&quot;</span><span class="p">,</span> <span class="s2">&quot;omnibus&quot;</span><span class="p">),</span>
        <span class="s2">&quot;sw&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;sw&quot;</span><span class="p">,</span> <span class="s2">&quot;shapiro&quot;</span><span class="p">,</span> <span class="s2">&quot;shapiro-wilk&quot;</span><span class="p">),</span>
        <span class="s2">&quot;dp&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;dp&quot;</span><span class="p">,</span> <span class="s2">&quot;dagostino&quot;</span><span class="p">,</span> <span class="s2">&quot;dagostino-pearson&quot;</span><span class="p">),</span>
        <span class="s2">&quot;ad&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;ad&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson-darling&quot;</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;jb&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_jb</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;ob&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_ob</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;sw&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_sw</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;dp&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_dp</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;ad&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_ad</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="n">generate_error_message</span><span class="p">(</span>
            <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;algorithm&quot;</span><span class="p">,</span>
            <span class="n">value_parsed</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.normality.is_normal" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">is_normal</span>


<a href="#ts_stat_tests.tests.normality.is_normal" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">is_normal</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test whether a given data set is <code>normal</code> or not.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function implements the given algorithm (defined in the parameter <code>algorithm</code>), and returns a dictionary containing the relevant data:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The result of the test. Will be `True` if `p-value &gt;= alpha`, and `False` otherwise</span>
    <span class="s2">&quot;statistic&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The test statistic</span>
    <span class="s2">&quot;p_value&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The p-value of the test (if applicable)</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The significance level used</span>
<span class="p">}</span>
</code></pre></div></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which normality algorithm to use.<br>
- <code>jb()</code>: <code>["jb", "jarque", "jarque-bera"]</code><br>
- <code>ob()</code>: <code>["ob", "omni", "omnibus"]</code><br>
- <code>sw()</code>: <code>["sw", "shapiro", "shapiro-wilk"]</code><br>
- <code>dp()</code>: <code>["dp", "dagostino", "dagostino-pearson"]</code><br>
- <code>ad()</code>: <code>["ad", "anderson", "anderson-darling"]</code><br>
Defaults to <code>"dp"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;dp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>alpha</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Significance level. Default is <code>0.05</code>.</p>
              </div>
            </td>
            <td>
                  <code>0.05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis along which to compute the test. Default is <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_policy</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_DP_NAN_POLICY_OPTIONS">VALID_DP_NAN_POLICY_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Defines how to handle when input contains <code>NaN</code>.<br>
- <code>propagate</code>: returns <code>NaN</code><br>
- <code>raise</code>: throws an error<br>
- <code>omit</code>: performs the calculations ignoring <code>NaN</code> values<br>
Defaults to <code>"propagate"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;propagate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dist</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_AD_DIST_OPTIONS">VALID_AD_DIST_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of distribution to test against.<br>
Only relevant when <code>algorithm=anderson</code>.<br>
Defaults to <code>"norm"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;norm&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the results of the test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>Calculations are performed by <code>scipy.stats</code> and <code>statsmodels.stats</code>.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>is_normal</code> with <code>dagostino-pearson</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.normality</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">is_normal</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;dp&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">]</span>
<span class="go">True</span>
</code></pre></div></td></tr></table></div></p>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_normal</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test whether a given data set is `normal` or not.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function implements the given algorithm (defined in the parameter `algorithm`), and returns a dictionary containing the relevant data:</span>
<span class="sd">        ```python</span>
<span class="sd">        {</span>
<span class="sd">            &quot;result&quot;: ...,  # The result of the test. Will be `True` if `p-value &gt;= alpha`, and `False` otherwise</span>
<span class="sd">            &quot;statistic&quot;: ...,  # The test statistic</span>
<span class="sd">            &quot;p_value&quot;: ...,  # The p-value of the test (if applicable)</span>
<span class="sd">            &quot;alpha&quot;: ...,  # The significance level used</span>
<span class="sd">        }</span>
<span class="sd">        ```</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str):</span>
<span class="sd">            Which normality algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `jb()`: `[&quot;jb&quot;, &quot;jarque&quot;, &quot;jarque-bera&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ob()`: `[&quot;ob&quot;, &quot;omni&quot;, &quot;omnibus&quot;]`&lt;br&gt;</span>
<span class="sd">            - `sw()`: `[&quot;sw&quot;, &quot;shapiro&quot;, &quot;shapiro-wilk&quot;]`&lt;br&gt;</span>
<span class="sd">            - `dp()`: `[&quot;dp&quot;, &quot;dagostino&quot;, &quot;dagostino-pearson&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ad()`: `[&quot;ad&quot;, &quot;anderson&quot;, &quot;anderson-darling&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;dp&quot;`.</span>
<span class="sd">        alpha (float):</span>
<span class="sd">            Significance level. Default is `0.05`.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis along which to compute the test. Default is `0`.</span>
<span class="sd">        nan_policy (VALID_DP_NAN_POLICY_OPTIONS):</span>
<span class="sd">            Defines how to handle when input contains `NaN`.&lt;br&gt;</span>
<span class="sd">            - `propagate`: returns `NaN`&lt;br&gt;</span>
<span class="sd">            - `raise`: throws an error&lt;br&gt;</span>
<span class="sd">            - `omit`: performs the calculations ignoring `NaN` values&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;propagate&quot;`.</span>
<span class="sd">        dist (VALID_AD_DIST_OPTIONS):</span>
<span class="sd">            The type of distribution to test against.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=anderson`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;norm&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (dict):</span>
<span class="sd">            A dictionary containing the results of the test.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        Calculations are performed by `scipy.stats` and `statsmodels.stats`.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        `is_normal` with `dagostino-pearson` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.normality import is_normal</span>
<span class="sd">        &gt;&gt;&gt; data = np.random.normal(0, 1, 100)</span>
<span class="sd">        &gt;&gt;&gt; result = is_normal(data, algorithm=&quot;dp&quot;)</span>
<span class="sd">        &gt;&gt;&gt; result[&quot;result&quot;]</span>
<span class="sd">        True</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">normality</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="c1"># Anderson-Darling is a bit different</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;ad&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;ad&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson-darling&quot;</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;ad&quot;</span><span class="p">]:</span>
        <span class="c1"># res is AndersonResult(statistic, critical_values, significance_level, fit_result)</span>
        <span class="c1"># indexing only gives the first 3 elements</span>
        <span class="n">stat</span><span class="p">,</span> <span class="n">crit</span><span class="p">,</span> <span class="n">sig</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="c1"># sig is something like [15. , 10. ,  5. ,  2.5,  1. ]</span>
        <span class="c1"># alpha is something like 0.05 (which is 5%)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sig</span> <span class="o">-</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)))</span>
        <span class="n">critical_value</span> <span class="o">=</span> <span class="n">crit</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">is_norm</span> <span class="o">=</span> <span class="n">stat</span> <span class="o">&lt;</span> <span class="n">critical_value</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">is_norm</span><span class="p">),</span>
            <span class="s2">&quot;statistic&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">stat</span><span class="p">),</span>
            <span class="s2">&quot;critical_value&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">critical_value</span><span class="p">),</span>
            <span class="s2">&quot;significance_level&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">sig</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span>
            <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="c1"># For others, they return (statistic, pvalue) or similar</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s2">&quot;pvalue&quot;</span><span class="p">):</span>
        <span class="n">p_val</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Fallback</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">res</span>
        <span class="n">p_val</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">is_norm</span> <span class="o">=</span> <span class="n">p_val</span> <span class="o">&gt;=</span> <span class="n">alpha</span> <span class="k">if</span> <span class="n">p_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">is_norm</span><span class="p">),</span>
        <span class="s2">&quot;statistic&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">stat</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">stat</span><span class="p">,</span>
        <span class="s2">&quot;p_value&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">p_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div><h2 id="normality-algorithms">Normality Algorithms<a class="headerlink" href="#normality-algorithms" title="Permanent link">ðŸ”—</a></h2>


<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.tests.normality" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.tests.normality</span>


<a href="#ts_stat_tests.tests.normality" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains convenience functions and tests for normality measures, allowing for easy access to different normality algorithms.</p>
</div>










  <div class="doc doc-children">



























































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.normality.normality" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">normality</span>


<a href="#ts_stat_tests.tests.normality.normality" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">normality</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Perform a normality test on the given data.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is a convenience wrapper around the five underlying algorithms:<br>
- <a class="autorefs autorefs-internal" title="            jb" href="#ts_stat_tests.algorithms.normality.jb"><code>jb()</code></a><br>
- <a class="autorefs autorefs-internal" title="            ob" href="#ts_stat_tests.algorithms.normality.ob"><code>ob()</code></a><br>
- <a class="autorefs autorefs-internal" title="            sw" href="#ts_stat_tests.algorithms.normality.sw"><code>sw()</code></a><br>
- <a class="autorefs autorefs-internal" title="            dp" href="#ts_stat_tests.algorithms.normality.dp"><code>dp()</code></a><br>
- <a class="autorefs autorefs-internal" title="            ad" href="#ts_stat_tests.algorithms.normality.ad"><code>ad()</code></a></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which normality algorithm to use.<br>
- <code>jb()</code>: <code>["jb", "jarque", "jarque-bera"]</code><br>
- <code>ob()</code>: <code>["ob", "omni", "omnibus"]</code><br>
- <code>sw()</code>: <code>["sw", "shapiro", "shapiro-wilk"]</code><br>
- <code>dp()</code>: <code>["dp", "dagostino", "dagostino-pearson"]</code><br>
- <code>ad()</code>: <code>["ad", "anderson", "anderson-darling"]</code><br>
Defaults to <code>"dp"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;dp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis along which to compute the test. Default is <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_policy</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_DP_NAN_POLICY_OPTIONS">VALID_DP_NAN_POLICY_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Defines how to handle when input contains <code>NaN</code>.<br>
- <code>propagate</code>: returns <code>NaN</code><br>
- <code>raise</code>: throws an error<br>
- <code>omit</code>: performs the calculations ignoring <code>NaN</code> values<br>
Defaults to <code>"propagate"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;propagate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dist</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_AD_DIST_OPTIONS">VALID_AD_DIST_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of distribution to test against.<br>
Only relevant when <code>algorithm=anderson</code>.<br>
Defaults to <code>"norm"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;norm&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>When the given value for <code>algorithm</code> is not valid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result of the normality test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>Calculations are performed by <code>scipy.stats</code> and <code>statsmodels.stats</code>.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>normality</code> with <code>dagostino-pearson</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.normality</span><span class="w"> </span><span class="kn">import</span> <span class="n">normality</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">normality</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;dp&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></p>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">normality</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Perform a normality test on the given data.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function is a convenience wrapper around the five underlying algorithms:&lt;br&gt;</span>
<span class="sd">        - [`jb()`][ts_stat_tests.algorithms.normality.jb]&lt;br&gt;</span>
<span class="sd">        - [`ob()`][ts_stat_tests.algorithms.normality.ob]&lt;br&gt;</span>
<span class="sd">        - [`sw()`][ts_stat_tests.algorithms.normality.sw]&lt;br&gt;</span>
<span class="sd">        - [`dp()`][ts_stat_tests.algorithms.normality.dp]&lt;br&gt;</span>
<span class="sd">        - [`ad()`][ts_stat_tests.algorithms.normality.ad]</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str):</span>
<span class="sd">            Which normality algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `jb()`: `[&quot;jb&quot;, &quot;jarque&quot;, &quot;jarque-bera&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ob()`: `[&quot;ob&quot;, &quot;omni&quot;, &quot;omnibus&quot;]`&lt;br&gt;</span>
<span class="sd">            - `sw()`: `[&quot;sw&quot;, &quot;shapiro&quot;, &quot;shapiro-wilk&quot;]`&lt;br&gt;</span>
<span class="sd">            - `dp()`: `[&quot;dp&quot;, &quot;dagostino&quot;, &quot;dagostino-pearson&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ad()`: `[&quot;ad&quot;, &quot;anderson&quot;, &quot;anderson-darling&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;dp&quot;`.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis along which to compute the test. Default is `0`.</span>
<span class="sd">        nan_policy (VALID_DP_NAN_POLICY_OPTIONS):</span>
<span class="sd">            Defines how to handle when input contains `NaN`.&lt;br&gt;</span>
<span class="sd">            - `propagate`: returns `NaN`&lt;br&gt;</span>
<span class="sd">            - `raise`: throws an error&lt;br&gt;</span>
<span class="sd">            - `omit`: performs the calculations ignoring `NaN` values&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;propagate&quot;`.</span>
<span class="sd">        dist (VALID_AD_DIST_OPTIONS):</span>
<span class="sd">            The type of distribution to test against.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=anderson`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;norm&quot;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: When the given value for `algorithm` is not valid.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Any):</span>
<span class="sd">            The result of the normality test.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        Calculations are performed by `scipy.stats` and `statsmodels.stats`.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        `normality` with `dagostino-pearson` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.normality import normality</span>
<span class="sd">        &gt;&gt;&gt; data = np.random.normal(0, 1, 100)</span>
<span class="sd">        &gt;&gt;&gt; result = normality(data, algorithm=&quot;dp&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;jb&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;jb&quot;</span><span class="p">,</span> <span class="s2">&quot;jarque&quot;</span><span class="p">,</span> <span class="s2">&quot;jarque-bera&quot;</span><span class="p">),</span>
        <span class="s2">&quot;ob&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;ob&quot;</span><span class="p">,</span> <span class="s2">&quot;omni&quot;</span><span class="p">,</span> <span class="s2">&quot;omnibus&quot;</span><span class="p">),</span>
        <span class="s2">&quot;sw&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;sw&quot;</span><span class="p">,</span> <span class="s2">&quot;shapiro&quot;</span><span class="p">,</span> <span class="s2">&quot;shapiro-wilk&quot;</span><span class="p">),</span>
        <span class="s2">&quot;dp&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;dp&quot;</span><span class="p">,</span> <span class="s2">&quot;dagostino&quot;</span><span class="p">,</span> <span class="s2">&quot;dagostino-pearson&quot;</span><span class="p">),</span>
        <span class="s2">&quot;ad&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;ad&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson-darling&quot;</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;jb&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_jb</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;ob&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_ob</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;sw&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_sw</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;dp&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_dp</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;ad&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">_ad</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="n">generate_error_message</span><span class="p">(</span>
            <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;algorithm&quot;</span><span class="p">,</span>
            <span class="n">value_parsed</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.normality.is_normal" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">is_normal</span>


<a href="#ts_stat_tests.tests.normality.is_normal" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">is_normal</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test whether a given data set is <code>normal</code> or not.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function implements the given algorithm (defined in the parameter <code>algorithm</code>), and returns a dictionary containing the relevant data:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The result of the test. Will be `True` if `p-value &gt;= alpha`, and `False` otherwise</span>
    <span class="s2">&quot;statistic&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The test statistic</span>
    <span class="s2">&quot;p_value&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The p-value of the test (if applicable)</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The significance level used</span>
<span class="p">}</span>
</code></pre></div></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which normality algorithm to use.<br>
- <code>jb()</code>: <code>["jb", "jarque", "jarque-bera"]</code><br>
- <code>ob()</code>: <code>["ob", "omni", "omnibus"]</code><br>
- <code>sw()</code>: <code>["sw", "shapiro", "shapiro-wilk"]</code><br>
- <code>dp()</code>: <code>["dp", "dagostino", "dagostino-pearson"]</code><br>
- <code>ad()</code>: <code>["ad", "anderson", "anderson-darling"]</code><br>
Defaults to <code>"dp"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;dp&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>alpha</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Significance level. Default is <code>0.05</code>.</p>
              </div>
            </td>
            <td>
                  <code>0.05</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis along which to compute the test. Default is <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_policy</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_DP_NAN_POLICY_OPTIONS">VALID_DP_NAN_POLICY_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Defines how to handle when input contains <code>NaN</code>.<br>
- <code>propagate</code>: returns <code>NaN</code><br>
- <code>raise</code>: throws an error<br>
- <code>omit</code>: performs the calculations ignoring <code>NaN</code> values<br>
Defaults to <code>"propagate"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;propagate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dist</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_AD_DIST_OPTIONS">VALID_AD_DIST_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of distribution to test against.<br>
Only relevant when <code>algorithm=anderson</code>.<br>
Defaults to <code>"norm"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;norm&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the results of the test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>Calculations are performed by <code>scipy.stats</code> and <code>statsmodels.stats</code>.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>is_normal</code> with <code>dagostino-pearson</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.normality</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">is_normal</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;dp&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;result&quot;</span><span class="p">]</span>
<span class="go">True</span>
</code></pre></div></td></tr></table></div></p>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_normal</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dp&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test whether a given data set is `normal` or not.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function implements the given algorithm (defined in the parameter `algorithm`), and returns a dictionary containing the relevant data:</span>
<span class="sd">        ```python</span>
<span class="sd">        {</span>
<span class="sd">            &quot;result&quot;: ...,  # The result of the test. Will be `True` if `p-value &gt;= alpha`, and `False` otherwise</span>
<span class="sd">            &quot;statistic&quot;: ...,  # The test statistic</span>
<span class="sd">            &quot;p_value&quot;: ...,  # The p-value of the test (if applicable)</span>
<span class="sd">            &quot;alpha&quot;: ...,  # The significance level used</span>
<span class="sd">        }</span>
<span class="sd">        ```</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str):</span>
<span class="sd">            Which normality algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `jb()`: `[&quot;jb&quot;, &quot;jarque&quot;, &quot;jarque-bera&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ob()`: `[&quot;ob&quot;, &quot;omni&quot;, &quot;omnibus&quot;]`&lt;br&gt;</span>
<span class="sd">            - `sw()`: `[&quot;sw&quot;, &quot;shapiro&quot;, &quot;shapiro-wilk&quot;]`&lt;br&gt;</span>
<span class="sd">            - `dp()`: `[&quot;dp&quot;, &quot;dagostino&quot;, &quot;dagostino-pearson&quot;]`&lt;br&gt;</span>
<span class="sd">            - `ad()`: `[&quot;ad&quot;, &quot;anderson&quot;, &quot;anderson-darling&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;dp&quot;`.</span>
<span class="sd">        alpha (float):</span>
<span class="sd">            Significance level. Default is `0.05`.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis along which to compute the test. Default is `0`.</span>
<span class="sd">        nan_policy (VALID_DP_NAN_POLICY_OPTIONS):</span>
<span class="sd">            Defines how to handle when input contains `NaN`.&lt;br&gt;</span>
<span class="sd">            - `propagate`: returns `NaN`&lt;br&gt;</span>
<span class="sd">            - `raise`: throws an error&lt;br&gt;</span>
<span class="sd">            - `omit`: performs the calculations ignoring `NaN` values&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;propagate&quot;`.</span>
<span class="sd">        dist (VALID_AD_DIST_OPTIONS):</span>
<span class="sd">            The type of distribution to test against.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=anderson`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;norm&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (dict):</span>
<span class="sd">            A dictionary containing the results of the test.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        Calculations are performed by `scipy.stats` and `statsmodels.stats`.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        `is_normal` with `dagostino-pearson` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.normality import is_normal</span>
<span class="sd">        &gt;&gt;&gt; data = np.random.normal(0, 1, 100)</span>
<span class="sd">        &gt;&gt;&gt; result = is_normal(data, algorithm=&quot;dp&quot;)</span>
<span class="sd">        &gt;&gt;&gt; result[&quot;result&quot;]</span>
<span class="sd">        True</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">normality</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="c1"># Anderson-Darling is a bit different</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;ad&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;ad&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson&quot;</span><span class="p">,</span> <span class="s2">&quot;anderson-darling&quot;</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;ad&quot;</span><span class="p">]:</span>
        <span class="c1"># res is AndersonResult(statistic, critical_values, significance_level, fit_result)</span>
        <span class="c1"># indexing only gives the first 3 elements</span>
        <span class="n">stat</span><span class="p">,</span> <span class="n">crit</span><span class="p">,</span> <span class="n">sig</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="c1"># sig is something like [15. , 10. ,  5. ,  2.5,  1. ]</span>
        <span class="c1"># alpha is something like 0.05 (which is 5%)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sig</span> <span class="o">-</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)))</span>
        <span class="n">critical_value</span> <span class="o">=</span> <span class="n">crit</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">is_norm</span> <span class="o">=</span> <span class="n">stat</span> <span class="o">&lt;</span> <span class="n">critical_value</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">is_norm</span><span class="p">),</span>
            <span class="s2">&quot;statistic&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">stat</span><span class="p">),</span>
            <span class="s2">&quot;critical_value&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">critical_value</span><span class="p">),</span>
            <span class="s2">&quot;significance_level&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">sig</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span>
            <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="c1"># For others, they return (statistic, pvalue) or similar</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="s2">&quot;pvalue&quot;</span><span class="p">):</span>
        <span class="n">p_val</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
        <span class="n">stat</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Fallback</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">res</span>
        <span class="n">p_val</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">is_norm</span> <span class="o">=</span> <span class="n">p_val</span> <span class="o">&gt;=</span> <span class="n">alpha</span> <span class="k">if</span> <span class="n">p_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">is_norm</span><span class="p">),</span>
        <span class="s2">&quot;statistic&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">stat</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span> <span class="k">else</span> <span class="n">stat</span><span class="p">,</span>
        <span class="s2">&quot;p_value&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">p_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.algorithms.normality" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.algorithms.normality</span>


<a href="#ts_stat_tests.algorithms.normality" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module provides implementations of various statistical tests to assess the normality of data distributions. These tests are essential in statistical analysis and time series forecasting, as many models assume that the underlying data follows a normal distribution.</p>
</div>










  <div class="doc doc-children">































































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.normality.jb" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">jb</span>


<a href="#ts_stat_tests.algorithms.normality.jb" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">jb</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
<span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>The Jarque-Bera test is a statistical test used to determine whether a dataset follows a normal distribution. In time series forecasting, the test can be used to evaluate whether the residuals of a model follow a normal distribution, which is an assumption of many time series forecasting models.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>To apply the Jarque-Bera test to time series data, we first need to estimate the residuals of the forecasting model. The residuals represent the difference between the actual values of the time series and the values predicted by the model. We can then use the Jarque-Bera test to evaluate whether the residuals follow a normal distribution.</p>
<p>The Jarque-Bera test is based on two statistics, skewness and kurtosis, which measure the degree of asymmetry and peakedness in the distribution of the residuals. The test compares the observed skewness and kurtosis of the residuals to the expected values for a normal distribution. If the observed values are significantly different from the expected values, the test rejects the null hypothesis that the residuals follow a normal distribution.</p>
<p>In practice, we can use statistical software to perform the Jarque-Bera test on the residuals of a time series forecasting model. If the test indicates that the residuals do not follow a normal distribution, we may need to consider modifying the forecasting model or using a different modeling approach.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data to test for normality. Usually regression model residuals that are mean 0.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis to use if data has more than 1 dimension.<br>
Defaults to <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>JB</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.ArrayLike">ArrayLike</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Jarque-Bera test statistic.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>JBpv</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.ArrayLike">ArrayLike</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The pvalue of the test statistic.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>skew</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.ArrayLike">ArrayLike</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimated skewness of the data.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>kurtosis</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.ArrayLike">ArrayLike</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Estimated kurtosis of the data.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<p>Example one, using the <code>airline</code> data from the <code>sktime</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">jarque_bera</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Load the airline dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Apply Jarque-Bera test</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jb_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">skewness</span><span class="p">,</span> <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">jarque_bera</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jarque-Bera test statistic:&quot;</span><span class="p">,</span> <span class="n">jb_value</span><span class="p">)</span>
<span class="go">Jarque-Bera test statistic: 4.588031669436549</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p-value:&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
<span class="go">p-value: 0.10134805179561781</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Check the test</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject the null hypothesis that the data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cannot reject the null hypothesis that the data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Cannot reject the null hypothesis that the data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>In this example, the p-value is <strong>greater</strong> than <code>0.05</code>, indicating that we <em>cannot</em> reject the null hypothesis that the data <em>is</em> normally distributed. Therefore, we can assume that the airline data <strong>does</strong> follow a normal distribution.</p>
<hr />
<p>Example two, using the <code>sine</code> wave data generated from the <code>numpy</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">jarque_bera</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sine wave data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Apply Jarque-Bera test</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jb_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">skewness</span><span class="p">,</span> <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">jarque_bera</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jarque-Bera test statistic:&quot;</span><span class="p">,</span> <span class="n">jb_value</span><span class="p">)</span>
<span class="go">Jarque-Bera test statistic: 15.830310292715973</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p-value:&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
<span class="go">p-value: 0.00036833142556487206</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject the null hypothesis that the data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cannot reject the null hypothesis that the data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Reject the null hypothesis that the data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>In this example, the p-value is <strong>less</strong> than <code>0.05</code>, indicating that we <em>can</em> reject the null hypothesis that the data <em>is</em> normally distributed. Therefore, we can assume that the sine wave data does <strong>not</strong> follow a normal distribution.</p>
<hr />
<p>Example three, using the <code>FractionalGaussianNoise</code> random data generated from the <code>stochastic</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.noise</span><span class="w"> </span><span class="kn">import</span> <span class="n">FractionalGaussianNoise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">jarque_bera</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate Fractional Gaussian Noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fgn</span> <span class="o">=</span> <span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;daviesharte&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noise</span> <span class="o">=</span> <span class="n">fgn</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Apply Jarque-Bera test</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jb_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">skewness</span><span class="p">,</span> <span class="n">kurtosis</span> <span class="o">=</span> <span class="n">jarque_bera</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jarque-Bera test statistic:&quot;</span><span class="p">,</span> <span class="n">jb_value</span><span class="p">)</span>
<span class="go">Jarque-Bera test statistic: 8.94626982252318</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p-value:&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">)</span>
<span class="go">p-value: 0.011411891515478784</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject the null hypothesis that the data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cannot reject the null hypothesis that the data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Reject the null hypothesis that the data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>In this example, the p-value is <strong>less</strong> than <code>0.05</code>, indicating that we <em>can</em> reject the null hypothesis that the data <em>is</em> normally distributed. Therefore, we can assume that the random noise generated by <code>FractionalGaussianNoise</code> does <strong>not</strong> follow a normal distribution.</p>
</details>
<details class="note">
<summary>Notes</summary>
<p>Each output returned has 1 dimension fewer than data.</p>
<p>The Jarque-Bera test statistic tests the null that the data is normally distributed against an alternative that the data follow some other distribution. The test statistic is based on two moments of the data, the skewness, and the kurtosis, and has an asymptotic <span class="arithmatex">\(x_2^2\)</span> distribution.</p>
<p>The test statistic is defined as:</p>
<div class="arithmatex">\[
JB = n \left( \frac{S^2}{6} + \frac{(K-3)^2}{24} \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(n\)</span> is the number of data points,</li>
<li><span class="arithmatex">\(S\)</span> is the sample skewness, and</li>
<li><span class="arithmatex">\(K\)</span> is the sample kurtosis of the data.</li>
</ul>
</details>
<details class="success">
<summary>Credit</summary>
<ul>
<li>All credit goes to the <a href="https://www.statsmodels.org"><code>statsmodels</code></a> library.</li>
</ul>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Jarque, C. and Bera, A. (1980) "Efficient tests for normality, homoscedasticity and serial independence of regression residuals", 6 Econometric Letters 255-259.</li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            ob" href="#ts_stat_tests.algorithms.normality.ob"><code>ob()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sw" href="#ts_stat_tests.algorithms.normality.sw"><code>sw()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            dp" href="#ts_stat_tests.algorithms.normality.dp"><code>dp()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ad" href="#ts_stat_tests.algorithms.normality.ad"><code>ad()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">jb</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
    <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        The Jarque-Bera test is a statistical test used to determine whether a dataset follows a normal distribution. In time series forecasting, the test can be used to evaluate whether the residuals of a model follow a normal distribution, which is an assumption of many time series forecasting models.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        To apply the Jarque-Bera test to time series data, we first need to estimate the residuals of the forecasting model. The residuals represent the difference between the actual values of the time series and the values predicted by the model. We can then use the Jarque-Bera test to evaluate whether the residuals follow a normal distribution.</span>

<span class="sd">        The Jarque-Bera test is based on two statistics, skewness and kurtosis, which measure the degree of asymmetry and peakedness in the distribution of the residuals. The test compares the observed skewness and kurtosis of the residuals to the expected values for a normal distribution. If the observed values are significantly different from the expected values, the test rejects the null hypothesis that the residuals follow a normal distribution.</span>

<span class="sd">        In practice, we can use statistical software to perform the Jarque-Bera test on the residuals of a time series forecasting model. If the test indicates that the residuals do not follow a normal distribution, we may need to consider modifying the forecasting model or using a different modeling approach.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            Data to test for normality. Usually regression model residuals that are mean 0.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis to use if data has more than 1 dimension.&lt;br&gt;</span>
<span class="sd">            Defaults to `0`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        JB (Union[float, ArrayLike]):</span>
<span class="sd">            The Jarque-Bera test statistic.</span>
<span class="sd">        JBpv (Union[float, ArrayLike]):</span>
<span class="sd">            The pvalue of the test statistic.</span>
<span class="sd">        skew (Union[float, ArrayLike]):</span>
<span class="sd">            Estimated skewness of the data.</span>
<span class="sd">        kurtosis (Union[float, ArrayLike]):</span>
<span class="sd">            Estimated kurtosis of the data.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        Example one, using the `airline` data from the `sktime` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from statsmodels.stats.stattools import jarque_bera</span>

<span class="sd">        &gt;&gt;&gt; # Load the airline dataset</span>
<span class="sd">        &gt;&gt;&gt; y = load_airline()</span>

<span class="sd">        &gt;&gt;&gt; # Apply Jarque-Bera test</span>
<span class="sd">        &gt;&gt;&gt; jb_value, p_value, skewness, kurtosis = jarque_bera(y)</span>

<span class="sd">        &gt;&gt;&gt; # Print the results</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Jarque-Bera test statistic:&quot;, jb_value)</span>
<span class="sd">        Jarque-Bera test statistic: 4.588031669436549</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;p-value:&quot;, p_value)</span>
<span class="sd">        p-value: 0.10134805179561781</span>

<span class="sd">        &gt;&gt;&gt; # Check the test</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; 0.05:</span>
<span class="sd">        ...     print(&quot;Reject the null hypothesis that the data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Cannot reject the null hypothesis that the data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Cannot reject the null hypothesis that the data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        In this example, the p-value is **greater** than `0.05`, indicating that we _cannot_ reject the null hypothesis that the data _is_ normally distributed. Therefore, we can assume that the airline data **does** follow a normal distribution.</span>

<span class="sd">        ---</span>

<span class="sd">        Example two, using the `sine` wave data generated from the `numpy` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from statsmodels.stats.stattools import jarque_bera</span>

<span class="sd">        &gt;&gt;&gt; # Generate sine wave data</span>
<span class="sd">        &gt;&gt;&gt; t = np.linspace(0, 10, 100)</span>
<span class="sd">        &gt;&gt;&gt; y = np.sin(t)</span>

<span class="sd">        &gt;&gt;&gt; # Apply Jarque-Bera test</span>
<span class="sd">        &gt;&gt;&gt; jb_value, p_value, skewness, kurtosis = jarque_bera(y)</span>

<span class="sd">        &gt;&gt;&gt; # Print the results</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Jarque-Bera test statistic:&quot;, jb_value)</span>
<span class="sd">        Jarque-Bera test statistic: 15.830310292715973</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;p-value:&quot;, p_value)</span>
<span class="sd">        p-value: 0.00036833142556487206</span>

<span class="sd">        &gt;&gt;&gt; if p_value &lt; 0.05:</span>
<span class="sd">        ...     print(&quot;Reject the null hypothesis that the data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Cannot reject the null hypothesis that the data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Reject the null hypothesis that the data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        In this example, the p-value is **less** than `0.05`, indicating that we _can_ reject the null hypothesis that the data _is_ normally distributed. Therefore, we can assume that the sine wave data does **not** follow a normal distribution.</span>

<span class="sd">        ---</span>

<span class="sd">        Example three, using the `FractionalGaussianNoise` random data generated from the `stochastic` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.noise import FractionalGaussianNoise</span>
<span class="sd">        &gt;&gt;&gt; from statsmodels.stats.stattools import jarque_bera</span>

<span class="sd">        &gt;&gt;&gt; # Generate Fractional Gaussian Noise</span>
<span class="sd">        &gt;&gt;&gt; fgn = FractionalGaussianNoise(t=1, hurst=0.5, length=100, method=&quot;daviesharte&quot;)</span>
<span class="sd">        &gt;&gt;&gt; noise = fgn.sample()</span>

<span class="sd">        &gt;&gt;&gt; # Apply Jarque-Bera test</span>
<span class="sd">        &gt;&gt;&gt; jb_value, p_value, skewness, kurtosis = jarque_bera(y)</span>

<span class="sd">        &gt;&gt;&gt; # Print the results</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Jarque-Bera test statistic:&quot;, jb_value)</span>
<span class="sd">        Jarque-Bera test statistic: 8.94626982252318</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;p-value:&quot;, p_value)</span>
<span class="sd">        p-value: 0.011411891515478784</span>

<span class="sd">        &gt;&gt;&gt; if p_value &lt; 0.05:</span>
<span class="sd">        ...     print(&quot;Reject the null hypothesis that the data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Cannot reject the null hypothesis that the data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Reject the null hypothesis that the data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        In this example, the p-value is **less** than `0.05`, indicating that we _can_ reject the null hypothesis that the data _is_ normally distributed. Therefore, we can assume that the random noise generated by `FractionalGaussianNoise` does **not** follow a normal distribution.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        Each output returned has 1 dimension fewer than data.</span>

<span class="sd">        The Jarque-Bera test statistic tests the null that the data is normally distributed against an alternative that the data follow some other distribution. The test statistic is based on two moments of the data, the skewness, and the kurtosis, and has an asymptotic $x_2^2$ distribution.</span>

<span class="sd">        The test statistic is defined as:</span>

<span class="sd">        $$</span>
<span class="sd">        JB = n \\left( \\frac{S^2}{6} + \\frac{(K-3)^2}{24} \\right)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $n$ is the number of data points,</span>
<span class="sd">        - $S$ is the sample skewness, and</span>
<span class="sd">        - $K$ is the sample kurtosis of the data.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        - All credit goes to the [`statsmodels`](https://www.statsmodels.org) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - Jarque, C. and Bera, A. (1980) &quot;Efficient tests for normality, homoscedasticity and serial independence of regression residuals&quot;, 6 Econometric Letters 255-259.</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`ob()`][ts_stat_tests.algorithms.normality.ob]</span>
<span class="sd">        - [`sw()`][ts_stat_tests.algorithms.normality.sw]</span>
<span class="sd">        - [`dp()`][ts_stat_tests.algorithms.normality.dp]</span>
<span class="sd">        - [`ad()`][ts_stat_tests.algorithms.normality.ad]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_jb</span><span class="p">(</span><span class="n">resids</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.normality.ob" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">ob</span>


<a href="#ts_stat_tests.algorithms.normality.ob" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">ob</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">NormaltestResult</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>The Omnibus test is a statistical test used to evaluate the normality of a dataset, including time series data. In time series forecasting, the Omnibus test can be used to assess whether the residuals of a model follow a normal distribution, which is an important assumption for many statistical models.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The Omnibus test uses a combination of skewness and kurtosis measures to assess whether the residuals follow a normal distribution. Skewness measures the degree of asymmetry in the distribution of the residuals, while kurtosis measures the degree of peakedness or flatness. If the residuals follow a normal distribution, their skewness and kurtosis should be close to zero.</p>
<p>To apply the Omnibus test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the Omnibus test on the residuals. The test produces a single p-value, which indicates the probability of observing the observed skewness and kurtosis values if the residuals follow a normal distribution. If the p-value is greater than the significance level (usually 0.05), we can conclude that the residuals follow a normal distribution.</p>
<p>If the Omnibus test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</p>
<p>The Omnibus test for normality is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. The mathematical equation for the Omnibus test is:</p>
<div class="arithmatex">\[
O = N \times (b_1^2 + b_2^2)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(O\)</span> is the Omnibus test statistic</li>
<li><span class="arithmatex">\(N\)</span> is the sample size</li>
<li><span class="arithmatex">\(b1\)</span> and <span class="arithmatex">\(b2\)</span> are the coefficients of the first two terms of a third-order polynomial fit to the data</li>
</ul>
<p>To calculate the Omnibus test statistic for time series data, we need to perform the following steps:</p>
<ol>
<li>
<p>Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</p>
</li>
<li>
<p>Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</p>
</li>
<li>
<p>Calculate the skewness and kurtosis of the residuals: These are measures of the asymmetry and peakedness of the distribution of the residuals, respectively.</p>
</li>
<li>
<p>Fit a third-order polynomial to the standardized residuals: The standardized residuals are the residuals divided by their sample standard deviation. The third-order polynomial has the form:</p>
<div class="arithmatex">\[
z = b_0 + (b_1 \times x) + (b_2 \times x^2) + (b_3 \times x^3)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(z\)</span> is the standardized residual,</li>
<li><span class="arithmatex">\(x\)</span> is the normal deviate (i.e., the value that would be expected if the data followed a normal distribution), and</li>
<li><span class="arithmatex">\(b_0\)</span>, <span class="arithmatex">\(b_1\)</span>, <span class="arithmatex">\(b_2\)</span>, and <span class="arithmatex">\(b_3\)</span> are the coefficients of the polynomial fit.</li>
</ul>
</li>
<li>
<p>Calculate the values of <span class="arithmatex">\(b_1\)</span> and <span class="arithmatex">\(b_2\)</span>: These are the coefficients of the first two terms of the polynomial fit.</p>
</li>
<li>
<p>Substitute the values for sample size, <span class="arithmatex">\(b_1\)</span>, and <span class="arithmatex">\(b_2\)</span> into the Omnibus formula: The formula calculates a single test statistic, which is the Omnibus value.</p>
</li>
<li>
<p>Compare the Omnibus value to a critical value from a chi-squared distribution with 2 degrees of freedom: If the Omnibus value is greater than the critical value, we can reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution. If the Omnibus value is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution.</p>
</li>
</ol>
<p>In summary, the Omnibus test is a statistical test that evaluates normality of time series residuals using a third-order polynomial fit to the standardized residuals. It calculates a single test statistic using the coefficients of the polynomial fit and compares it to a critical value to determine whether the residuals follow a normal distribution.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data to test for normality. Usually regression model residuals that are mean 0.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis to use if data has more than 1 dimension.<br>
Defaults to <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>statistic</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="np.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Omnibus test statistic.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>pvalue</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="np.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The p-value for the hypothesis test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<p>Example one, using the <code>airline</code> data from the <code>sktime</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">omni_normtest</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load the airline dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">airline</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run the Omnibus test on the dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">omni_normtest</span><span class="p">(</span><span class="n">airline</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Omnibus test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Omnibus test statistic: 1.753</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Omnibus test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Omnibus test p-value: 0.416</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Fail to reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of the Omnibus test is that the data <em>is</em> normally distributed. In this case, the p-value is <code>0.416</code>, which is <strong>greater</strong> than the significance level of <code>0.05</code>, indicating that we <em>fail</em> to reject the null hypothesis. Therefore, we can conclude that the Airline dataset <strong>is</strong> likely normally distributed.</p>
<hr />
<p>Example two, using the <code>sine</code> wave data generated from the <code>numpy</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">omni_normtest</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate sine wave data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run the Omnibus test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">omni_normtest</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Omnibus test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Omnibus test statistic: 24.750</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Omnibus test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Omnibus test p-value: 4.326e-06</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of the Omnibus test <em>is</em> that the data is normally distributed. In this case, the p-value is <code>4.326e-06</code>, which is much <strong>smaller</strong> than the significance level of <code>0.05</code>, indicating strong evidence to <em>reject</em> the null hypothesis. Therefore, we can conclude that the sine wave data is <strong>not</strong> normally distributed.</p>
<hr />
<p>Example three, using the <code>FractionalGaussianNoise</code> random data generated from the <code>stochastic</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.noise</span><span class="w"> </span><span class="kn">import</span> <span class="n">FractionalGaussianNoise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">omni_normtest</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate Fractional Gaussian Noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fgn</span> <span class="o">=</span> <span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;daviesharte&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noise</span> <span class="o">=</span> <span class="n">fgn</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run the Omnibus test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">omni_normtest</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Omnibus test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Omnibus test statistic: 4.717</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Omnibus test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Omnibus test p-value: 0.094</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Fail to reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of the Omnibus test <em>is</em> that the data is normally distributed. In this case, the p-value is <code>0.094</code>, which is <strong>greater</strong> than the significance level of <code>0.05</code>, indicating that we <em>fail</em> to reject the null hypothesis. Therefore, we can conclude that the random noise generated by the <code>FractionalGaussianNoise</code> class <strong>is</strong> likely normally distributed.</p>
</details>
<details class="note">
<summary>Notes</summary>
<p>The Omnibus test statistic tests the null that the data is normally distributed against an alternative that the data follow some other distribution. It is based on D'Agostino's <span class="arithmatex">\(K^2\)</span> test statistic.</p>
</details>
<details class="success">
<summary>Credit</summary>
<ul>
<li>All credit goes to the <a href="https://www.statsmodels.org"><code>statsmodels</code></a> library.</li>
</ul>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>D'Agostino, R. B. and Pearson, E. S. (1973), "Tests for departure from normality," Biometrika, 60, 613-622.</li>
<li>D'Agostino, R. B. and Stephens, M. A. (1986), "Goodness-of-fit techniques," New York: Marcel Dekker.</li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            jb" href="#ts_stat_tests.algorithms.normality.jb"><code>jb()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sw" href="#ts_stat_tests.algorithms.normality.sw"><code>sw()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            dp" href="#ts_stat_tests.algorithms.normality.dp"><code>dp()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ad" href="#ts_stat_tests.algorithms.normality.ad"><code>ad()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ob</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">NormaltestResult</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        The Omnibus test is a statistical test used to evaluate the normality of a dataset, including time series data. In time series forecasting, the Omnibus test can be used to assess whether the residuals of a model follow a normal distribution, which is an important assumption for many statistical models.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The Omnibus test uses a combination of skewness and kurtosis measures to assess whether the residuals follow a normal distribution. Skewness measures the degree of asymmetry in the distribution of the residuals, while kurtosis measures the degree of peakedness or flatness. If the residuals follow a normal distribution, their skewness and kurtosis should be close to zero.</span>

<span class="sd">        To apply the Omnibus test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the Omnibus test on the residuals. The test produces a single p-value, which indicates the probability of observing the observed skewness and kurtosis values if the residuals follow a normal distribution. If the p-value is greater than the significance level (usually 0.05), we can conclude that the residuals follow a normal distribution.</span>

<span class="sd">        If the Omnibus test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</span>

<span class="sd">        The Omnibus test for normality is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. The mathematical equation for the Omnibus test is:</span>

<span class="sd">        $$</span>
<span class="sd">        O = N \\times (b_1^2 + b_2^2)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $O$ is the Omnibus test statistic</span>
<span class="sd">        - $N$ is the sample size</span>
<span class="sd">        - $b1$ and $b2$ are the coefficients of the first two terms of a third-order polynomial fit to the data</span>

<span class="sd">        To calculate the Omnibus test statistic for time series data, we need to perform the following steps:</span>

<span class="sd">        1. Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</span>

<span class="sd">        1. Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</span>

<span class="sd">        1. Calculate the skewness and kurtosis of the residuals: These are measures of the asymmetry and peakedness of the distribution of the residuals, respectively.</span>

<span class="sd">        1. Fit a third-order polynomial to the standardized residuals: The standardized residuals are the residuals divided by their sample standard deviation. The third-order polynomial has the form:</span>

<span class="sd">            $$</span>
<span class="sd">            z = b_0 + (b_1 \\times x) + (b_2 \\times x^2) + (b_3 \\times x^3)</span>
<span class="sd">            $$</span>

<span class="sd">            where:</span>

<span class="sd">            - $z$ is the standardized residual,</span>
<span class="sd">            - $x$ is the normal deviate (i.e., the value that would be expected if the data followed a normal distribution), and</span>
<span class="sd">            - $b_0$, $b_1$, $b_2$, and $b_3$ are the coefficients of the polynomial fit.</span>

<span class="sd">        1. Calculate the values of $b_1$ and $b_2$: These are the coefficients of the first two terms of the polynomial fit.</span>

<span class="sd">        1. Substitute the values for sample size, $b_1$, and $b_2$ into the Omnibus formula: The formula calculates a single test statistic, which is the Omnibus value.</span>

<span class="sd">        1. Compare the Omnibus value to a critical value from a chi-squared distribution with 2 degrees of freedom: If the Omnibus value is greater than the critical value, we can reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution. If the Omnibus value is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution.</span>

<span class="sd">        In summary, the Omnibus test is a statistical test that evaluates normality of time series residuals using a third-order polynomial fit to the standardized residuals. It calculates a single test statistic using the coefficients of the polynomial fit and compares it to a critical value to determine whether the residuals follow a normal distribution.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            Data to test for normality. Usually regression model residuals that are mean 0.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis to use if data has more than 1 dimension.&lt;br&gt;</span>
<span class="sd">            Defaults to `0`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        statistic (Union[float, np.ndarray]):</span>
<span class="sd">            The Omnibus test statistic.</span>
<span class="sd">        pvalue (Union[float, np.ndarray]):</span>
<span class="sd">            The p-value for the hypothesis test.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>
<span class="sd">        Example one, using the `airline` data from the `sktime` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from statsmodels.stats.stattools import omni_normtest</span>

<span class="sd">        &gt;&gt;&gt; # load the airline dataset</span>
<span class="sd">        &gt;&gt;&gt; airline = load_airline()</span>

<span class="sd">        &gt;&gt;&gt; # run the Omnibus test on the dataset</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = omni_normtest(airline)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Omnibus test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        Omnibus test statistic: 1.753</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Omnibus test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        Omnibus test p-value: 0.416</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Fail to reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of the Omnibus test is that the data _is_ normally distributed. In this case, the p-value is `0.416`, which is **greater** than the significance level of `0.05`, indicating that we _fail_ to reject the null hypothesis. Therefore, we can conclude that the Airline dataset **is** likely normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example two, using the `sine` wave data generated from the `numpy` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from statsmodels.stats.stattools import omni_normtest</span>

<span class="sd">        &gt;&gt;&gt; # generate sine wave data</span>
<span class="sd">        &gt;&gt;&gt; data = np.sin(np.linspace(0, 2 * np.pi, num=100))</span>

<span class="sd">        &gt;&gt;&gt; # run the Omnibus test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = omni_normtest(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Omnibus test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        Omnibus test statistic: 24.750</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Omnibus test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        Omnibus test p-value: 4.326e-06</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of the Omnibus test _is_ that the data is normally distributed. In this case, the p-value is `4.326e-06`, which is much **smaller** than the significance level of `0.05`, indicating strong evidence to _reject_ the null hypothesis. Therefore, we can conclude that the sine wave data is **not** normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example three, using the `FractionalGaussianNoise` random data generated from the `stochastic` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.noise import FractionalGaussianNoise</span>
<span class="sd">        &gt;&gt;&gt; from statsmodels.stats.stattools import omni_normtest</span>

<span class="sd">        &gt;&gt;&gt; # Generate Fractional Gaussian Noise</span>
<span class="sd">        &gt;&gt;&gt; fgn = FractionalGaussianNoise(t=1, hurst=0.5, length=1000, method=&quot;daviesharte&quot;)</span>
<span class="sd">        &gt;&gt;&gt; noise = fgn.sample()</span>

<span class="sd">        &gt;&gt;&gt; # run the Omnibus test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = omni_normtest(noise)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Omnibus test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        Omnibus test statistic: 4.717</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Omnibus test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        Omnibus test p-value: 0.094</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Fail to reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of the Omnibus test _is_ that the data is normally distributed. In this case, the p-value is `0.094`, which is **greater** than the significance level of `0.05`, indicating that we _fail_ to reject the null hypothesis. Therefore, we can conclude that the random noise generated by the `FractionalGaussianNoise` class **is** likely normally distributed.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        The Omnibus test statistic tests the null that the data is normally distributed against an alternative that the data follow some other distribution. It is based on D&#39;Agostino&#39;s $K^2$ test statistic.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        - All credit goes to the [`statsmodels`](https://www.statsmodels.org) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - D&#39;Agostino, R. B. and Pearson, E. S. (1973), &quot;Tests for departure from normality,&quot; Biometrika, 60, 613-622.</span>
<span class="sd">        - D&#39;Agostino, R. B. and Stephens, M. A. (1986), &quot;Goodness-of-fit techniques,&quot; New York: Marcel Dekker.</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`jb()`][ts_stat_tests.algorithms.normality.jb]</span>
<span class="sd">        - [`sw()`][ts_stat_tests.algorithms.normality.sw]</span>
<span class="sd">        - [`dp()`][ts_stat_tests.algorithms.normality.dp]</span>
<span class="sd">        - [`ad()`][ts_stat_tests.algorithms.normality.ad]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_ob</span><span class="p">(</span><span class="n">resids</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.normality.sw" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">sw</span>


<a href="#ts_stat_tests.algorithms.normality.sw" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">sw</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">ShapiroResult</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>The Shapiro-Wilk test is a statistical test used to determine whether a dataset, including time series data, follows a normal distribution. In time series forecasting, the Shapiro-Wilk test can be used to evaluate whether the residuals of a model follow a normal distribution, which is an assumption of many statistical models.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The Shapiro-Wilk test is based on the null hypothesis that the residuals of the forecasting model are normally distributed. The test calculates a test statistic that compares the observed distribution of the residuals to the expected distribution under the null hypothesis of normality. If the observed distribution of the residuals deviates significantly from the expected distribution under normality, the test rejects the null hypothesis and concludes that the residuals do not follow a normal distribution.</p>
<p>To apply the Shapiro-Wilk test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the Shapiro-Wilk test on the residuals. The test produces a p-value, which indicates the probability of observing the observed distribution of the residuals if the null hypothesis of normality is true. If the p-value is less than the significance level (usually 0.05), we can conclude that the residuals do not follow a normal distribution.</p>
<p>If the Shapiro-Wilk test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</p>
<p>The Shapiro-Wilk test is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. The mathematical equation for the Shapiro-Wilk test is:</p>
<div class="arithmatex">\[
W = \frac { \left( \sum_{i=1}^n (a_i \times z_i) \right)^2 } { \sum_{i=1}^n (x_i - \bar{x})^2 }
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(W\)</span> is the test statistic</li>
<li><span class="arithmatex">\(a_i\)</span> are the coefficients calculated from the ordered sample values</li>
<li><span class="arithmatex">\(z_i\)</span> are the corresponding normal deviates for the ai coefficients</li>
<li><span class="arithmatex">\(x_i\)</span> are the ordered sample values</li>
<li><span class="arithmatex">\(\bar{x}\)</span> is the sample mean</li>
</ul>
<p>To calculate the Shapiro-Wilk test statistic for time series data, we need to perform the following steps:</p>
<ol>
<li>
<p>Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</p>
</li>
<li>
<p>Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</p>
</li>
<li>
<p>Standardize the residuals: The standardized residuals are the residuals divided by their sample standard deviation.</p>
</li>
<li>
<p>Order the standardized residuals from smallest to largest: This step ensures that the Shapiro-Wilk test is performed on a sample that is in ascending order.</p>
</li>
<li>
<p>Calculate the <span class="arithmatex">\(a_i\)</span> coefficients: The <span class="arithmatex">\(a_i\)</span> coefficients are calculated from the ordered sample values using the formula:</p>
<div class="arithmatex">\[
a_i = \frac { \sum_{j=1}^{n} (a_{i_j} \times x_j) }{ s^2 }
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(s^2\)</span> is the sample variance and</li>
<li><span class="arithmatex">\(a_{i_j}\)</span> are constants that depend on the sample size and the order of the sample values. These constants are pre-calculated and available in statistical software packages.</li>
</ul>
</li>
<li>
<p>Calculate the <span class="arithmatex">\(z_i\)</span> normal deviates: The <span class="arithmatex">\(z_i\)</span> normal deviates are the corresponding values of the standard normal distribution for the ai coefficients. These values are pre-calculated and available in statistical software packages.</p>
</li>
<li>
<p>Calculate the numerator of the test statistic: This is the sum of the product of the ai coefficients and the corresponding <span class="arithmatex">\(z_i\)</span> normal deviates:</p>
<div class="arithmatex">\[
\sum (a_i \times z_i)
\]</div>
</li>
<li>
<p>Calculate the denominator of the test statistic: This is the sum of the squared differences between the ordered sample values and the sample mean:</p>
<div class="arithmatex">\[
\sum (x_i - \bar{x})^2
\]</div>
</li>
<li>
<p>Calculate the test statistic: This is the ratio of the squared numerator to the denominator:</p>
<div class="arithmatex">\[
W = \frac { (\sum(a_i \times z_i))^2 } { \sum(x_i - \bar{x})^2 }
\]</div>
</li>
<li>
<p>Compare the test statistic to a critical value: If the test statistic is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution. If the test statistic is greater than the critical value, we reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution.</p>
</li>
</ol>
<p>In summary, the Shapiro-Wilk test is a statistical test that evaluates normality of time series residuals by standardizing and ordering the residuals, calculating ai coefficients and corresponding <span class="arithmatex">\(z_i\)</span> normal deviates, and computing the test statistic using a ratio of the squared sum of <span class="arithmatex">\(ai \times zi\)</span> to the sum of squared differences between the sample values and sample mean. Finally, we compare the test statistic to a critical value to determine whether the residuals follow a normal distribution or not.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Array of sample data</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>statistic</code></td>            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The test statistic.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>pvalue</code></td>            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The p-value for the hypothesis test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<p>Test the null hypothesis that a random sample was drawn from a normal distribution.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">From the `scipy` docs</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">shapiro</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span>
<span class="go">ShapiroResult(statistic=0.9813305735588074, pvalue=0.16855233907699585)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.9813305735588074</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">0.16855233907699585</span>
</code></pre></div></td></tr></table></div>
<hr />
<p>Example one, using the <code>airline</code> data from the <code>sktime</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">shapiro</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load the airline data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run the Shapiro-Wilk test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">shapiro</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shapiro-Wilk test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Shapiro-Wilk test statistic: 0.910</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shapiro-Wilk test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Shapiro-Wilk test p-value: 0.054</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Fail to reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of the Shapiro-Wilk test is that the data <em>is</em> normally distributed. In this case, the p-value is <code>0.054</code>, which is <strong>greater</strong> than the significance level of <code>0.05</code>, indicating that we <em>fail</em> to reject the null hypothesis. Therefore, we can conclude that the airline data <strong>is</strong> likely normally distributed.</p>
<hr />
<p>Example two, using the <code>sine</code> wave data generated from the <code>numpy</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">shapiro</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate sine wave data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run the Shapiro-Wilk test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">shapiro</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shapiro-Wilk test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shapiro-Wilk test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of the Shapiro-Wilk test <em>is</em> that the data is normally distributed. In this case, the p-value is <code>0.002</code>, which is <strong>less</strong> than the significance level of <code>0.05</code>, indicating that we <em>can</em> reject the null hypothesis. Therefore, we can conclude that the sine wave data is <strong>not</strong> normally distributed.</p>
<hr />
<p>Example three, using the <code>FractionalGaussianNoise</code> random data generated from the <code>stochastic</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.noise</span><span class="w"> </span><span class="kn">import</span> <span class="n">FractionalGaussianNoise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">shapiro</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate Fractional Gaussian Noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fgn</span> <span class="o">=</span> <span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;daviesharte&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">fgn</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run the Shapiro-Wilk test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">shapiro</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shapiro-Wilk test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Shapiro-Wilk test statistic: 0.979</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shapiro-Wilk test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Shapiro-Wilk test p-value: 0.417</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Fail to reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of the Shapiro-Wilk test <em>is</em> that the data is normally distributed. In this case, the p-value is <code>0.417</code>, which is <strong>greater</strong> than the significance level of <code>0.05</code>, indicating that we <em>fail</em> to reject the null hypothesis. Therefore, we can conclude that the random noise generated by the <code>FractionalGaussianNoise</code> class <strong>is</strong> likely normally distributed.</p>
</details>
<details class="note">
<summary>Notes</summary>
<p>The algorithm used is described in (Algorithm as R94 Appl. Statist. (1995)) but censoring parameters as described are not implemented. For <span class="arithmatex">\(N &gt; 5000\)</span> the <span class="arithmatex">\(W\)</span> test statistic is accurate but the <span class="arithmatex">\(p-value\)</span> may not be.</p>
<p>The chance of rejecting the null hypothesis when it is true is close to <span class="arithmatex">\(5%\)</span> regardless of sample size.</p>
</details>
<details class="success">
<summary>Credit</summary>
<ul>
<li>All credit goes to the <a href="https://docs.scipy.org/"><code>scipy</code></a> library.</li>
</ul>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm">https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</a></li>
<li>Shapiro, S. S. &amp; Wilk, M.B (1965). An analysis of variance test for normality (complete samples), Biometrika, Vol. 52, pp. 591-611.</li>
<li>Razali, N. M. &amp; Wah, Y. B. (2011) Power comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests, Journal of Statistical Modeling and Analytics, Vol. 2, pp. 21-33.</li>
<li>Algorithm as R94 Appl. Statist. (1995) VOL. 44, NO. 4.</li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            jb" href="#ts_stat_tests.algorithms.normality.jb"><code>jb()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ob" href="#ts_stat_tests.algorithms.normality.ob"><code>ob()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            dp" href="#ts_stat_tests.algorithms.normality.dp"><code>dp()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ad" href="#ts_stat_tests.algorithms.normality.ad"><code>ad()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sw</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">ShapiroResult</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        The Shapiro-Wilk test is a statistical test used to determine whether a dataset, including time series data, follows a normal distribution. In time series forecasting, the Shapiro-Wilk test can be used to evaluate whether the residuals of a model follow a normal distribution, which is an assumption of many statistical models.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The Shapiro-Wilk test is based on the null hypothesis that the residuals of the forecasting model are normally distributed. The test calculates a test statistic that compares the observed distribution of the residuals to the expected distribution under the null hypothesis of normality. If the observed distribution of the residuals deviates significantly from the expected distribution under normality, the test rejects the null hypothesis and concludes that the residuals do not follow a normal distribution.</span>

<span class="sd">        To apply the Shapiro-Wilk test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the Shapiro-Wilk test on the residuals. The test produces a p-value, which indicates the probability of observing the observed distribution of the residuals if the null hypothesis of normality is true. If the p-value is less than the significance level (usually 0.05), we can conclude that the residuals do not follow a normal distribution.</span>

<span class="sd">        If the Shapiro-Wilk test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</span>

<span class="sd">        The Shapiro-Wilk test is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. The mathematical equation for the Shapiro-Wilk test is:</span>

<span class="sd">        $$</span>
<span class="sd">        W = \\frac { \\left( \\sum_{i=1}^n (a_i \\times z_i) \\right)^2 } { \\sum_{i=1}^n (x_i - \\bar{x})^2 }</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $W$ is the test statistic</span>
<span class="sd">        - $a_i$ are the coefficients calculated from the ordered sample values</span>
<span class="sd">        - $z_i$ are the corresponding normal deviates for the ai coefficients</span>
<span class="sd">        - $x_i$ are the ordered sample values</span>
<span class="sd">        - $\\bar{x}$ is the sample mean</span>

<span class="sd">        To calculate the Shapiro-Wilk test statistic for time series data, we need to perform the following steps:</span>

<span class="sd">        1. Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</span>

<span class="sd">        1. Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</span>

<span class="sd">        1. Standardize the residuals: The standardized residuals are the residuals divided by their sample standard deviation.</span>

<span class="sd">        1. Order the standardized residuals from smallest to largest: This step ensures that the Shapiro-Wilk test is performed on a sample that is in ascending order.</span>

<span class="sd">        1. Calculate the $a_i$ coefficients: The $a_i$ coefficients are calculated from the ordered sample values using the formula:</span>

<span class="sd">            $$</span>
<span class="sd">            a_i = \\frac { \\sum_{j=1}^{n} (a_{i_j} \\times x_j) }{ s^2 }</span>
<span class="sd">            $$</span>

<span class="sd">            where:</span>

<span class="sd">            - $s^2$ is the sample variance and</span>
<span class="sd">            - $a_{i_j}$ are constants that depend on the sample size and the order of the sample values. These constants are pre-calculated and available in statistical software packages.</span>

<span class="sd">        1. Calculate the $z_i$ normal deviates: The $z_i$ normal deviates are the corresponding values of the standard normal distribution for the ai coefficients. These values are pre-calculated and available in statistical software packages.</span>

<span class="sd">        1. Calculate the numerator of the test statistic: This is the sum of the product of the ai coefficients and the corresponding $z_i$ normal deviates:</span>

<span class="sd">            $$</span>
<span class="sd">            \\sum (a_i \\times z_i)</span>
<span class="sd">            $$</span>

<span class="sd">        1. Calculate the denominator of the test statistic: This is the sum of the squared differences between the ordered sample values and the sample mean:</span>

<span class="sd">            $$</span>
<span class="sd">            \\sum (x_i - \\bar{x})^2</span>
<span class="sd">            $$</span>

<span class="sd">        1. Calculate the test statistic: This is the ratio of the squared numerator to the denominator:</span>

<span class="sd">            $$</span>
<span class="sd">            W = \\frac { (\\sum(a_i \\times z_i))^2 } { \\sum(x_i - \\bar{x})^2 }</span>
<span class="sd">            $$</span>

<span class="sd">        1. Compare the test statistic to a critical value: If the test statistic is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution. If the test statistic is greater than the critical value, we reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution.</span>

<span class="sd">        In summary, the Shapiro-Wilk test is a statistical test that evaluates normality of time series residuals by standardizing and ordering the residuals, calculating ai coefficients and corresponding $z_i$ normal deviates, and computing the test statistic using a ratio of the squared sum of $ai \\times zi$ to the sum of squared differences between the sample values and sample mean. Finally, we compare the test statistic to a critical value to determine whether the residuals follow a normal distribution or not.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            Array of sample data</span>

<span class="sd">    Returns:</span>
<span class="sd">        statistic (float):</span>
<span class="sd">            The test statistic.</span>
<span class="sd">        pvalue (float):</span>
<span class="sd">            The p-value for the hypothesis test.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>
<span class="sd">        Test the null hypothesis that a random sample was drawn from a normal distribution.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;From the `scipy` docs&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">        &gt;&gt;&gt; x = stats.norm.rvs(loc=5, scale=3, size=100, random_state=rng)</span>
<span class="sd">        &gt;&gt;&gt; shapiro_test = stats.shapiro(x)</span>
<span class="sd">        &gt;&gt;&gt; shapiro_test</span>
<span class="sd">        ShapiroResult(statistic=0.9813305735588074, pvalue=0.16855233907699585)</span>
<span class="sd">        &gt;&gt;&gt; shapiro_test.statistic</span>
<span class="sd">        0.9813305735588074</span>
<span class="sd">        &gt;&gt;&gt; shapiro_test.pvalue</span>
<span class="sd">        0.16855233907699585</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        Example one, using the `airline` data from the `sktime` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import shapiro</span>

<span class="sd">        &gt;&gt;&gt; # load the airline data</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>

<span class="sd">        &gt;&gt;&gt; # run the Shapiro-Wilk test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = shapiro(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Shapiro-Wilk test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        Shapiro-Wilk test statistic: 0.910</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Shapiro-Wilk test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        Shapiro-Wilk test p-value: 0.054</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Fail to reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of the Shapiro-Wilk test is that the data _is_ normally distributed. In this case, the p-value is `0.054`, which is **greater** than the significance level of `0.05`, indicating that we _fail_ to reject the null hypothesis. Therefore, we can conclude that the airline data **is** likely normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example two, using the `sine` wave data generated from the `numpy` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import shapiro</span>

<span class="sd">        &gt;&gt;&gt; # generate sine wave data</span>
<span class="sd">        &gt;&gt;&gt; x = np.linspace(0, 2 * np.pi, 100)</span>
<span class="sd">        &gt;&gt;&gt; data = np.sin(x)</span>

<span class="sd">        &gt;&gt;&gt; # run the Shapiro-Wilk test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = shapiro(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Shapiro-Wilk test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Shapiro-Wilk test p-value: {p_value:.3f}&quot;)</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of the Shapiro-Wilk test _is_ that the data is normally distributed. In this case, the p-value is `0.002`, which is **less** than the significance level of `0.05`, indicating that we _can_ reject the null hypothesis. Therefore, we can conclude that the sine wave data is **not** normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example three, using the `FractionalGaussianNoise` random data generated from the `stochastic` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.noise import FractionalGaussianNoise</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import shapiro</span>

<span class="sd">        &gt;&gt;&gt; # Generate Fractional Gaussian Noise</span>
<span class="sd">        &gt;&gt;&gt; fgn = FractionalGaussianNoise(t=1, hurst=0.5, length=100, method=&quot;daviesharte&quot;)</span>
<span class="sd">        &gt;&gt;&gt; data = fgn.sample()</span>

<span class="sd">        &gt;&gt;&gt; # run the Shapiro-Wilk test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = shapiro(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Shapiro-Wilk test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        Shapiro-Wilk test statistic: 0.979</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Shapiro-Wilk test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        Shapiro-Wilk test p-value: 0.417</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Fail to reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of the Shapiro-Wilk test _is_ that the data is normally distributed. In this case, the p-value is `0.417`, which is **greater** than the significance level of `0.05`, indicating that we _fail_ to reject the null hypothesis. Therefore, we can conclude that the random noise generated by the `FractionalGaussianNoise` class **is** likely normally distributed.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        The algorithm used is described in (Algorithm as R94 Appl. Statist. (1995)) but censoring parameters as described are not implemented. For $N &gt; 5000$ the $W$ test statistic is accurate but the $p-value$ may not be.</span>

<span class="sd">        The chance of rejecting the null hypothesis when it is true is close to $5%$ regardless of sample size.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        - All credit goes to the [`scipy`](https://docs.scipy.org/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</span>
<span class="sd">        - Shapiro, S. S. &amp; Wilk, M.B (1965). An analysis of variance test for normality (complete samples), Biometrika, Vol. 52, pp. 591-611.</span>
<span class="sd">        - Razali, N. M. &amp; Wah, Y. B. (2011) Power comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests, Journal of Statistical Modeling and Analytics, Vol. 2, pp. 21-33.</span>
<span class="sd">        - Algorithm as R94 Appl. Statist. (1995) VOL. 44, NO. 4.</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`jb()`][ts_stat_tests.algorithms.normality.jb]</span>
<span class="sd">        - [`ob()`][ts_stat_tests.algorithms.normality.ob]</span>
<span class="sd">        - [`dp()`][ts_stat_tests.algorithms.normality.dp]</span>
<span class="sd">        - [`ad()`][ts_stat_tests.algorithms.normality.ad]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_sw</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.normality.dp" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">dp</span>


<a href="#ts_stat_tests.algorithms.normality.dp" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">dp</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="nb">tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">]],</span>
    <span class="n">NormaltestResult</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>The D'Agostino and Pearson's test is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. In time series forecasting, the D'Agostino and Pearson's test can be used to assess whether the residuals of a model follow a normal distribution, which is an assumption of many statistical models.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The D'Agostino and Pearson's test uses a combination of skewness and kurtosis measures to assess whether the residuals follow a normal distribution. Skewness measures the degree of asymmetry in the distribution of the residuals, while kurtosis measures the degree of peakedness or flatness. If the residuals follow a normal distribution, their skewness and kurtosis should be close to zero.</p>
<p>To apply the D'Agostino and Pearson's test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the test on the residuals. The test produces a test statistic that compares the observed skewness and kurtosis values to the expected values under the null hypothesis of normality. If the observed values deviate significantly from the expected values under normality, the test rejects the null hypothesis and concludes that the residuals do not follow a normal distribution.</p>
<p>The D'Agostino and Pearson's test produces a p-value, which indicates the probability of observing the observed test statistic if the null hypothesis of normality is true. If the p-value is less than the significance level (usually 0.05), we can conclude that the residuals do not follow a normal distribution.</p>
<p>If the D'Agostino and Pearson's test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array containing the sample to be tested.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axis along which to compute test. If <code>None</code>, compute over the whole array <code>a</code>.<br>
Defaults to <code>0</code>.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nan_policy</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_DP_NAN_POLICY_OPTIONS">VALID_DP_NAN_POLICY_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Defines how to handle when input contains nan. The following options are available (default is 'propagate'):</p>
<ul>
<li>'propagate': returns nan</li>
<li>'raise': throws an error</li>
<li>'omit': performs the calculations ignoring nan values.</li>
</ul>
<p>Defaults to <code>"propagate"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;propagate&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>statistic</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="np.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Value <span class="arithmatex">\(s^2 + k^2\)</span>, where <span class="arithmatex">\(s\)</span> is the z-score returned by <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html"><code>skewtest</code></a> and <span class="arithmatex">\(k\)</span> is the z-score returned by <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosistest.html"><code>kurtosistest</code></a>.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>pvalue</code></td>            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="np.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A 2-sided chi-squared probability for the hypothesis test.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<p>Test the null hypothesis that a random sample was drawn from a normal distribution.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">From the `scipy` docs</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pts</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">pts</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">pts</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k2</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">normaltest</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;p = </span><span class="si">{:g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="go">p = 8.4713e-19</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>  <span class="c1"># null hypothesis: x comes from a normal distribution</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The null hypothesis can be rejected&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The null hypothesis cannot be rejected&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">&quot;The null hypothesis can be rejected&quot;</span>
</code></pre></div></td></tr></table></div>
<hr />
<p>Example one, using the <code>airline</code> data from the <code>sktime</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">normaltest</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load the airline data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run D&#39;Agostino and Pearson&#39;s test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">normaltest</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;D&#39;Agostino and Pearson&#39;s test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">D&#39;Agostino and Pearson&#39;s test statistic: 7.764</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;D&#39;Agostino and Pearson&#39;s test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">D&#39;Agostino and Pearson&#39;s test p-value: 0.021</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of D'Agostino and Pearson's test is that the data <em>is</em> normally distributed. In this case, the p-value is <code>0.021</code>, which is <strong>less</strong> than the significance level of <code>0.05</code>, indicating that we <em>can</em> reject the null hypothesis. Therefore, we can conclude that the airline data from the sktime library is <strong>not</strong> normally distributed.</p>
<hr />
<p>Example two, using the <code>sine</code> wave data generated from the <code>numpy</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">normaltest</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate sine wave data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run D&#39;Agostino and Pearson&#39;s test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">normaltest</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;D&#39;Agostino and Pearson&#39;s test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">D&#39;Agostino and Pearson&#39;s test statistic: 50.583</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;D&#39;Agostino and Pearson&#39;s test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">D&#39;Agostino and Pearson&#39;s test p-value: 0.000</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of D'Agostino and Pearson's test is that the data <em>is</em> normally distributed. In this case, the p-value is <code>0.000</code>, which is <strong>less</strong> than the significance level of <code>0.05</code>, indicating that we <em>can</em> reject the null hypothesis. Therefore, we can conclude that the sine wave data generated from the numpy library is <strong>not</strong> normally distributed.</p>
<hr />
<p>Example three, using the <code>FractionalGaussianNoise</code> random data generated from the <code>stochastic</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic</span><span class="w"> </span><span class="kn">import</span> <span class="n">FractionalGaussianNoise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">normaltest</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate random noise using FractionalGaussianNoise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fgn</span> <span class="o">=</span> <span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">H</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">fgn</span><span class="o">.</span><span class="n">generate</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run D&#39;Agostino and Pearson&#39;s test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">normaltest</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;D&#39;Agostino and Pearson&#39;s test statistic: </span><span class="si">{</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">D&#39;Agostino and Pearson&#39;s test statistic: 0.388</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;D&#39;Agostino and Pearson&#39;s test p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">D&#39;Agostino and Pearson&#39;s test p-value: 0.823</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Fail to reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of D'Agostino and Pearson's test is that the data <em>is</em> normally distributed. In this case, the p-value is <code>0.823</code>, which is <em>greater</em> than the significance level of <code>0.05</code>, indicating that we <em>fail</em> to reject the null hypothesis. Therefore, we can conclude that the random noise generated by the FractionalGaussianNoise class from the stochastic library <em>is</em> likely normally distributed.</p>
</details>
<details class="note">
<summary>Notes</summary>
<p>This function is a wrapper for the <code>scipy.stats.normaltest</code> function.</p>
<p>The D'Agostino and Pearson's test is a statistical test used to determine if a dataset, including time series data, is normally distributed. The test is based on the sample skewness and sample kurtosis of the dataset. The mathematical equation for the D'Agostino and Pearson's test is:</p>
<div class="arithmatex">\[
D^2 = \left( \frac{n+1}{6} \right) \times \left( S^2 + K^2 \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(D^2\)</span> is the test statistic</li>
<li><span class="arithmatex">\(n\)</span> is the sample size</li>
<li><span class="arithmatex">\(S\)</span> is the sample skewness</li>
<li><span class="arithmatex">\(K\)</span> is the sample kurtosis</li>
</ul>
<p>To calculate the D'Agostino and Pearson's test statistic for time series data, we need to perform the following steps:</p>
<ol>
<li>
<p>Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</p>
</li>
<li>
<p>Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</p>
</li>
<li>
<p>Standardize the residuals: The standardized residuals are the residuals divided by their sample standard deviation.</p>
</li>
<li>
<p>Calculate the sample skewness: The sample skewness is a measure of the asymmetry of the distribution of the residuals. It is calculated as:</p>
<div class="arithmatex">\[
S = \left( \frac {n} {(n-1) \times (n-2)} \right) \times \left( \frac {\sum_{i=1}^{n}(x_i - \bar{x})^3 } { s^3 } \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(x_i\)</span> are the standardized residuals,</li>
<li><span class="arithmatex">\(\bar{x}\)</span> is their mean,</li>
<li><span class="arithmatex">\(s\)</span> is their standard deviation, and</li>
<li><span class="arithmatex">\(n\)</span> is the sample size.</li>
</ul>
</li>
<li>
<p>Calculate the sample kurtosis: The sample kurtosis is a measure of the "peakedness" of the distribution of the residuals. It is calculated as:</p>
<div class="arithmatex">\[
K = \left( \frac { n \times (n+1) } { (n-1) \times (n-2) \times (n-3) } \right) \times \left( \frac { \sum_{i=1}^{n} (x_i - \bar{x})^4 } { s^4 } \right) - \left( \frac { 3 \times (n-1)^2 } { (n-2) \times (n-3) } \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(x_i\)</span> are the standardized residuals,</li>
<li><span class="arithmatex">\(\bar{x}\)</span> is their mean,</li>
<li><span class="arithmatex">\(s\)</span> is their standard deviation, and</li>
<li><span class="arithmatex">\(n\)</span> is the sample size.</li>
</ul>
</li>
<li>
<p>Calculate the test statistic: The test statistic is calculated using the formula:</p>
<div class="arithmatex">\[
D^2 = \left( \frac { n+1 } {6} \right) \times \left( S^2 + K^2 \right)
\]</div>
</li>
<li>
<p>Compare the test statistic to a critical value: If the test statistic is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution. If the test statistic is greater than the critical value, we reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution.</p>
</li>
</ol>
<p>In summary, the D'Agostino and Pearson's test is a statistical test that evaluates normality of time series residuals by standardizing the residuals, calculating their sample skewness and sample kurtosis, and computing the test statistic using a formula that takes into account both skewness and kurtosis. Finally, we compare the test statistic to a critical value to determine whether the residuals follow a normal distribution or not.</p>
</details>
<details class="success">
<summary>Credit</summary>
<ul>
<li>All credit goes to the <a href="https://docs.scipy.org/"><code>scipy</code></a> library.</li>
</ul>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>D'Agostino, R. B. (1971), "An omnibus test of normality for moderate and large sample size", Biometrika, 58, 341-348</li>
<li>D'Agostino, R. and Pearson, E. S. (1973), "Tests for departure from normality", Biometrika, 60, 613-622</li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            jb" href="#ts_stat_tests.algorithms.normality.jb"><code>jb()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ob" href="#ts_stat_tests.algorithms.normality.ob"><code>ob()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sw" href="#ts_stat_tests.algorithms.normality.sw"><code>sw()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ad" href="#ts_stat_tests.algorithms.normality.ad"><code>ad()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">dp</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">nan_policy</span><span class="p">:</span> <span class="n">VALID_DP_NAN_POLICY_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;propagate&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="nb">tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ArrayLike</span><span class="p">]],</span>
    <span class="n">NormaltestResult</span><span class="p">,</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        The D&#39;Agostino and Pearson&#39;s test is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. In time series forecasting, the D&#39;Agostino and Pearson&#39;s test can be used to assess whether the residuals of a model follow a normal distribution, which is an assumption of many statistical models.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The D&#39;Agostino and Pearson&#39;s test uses a combination of skewness and kurtosis measures to assess whether the residuals follow a normal distribution. Skewness measures the degree of asymmetry in the distribution of the residuals, while kurtosis measures the degree of peakedness or flatness. If the residuals follow a normal distribution, their skewness and kurtosis should be close to zero.</span>

<span class="sd">        To apply the D&#39;Agostino and Pearson&#39;s test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the test on the residuals. The test produces a test statistic that compares the observed skewness and kurtosis values to the expected values under the null hypothesis of normality. If the observed values deviate significantly from the expected values under normality, the test rejects the null hypothesis and concludes that the residuals do not follow a normal distribution.</span>

<span class="sd">        The D&#39;Agostino and Pearson&#39;s test produces a p-value, which indicates the probability of observing the observed test statistic if the null hypothesis of normality is true. If the p-value is less than the significance level (usually 0.05), we can conclude that the residuals do not follow a normal distribution.</span>

<span class="sd">        If the D&#39;Agostino and Pearson&#39;s test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The array containing the sample to be tested.</span>
<span class="sd">        axis (int):</span>
<span class="sd">            Axis along which to compute test. If `None`, compute over the whole array `a`.&lt;br&gt;</span>
<span class="sd">            Defaults to `0`.</span>
<span class="sd">        nan_policy (VALID_DP_NAN_POLICY_OPTIONS):</span>
<span class="sd">            Defines how to handle when input contains nan. The following options are available (default is &#39;propagate&#39;):</span>

<span class="sd">            - &#39;propagate&#39;: returns nan</span>
<span class="sd">            - &#39;raise&#39;: throws an error</span>
<span class="sd">            - &#39;omit&#39;: performs the calculations ignoring nan values.</span>

<span class="sd">            Defaults to `&quot;propagate&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        statistic (Union[float, np.ndarray]):</span>
<span class="sd">            Value $s^2 + k^2$, where $s$ is the z-score returned by [`skewtest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html) and $k$ is the z-score returned by [`kurtosistest`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosistest.html).</span>
<span class="sd">        pvalue (Union[float, np.ndarray]):</span>
<span class="sd">            A 2-sided chi-squared probability for the hypothesis test.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        Test the null hypothesis that a random sample was drawn from a normal distribution.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;From the `scipy` docs&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy import stats</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">        &gt;&gt;&gt; pts = 1000</span>
<span class="sd">        &gt;&gt;&gt; a = rng.normal(0, 1, size=pts)</span>
<span class="sd">        &gt;&gt;&gt; b = rng.normal(2, 1, size=pts)</span>
<span class="sd">        &gt;&gt;&gt; x = np.concatenate((a, b))</span>
<span class="sd">        &gt;&gt;&gt; k2, p = stats.normaltest(x)</span>
<span class="sd">        &gt;&gt;&gt; alpha = 1e-3</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;p = {:g}&quot;.format(p))</span>
<span class="sd">        p = 8.4713e-19</span>
<span class="sd">        &gt;&gt;&gt; if p &lt; alpha:  # null hypothesis: x comes from a normal distribution</span>
<span class="sd">        ...     print(&quot;The null hypothesis can be rejected&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;The null hypothesis cannot be rejected&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        &quot;The null hypothesis can be rejected&quot;</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        Example one, using the `airline` data from the `sktime` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import normaltest</span>

<span class="sd">        &gt;&gt;&gt; # load the airline data</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>

<span class="sd">        &gt;&gt;&gt; # run D&#39;Agostino and Pearson&#39;s test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = normaltest(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;D&#39;Agostino and Pearson&#39;s test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        D&#39;Agostino and Pearson&#39;s test statistic: 7.764</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;D&#39;Agostino and Pearson&#39;s test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        D&#39;Agostino and Pearson&#39;s test p-value: 0.021</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of D&#39;Agostino and Pearson&#39;s test is that the data _is_ normally distributed. In this case, the p-value is `0.021`, which is **less** than the significance level of `0.05`, indicating that we _can_ reject the null hypothesis. Therefore, we can conclude that the airline data from the sktime library is **not** normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example two, using the `sine` wave data generated from the `numpy` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import normaltest</span>

<span class="sd">        &gt;&gt;&gt; # generate sine wave data</span>
<span class="sd">        &gt;&gt;&gt; data = np.sin(np.linspace(0, 2 * np.pi, num=100))</span>

<span class="sd">        &gt;&gt;&gt; # run D&#39;Agostino and Pearson&#39;s test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = normaltest(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;D&#39;Agostino and Pearson&#39;s test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        D&#39;Agostino and Pearson&#39;s test statistic: 50.583</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;D&#39;Agostino and Pearson&#39;s test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        D&#39;Agostino and Pearson&#39;s test p-value: 0.000</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of D&#39;Agostino and Pearson&#39;s test is that the data _is_ normally distributed. In this case, the p-value is `0.000`, which is **less** than the significance level of `0.05`, indicating that we _can_ reject the null hypothesis. Therefore, we can conclude that the sine wave data generated from the numpy library is **not** normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example three, using the `FractionalGaussianNoise` random data generated from the `stochastic` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from stochastic import FractionalGaussianNoise</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import normaltest</span>

<span class="sd">        &gt;&gt;&gt; # generate random noise using FractionalGaussianNoise</span>
<span class="sd">        &gt;&gt;&gt; fgn = FractionalGaussianNoise(H=0.7, length=100)</span>
<span class="sd">        &gt;&gt;&gt; data = fgn.generate()</span>

<span class="sd">        &gt;&gt;&gt; # run D&#39;Agostino and Pearson&#39;s test on the data</span>
<span class="sd">        &gt;&gt;&gt; statistic, p_value = normaltest(data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;D&#39;Agostino and Pearson&#39;s test statistic: {statistic:.3f}&quot;)</span>
<span class="sd">        D&#39;Agostino and Pearson&#39;s test statistic: 0.388</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;D&#39;Agostino and Pearson&#39;s test p-value: {p_value:.3f}&quot;)</span>
<span class="sd">        D&#39;Agostino and Pearson&#39;s test p-value: 0.823</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if p_value &lt; alpha:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Fail to reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of D&#39;Agostino and Pearson&#39;s test is that the data _is_ normally distributed. In this case, the p-value is `0.823`, which is *greater* than the significance level of `0.05`, indicating that we _fail_ to reject the null hypothesis. Therefore, we can conclude that the random noise generated by the FractionalGaussianNoise class from the stochastic library *is* likely normally distributed.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        This function is a wrapper for the `scipy.stats.normaltest` function.</span>

<span class="sd">        The D&#39;Agostino and Pearson&#39;s test is a statistical test used to determine if a dataset, including time series data, is normally distributed. The test is based on the sample skewness and sample kurtosis of the dataset. The mathematical equation for the D&#39;Agostino and Pearson&#39;s test is:</span>

<span class="sd">        $$</span>
<span class="sd">        D^2 = \\left( \\frac{n+1}{6} \\right) \\times \\left( S^2 + K^2 \\right)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $D^2$ is the test statistic</span>
<span class="sd">        - $n$ is the sample size</span>
<span class="sd">        - $S$ is the sample skewness</span>
<span class="sd">        - $K$ is the sample kurtosis</span>

<span class="sd">        To calculate the D&#39;Agostino and Pearson&#39;s test statistic for time series data, we need to perform the following steps:</span>

<span class="sd">        1. Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</span>

<span class="sd">        1. Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</span>

<span class="sd">        1. Standardize the residuals: The standardized residuals are the residuals divided by their sample standard deviation.</span>

<span class="sd">        1. Calculate the sample skewness: The sample skewness is a measure of the asymmetry of the distribution of the residuals. It is calculated as:</span>

<span class="sd">            $$</span>
<span class="sd">            S = \\left( \\frac {n} {(n-1) \\times (n-2)} \\right) \\times \\left( \\frac {\\sum_{i=1}^{n}(x_i - \\bar{x})^3 } { s^3 } \\right)</span>
<span class="sd">            $$</span>

<span class="sd">            where:</span>

<span class="sd">            - $x_i$ are the standardized residuals,</span>
<span class="sd">            - $\\bar{x}$ is their mean,</span>
<span class="sd">            - $s$ is their standard deviation, and</span>
<span class="sd">            - $n$ is the sample size.</span>

<span class="sd">        1. Calculate the sample kurtosis: The sample kurtosis is a measure of the &quot;peakedness&quot; of the distribution of the residuals. It is calculated as:</span>

<span class="sd">            $$</span>
<span class="sd">            K = \\left( \\frac { n \\times (n+1) } { (n-1) \\times (n-2) \\times (n-3) } \\right) \\times \\left( \\frac { \\sum_{i=1}^{n} (x_i - \\bar{x})^4 } { s^4 } \\right) - \\left( \\frac { 3 \\times (n-1)^2 } { (n-2) \\times (n-3) } \\right)</span>
<span class="sd">            $$</span>

<span class="sd">            where:</span>

<span class="sd">            - $x_i$ are the standardized residuals,</span>
<span class="sd">            - $\\bar{x}$ is their mean,</span>
<span class="sd">            - $s$ is their standard deviation, and</span>
<span class="sd">            - $n$ is the sample size.</span>

<span class="sd">        1. Calculate the test statistic: The test statistic is calculated using the formula:</span>

<span class="sd">            $$</span>
<span class="sd">            D^2 = \\left( \\frac { n+1 } {6} \\right) \\times \\left( S^2 + K^2 \\right)</span>
<span class="sd">            $$</span>

<span class="sd">        1. Compare the test statistic to a critical value: If the test statistic is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution. If the test statistic is greater than the critical value, we reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution.</span>

<span class="sd">        In summary, the D&#39;Agostino and Pearson&#39;s test is a statistical test that evaluates normality of time series residuals by standardizing the residuals, calculating their sample skewness and sample kurtosis, and computing the test statistic using a formula that takes into account both skewness and kurtosis. Finally, we compare the test statistic to a critical value to determine whether the residuals follow a normal distribution or not.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        - All credit goes to the [`scipy`](https://docs.scipy.org/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - D&#39;Agostino, R. B. (1971), &quot;An omnibus test of normality for moderate and large sample size&quot;, Biometrika, 58, 341-348</span>
<span class="sd">        - D&#39;Agostino, R. and Pearson, E. S. (1973), &quot;Tests for departure from normality&quot;, Biometrika, 60, 613-622</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`jb()`][ts_stat_tests.algorithms.normality.jb]</span>
<span class="sd">        - [`ob()`][ts_stat_tests.algorithms.normality.ob]</span>
<span class="sd">        - [`sw()`][ts_stat_tests.algorithms.normality.sw]</span>
<span class="sd">        - [`ad()`][ts_stat_tests.algorithms.normality.ad]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_dp</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="n">nan_policy</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.normality.ad" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">ad</span>


<a href="#ts_stat_tests.algorithms.normality.ad" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">ad</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span> <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AndersonResult</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>The Anderson-Darling test is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. In time series forecasting, the Anderson-Darling test can be used to assess whether the residuals of a model follow a normal distribution, which is an assumption of many statistical models.</p>
<p>The Anderson-Darling test tests the null hypothesis that a sample is drawn from a population that follows a particular distribution. For the Anderson-Darling test, the critical values depend on which distribution is being tested against. This function works for normal, exponential, logistic, or Gumbel (Extreme Value Type I) distributions.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The Anderson-Darling test is based on the null hypothesis that the residuals of the forecasting model are normally distributed. The test calculates a test statistic that measures the distance between the observed distribution of the residuals and the expected distribution under the null hypothesis of normality. If the observed distribution of the residuals deviates significantly from the expected distribution under normality, the test rejects the null hypothesis and concludes that the residuals do not follow a normal distribution.</p>
<p>To apply the Anderson-Darling test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the test on the residuals. The test produces a p-value, which indicates the probability of observing the observed distribution of the residuals if the null hypothesis of normality is true. If the p-value is less than the significance level (usually <span class="arithmatex">\(0.05\)</span>), we can conclude that the residuals do not follow a normal distribution.</p>
<p>The Anderson-Darling test is more sensitive to deviations from normality in the tails of the distribution than other tests, such as the Shapiro-Wilk test. This makes it a useful test when assessing whether the residuals of a time series forecasting model exhibit heavy tails or other non-normal features.</p>
<p>If the Anderson-Darling test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Array of sample data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dist</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.normality.VALID_AD_DIST_OPTIONS">VALID_AD_DIST_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The type of distribution to test against. The default is <code>'norm'</code>. The names <code>'extreme1'</code>, <code>'gumbel_l'</code> and <code>'gumbel'</code> are synonyms for the same distribution.<br>
Defaults to <code>"norm"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;norm&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>statistic</code></td>            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Anderson-Darling test statistic.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>critical_values</code></td>            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The critical values for this distribution.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>significance_level</code></td>            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The significance levels for the corresponding critical values in percents. The function returns critical values for a differing set of significance levels depending on the distribution that is being tested against.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>fit_result</code></td>            <td>
                  <code><span title="Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An object containing the results of fitting the distribution to the data.
Note that the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats._result_classes.FitResult.html"><code>FitResult</code></a> class was added to SciPy in version <code>1.10.0</code>. In the same release, this <code>anderson</code> function from SciPy had the outputs extended to include the <code>fit_result</code> object. The SciPy version <code>1.10.0</code> requires Python version <code>&gt;=3.8</code>.<br><br>Therefore, when this function is executed on Python <code>3.7</code>, it will default to the highest compatible SciPy version, which is <code>1.7.0</code>. Hence, to ensure that this algorithm can still be used in Python <code>3.7</code>, the type of this output object is changed to <code>Any</code>, and is only returned when the Python version is <code>&gt;=3.8</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<p>Test the null hypothesis that a random sample was drawn from a normal distribution (with unspecified mean and standard deviation).</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">From the `scipy` docs</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">anderson</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">anderson</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.8398018749744764</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">critical_values</span>
<span class="go">array([0.527, 0.6  , 0.719, 0.839, 0.998])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">significance_level</span>
<span class="go">array([15. , 10. ,  5. ,  2.5,  1. ])</span>
</code></pre></div></td></tr></table></div>
<p>The value of the statistic (barely) exceeds the critical value associated with a significance level of <span class="arithmatex">\(2.5%\)</span>, so the null hypothesis may be rejected at a significance level of <span class="arithmatex">\(2.5%\)</span>, but not at a significance level of <span class="arithmatex">\(1%\)</span>.</p>
<hr />
<p>Example one, using the <code>airline</code> data from the <code>sktime</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">anderson</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># load the airline data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">airline_data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># run Anderson-Darling test on the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">anderson</span><span class="p">(</span><span class="n">airline_data</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the results</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Anderson-Darling test statistic: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">statistic</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Anderson-Darling test statistic: 3.089</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Anderson-Darling test critical values: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Anderson-Darling test critical values: [0.565 0.644 0.772 0.901 1.072]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Anderson-Darling test significance levels: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">significance_level</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Anderson-Darling test significance levels: [15.  10.   5.   2.5  1. ]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># check if null hypothesis is rejected</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">statistic</span> <span class="o">&gt;</span> <span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fail to reject null hypothesis that data is normally distributed&quot;</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">Reject null hypothesis that data is normally distributed</span>
</code></pre></div></td></tr></table></div>
<p>The null hypothesis of Anderson-Darling test is that the data is normally distributed. In this case, the test statistic is 3.089, which is greater than the critical value at 5% significance level of 0.772, indicating that we reject the null hypothesis. Therefore, we can conclude that the airline data from the sktime library is not normally distributed.</p>
<hr />
<p>Example two, using the <code>sine</code> wave data generated from the <code>numpy</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Import packages</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">anderson</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sine wave data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Perform Anderson-Darling test</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">anderson</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Statistic: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">result</span><span class="o">.</span><span class="n">statistic</span><span class="p">)</span>
<span class="go">Statistic: 0.161</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="p">)):</span>
<span class="gp">... </span>    <span class="n">sl</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">significance_level</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="gp">... </span>    <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">statistic</span> <span class="o">&lt;</span> <span class="n">cv</span><span class="p">:</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%.3f</span><span class="s2">: </span><span class="si">%.3f</span><span class="s2">, data looks normal (fail to reject H0)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sl</span><span class="p">,</span> <span class="n">cv</span><span class="p">))</span>
<span class="gp">... </span>    <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%.3f</span><span class="s2">: </span><span class="si">%.3f</span><span class="s2">, data does not look normal (reject H0)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sl</span><span class="p">,</span> <span class="n">cv</span><span class="p">))</span>
<span class="gp">...</span>
<span class="go">15.000: 0.561, data looks normal (fail to reject H0)</span>
<span class="go">10.000: 0.638, data looks normal (fail to reject H0)</span>
<span class="go">5.000: 0.765, data looks normal (fail to reject H0)</span>
<span class="go">2.500: 0.892, data looks normal (fail to reject H0)</span>
<span class="go">1.000: 1.061, data looks normal (fail to reject H0)</span>
</code></pre></div></td></tr></table></div>
<p>In this case, the Anderson-Darling test statistic is 0.161. The critical values and significance levels are also printed. The null hypothesis is that the data is drawn from a normal distribution. Based on the output, we can see that the statistic value is less than all of the critical values for the chosen significance levels, meaning we fail to reject the null hypothesis. Therefore, we can conclude that the sine wave data generated from NumPy is normally distributed.</p>
<hr />
<p>Example three, using the <code>FractionalGaussianNoise</code> random data generated from the <code>stochastic</code> package.</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Python</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.noise</span><span class="w"> </span><span class="kn">import</span> <span class="n">FractionalGaussianNoise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">anderson</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate fractional Gaussian noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fgn</span> <span class="o">=</span> <span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># calculate the anderson-darling test</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">anderson</span><span class="p">(</span><span class="n">fgn</span><span class="o">.</span><span class="n">fgn</span><span class="p">(),</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># print the result</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Statistic: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">result</span><span class="o">.</span><span class="n">statistic</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="p">)):</span>
<span class="gp">... </span>    <span class="n">sl</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">significance_level</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="gp">... </span>    <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">statistic</span> <span class="o">&lt;</span> <span class="n">result</span><span class="o">.</span><span class="n">critical_values</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%.3f</span><span class="s2">: </span><span class="si">%.3f</span><span class="s2">, data looks normal (fail to reject H0)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sl</span><span class="p">,</span> <span class="n">cv</span><span class="p">))</span>
<span class="gp">... </span>    <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%.3f</span><span class="s2">: </span><span class="si">%.3f</span><span class="s2">, data does not look normal (reject H0)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sl</span><span class="p">,</span> <span class="n">cv</span><span class="p">))</span>
<span class="gp">...</span>
</code></pre></div></td></tr></table></div>
<p>In this example, the test statistic is 1.171, and the critical values at different significance levels are 0.570, 0.648, 0.777, 0.906, and 1.076. Since the test statistic is greater than all of the critical values, we can reject the null hypothesis and conclude that the data is not normally distributed.</p>
</details>
<details class="note">
<summary>Notes</summary>
<p>Critical values provided are for the following significance levels:</p>
<ul>
<li>normal/exponential<ul>
<li>15%, 10%, 5%, 2.5%, 1%</li>
</ul>
</li>
<li>logistic<ul>
<li>25%, 10%, 5%, 2.5%, 1%, 0.5%</li>
</ul>
</li>
<li>Gumbel<ul>
<li>25%, 10%, 5%, 2.5%, 1%</li>
</ul>
</li>
</ul>
<p>If the returned statistic is larger than these critical values then for the corresponding significance level, the null hypothesis that the data come from the chosen distribution can be rejected. The returned statistic is referred to as 'A2' in the references.</p>
<p>The Anderson-Darling test is a statistical test used to determine whether a dataset, including time series data, is normally distributed. The test is based on the deviations of the sample distribution from the theoretical normal distribution. The mathematical equation for the Anderson-Darling test is:</p>
<div class="arithmatex">\[
A^2 = -n - \sum_{i=1}^{n} \left( \left( \frac{2 \times i - 1}{n} \right) \times (log(F(x_i)) + log(1-F(n-i+1))) \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(A^2\)</span> is the test statistic</li>
<li><span class="arithmatex">\(n\)</span> is the sample size</li>
<li><span class="arithmatex">\(F(x_i)\)</span> is the empirical distribution function of the sample at <span class="arithmatex">\(x_i\)</span></li>
<li><span class="arithmatex">\(log\)</span> is a natural logarithm</li>
</ul>
<p>To calculate the Anderson-Darling test statistic for time series data, we need to perform the following steps:</p>
<ol>
<li>
<p>Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</p>
</li>
<li>
<p>Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</p>
</li>
<li>
<p>Standardize the residuals: The standardized residuals are the residuals divided by their sample standard deviation.</p>
</li>
<li>
<p>Sort the standardized residuals in ascending order.</p>
</li>
<li>
<p>Calculate the empirical distribution function (EDF) of the residuals: The EDF is the proportion of the standardized residuals that are less than or equal to a given value. It is calculated as:</p>
<div class="arithmatex">\[
F(x_i) = \left( \frac{1}{n} \right) \times \sum_{j=1}^{n} \left( I(x_i &lt;= x_j) \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(x_i\)</span> are the sorted standardized residuals,</li>
<li><span class="arithmatex">\(x_j\)</span> are the sample values, and</li>
<li><span class="arithmatex">\(I()\)</span> is the indicator function.</li>
</ul>
</li>
<li>
<p>Calculate the test statistic: The test statistic is calculated using the formula:</p>
<div class="arithmatex">\[
A^2 = -n - \sum_{i=1}^{n} \left( \left( \frac{2 \times i - 1}{n} \right) \times (log(F(x_i)) + log(1-F(n-i+1))) \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(x_i\)</span> are the sorted standardized residuals.</li>
</ul>
</li>
<li>
<p>Compare the test statistic to a critical value: If the test statistic is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution. If the test statistic is greater than the critical value, we reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution.</p>
</li>
</ol>
<p>In summary, the Anderson-Darling test is a statistical test that evaluates normality of time series residuals by comparing the empirical distribution function of the sample data to the cumulative distribution function of the normal distribution. The test statistic is calculated by summing the product of weights and logarithms of the empirical distribution function and the complement of the normal distribution CDF. Finally, we compare the test statistic to a critical value to determine whether the residuals follow a normal distribution or not.</p>
</details>
<details class="success">
<summary>Credit</summary>
<ul>
<li>All credit goes to the <a href="https://docs.scipy.org/"><code>scipy</code></a> library.</li>
</ul>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm">https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</a></li>
<li>Stephens, M. A. (1974). EDF Statistics for Goodness of Fit and Some Comparisons, Journal of the American Statistical Association, Vol. 69, pp. 730-737.</li>
<li>Stephens, M. A. (1976). Asymptotic Results for Goodness-of-Fit Statistics with Unknown Parameters, Annals of Statistics, Vol. 4, pp. 357-369.</li>
<li>Stephens, M. A. (1977). Goodness of Fit for the Extreme Value Distribution, Biometrika, Vol. 64, pp. 583-588.</li>
<li>Stephens, M. A. (1977). Goodness of Fit with Special Reference to Tests for Exponentiality , Technical Report No. 262, Department of Statistics, Stanford University, Stanford, CA.</li>
<li>Stephens, M. A. (1979). Tests of Fit for the Logistic Distribution Based on the Empirical Distribution Function, Biometrika, Vol. 66, pp. 591-595.</li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            jb" href="#ts_stat_tests.algorithms.normality.jb"><code>jb()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            ob" href="#ts_stat_tests.algorithms.normality.ob"><code>ob()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sw" href="#ts_stat_tests.algorithms.normality.sw"><code>sw()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            dp" href="#ts_stat_tests.algorithms.normality.dp"><code>dp()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/normality.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ad</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">dist</span><span class="p">:</span> <span class="n">VALID_AD_DIST_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AndersonResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        The Anderson-Darling test is a statistical test used to evaluate whether a dataset, including time series data, follows a normal distribution. In time series forecasting, the Anderson-Darling test can be used to assess whether the residuals of a model follow a normal distribution, which is an assumption of many statistical models.</span>

<span class="sd">        The Anderson-Darling test tests the null hypothesis that a sample is drawn from a population that follows a particular distribution. For the Anderson-Darling test, the critical values depend on which distribution is being tested against. This function works for normal, exponential, logistic, or Gumbel (Extreme Value Type I) distributions.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The Anderson-Darling test is based on the null hypothesis that the residuals of the forecasting model are normally distributed. The test calculates a test statistic that measures the distance between the observed distribution of the residuals and the expected distribution under the null hypothesis of normality. If the observed distribution of the residuals deviates significantly from the expected distribution under normality, the test rejects the null hypothesis and concludes that the residuals do not follow a normal distribution.</span>

<span class="sd">        To apply the Anderson-Darling test to time series data, we first need to estimate the residuals of the forecasting model. We can then use a statistical software package to perform the test on the residuals. The test produces a p-value, which indicates the probability of observing the observed distribution of the residuals if the null hypothesis of normality is true. If the p-value is less than the significance level (usually $0.05$), we can conclude that the residuals do not follow a normal distribution.</span>

<span class="sd">        The Anderson-Darling test is more sensitive to deviations from normality in the tails of the distribution than other tests, such as the Shapiro-Wilk test. This makes it a useful test when assessing whether the residuals of a time series forecasting model exhibit heavy tails or other non-normal features.</span>

<span class="sd">        If the Anderson-Darling test indicates that the residuals do not follow a normal distribution, we may need to consider using a different modeling approach or modifying the forecasting model. It is important to ensure that the residuals of a time series forecasting model follow a normal distribution to ensure that the model is valid and reliable for making predictions.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            Array of sample data.</span>
<span class="sd">        dist (VALID_AD_DIST_OPTIONS):</span>
<span class="sd">            The type of distribution to test against. The default is `&#39;norm&#39;`. The names `&#39;extreme1&#39;`, `&#39;gumbel_l&#39;` and `&#39;gumbel&#39;` are synonyms for the same distribution.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;norm&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        statistic (float):</span>
<span class="sd">            The Anderson-Darling test statistic.</span>
<span class="sd">        critical_values (list):</span>
<span class="sd">            The critical values for this distribution.</span>
<span class="sd">        significance_level (list):</span>
<span class="sd">            The significance levels for the corresponding critical values in percents. The function returns critical values for a differing set of significance levels depending on the distribution that is being tested against.</span>
<span class="sd">        fit_result (Any):</span>
<span class="sd">            An object containing the results of fitting the distribution to the data.</span>
<span class="sd">            Note that the [`FitResult`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats._result_classes.FitResult.html) class was added to SciPy in version `1.10.0`. In the same release, this `anderson` function from SciPy had the outputs extended to include the `fit_result` object. The SciPy version `1.10.0` requires Python version `&gt;=3.8`.&lt;br&gt;&lt;br&gt;Therefore, when this function is executed on Python `3.7`, it will default to the highest compatible SciPy version, which is `1.7.0`. Hence, to ensure that this algorithm can still be used in Python `3.7`, the type of this output object is changed to `Any`, and is only returned when the Python version is `&gt;=3.8`.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        Test the null hypothesis that a random sample was drawn from a normal distribution (with unspecified mean and standard deviation).</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;From the `scipy` docs&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import anderson</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng()</span>
<span class="sd">        &gt;&gt;&gt; data = rng.random(size=35)</span>
<span class="sd">        &gt;&gt;&gt; res = anderson(data)</span>
<span class="sd">        &gt;&gt;&gt; res.statistic</span>
<span class="sd">        0.8398018749744764</span>
<span class="sd">        &gt;&gt;&gt; res.critical_values</span>
<span class="sd">        array([0.527, 0.6  , 0.719, 0.839, 0.998])</span>
<span class="sd">        &gt;&gt;&gt; res.significance_level</span>
<span class="sd">        array([15. , 10. ,  5. ,  2.5,  1. ])</span>
<span class="sd">        ```</span>

<span class="sd">        The value of the statistic (barely) exceeds the critical value associated with a significance level of $2.5%$, so the null hypothesis may be rejected at a significance level of $2.5%$, but not at a significance level of $1%$.</span>

<span class="sd">        ---</span>

<span class="sd">        Example one, using the `airline` data from the `sktime` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import anderson</span>

<span class="sd">        &gt;&gt;&gt; # load the airline data</span>
<span class="sd">        &gt;&gt;&gt; airline_data = load_airline()</span>

<span class="sd">        &gt;&gt;&gt; # run Anderson-Darling test on the data</span>
<span class="sd">        &gt;&gt;&gt; result = anderson(airline_data)</span>

<span class="sd">        &gt;&gt;&gt; # print the results</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Anderson-Darling test statistic: {result.statistic:.3f}&quot;)</span>
<span class="sd">        Anderson-Darling test statistic: 3.089</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Anderson-Darling test critical values: {result.critical_values}&quot;)</span>
<span class="sd">        Anderson-Darling test critical values: [0.565 0.644 0.772 0.901 1.072]</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Anderson-Darling test significance levels: {result.significance_level}&quot;)</span>
<span class="sd">        Anderson-Darling test significance levels: [15.  10.   5.   2.5  1. ]</span>

<span class="sd">        &gt;&gt;&gt; # check if null hypothesis is rejected</span>
<span class="sd">        &gt;&gt;&gt; alpha = 0.05</span>
<span class="sd">        &gt;&gt;&gt; if result.statistic &gt; result.critical_values[2]:</span>
<span class="sd">        ...     print(&quot;Reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ... else:</span>
<span class="sd">        ...     print(&quot;Fail to reject null hypothesis that data is normally distributed&quot;)</span>
<span class="sd">        ...</span>
<span class="sd">        Reject null hypothesis that data is normally distributed</span>
<span class="sd">        ```</span>

<span class="sd">        The null hypothesis of Anderson-Darling test is that the data is normally distributed. In this case, the test statistic is 3.089, which is greater than the critical value at 5% significance level of 0.772, indicating that we reject the null hypothesis. Therefore, we can conclude that the airline data from the sktime library is not normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example two, using the `sine` wave data generated from the `numpy` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Import packages</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import anderson</span>

<span class="sd">        &gt;&gt;&gt; # Generate sine wave data</span>
<span class="sd">        &gt;&gt;&gt; x = np.sin(np.linspace(0, 2 * np.pi, 100))</span>

<span class="sd">        &gt;&gt;&gt; # Perform Anderson-Darling test</span>
<span class="sd">        &gt;&gt;&gt; result = anderson(x)</span>

<span class="sd">        &gt;&gt;&gt; print(&quot;Statistic: %.3f&quot; % result.statistic)</span>
<span class="sd">        Statistic: 0.161</span>
<span class="sd">        &gt;&gt;&gt; for i in range(len(result.critical_values)):</span>
<span class="sd">        ...     sl, cv = result.significance_level[i], result.critical_values[i]</span>
<span class="sd">        ...     if result.statistic &lt; cv:</span>
<span class="sd">        ...         print(&quot;%.3f: %.3f, data looks normal (fail to reject H0)&quot; % (sl, cv))</span>
<span class="sd">        ...     else:</span>
<span class="sd">        ...         print(&quot;%.3f: %.3f, data does not look normal (reject H0)&quot; % (sl, cv))</span>
<span class="sd">        ...</span>
<span class="sd">        15.000: 0.561, data looks normal (fail to reject H0)</span>
<span class="sd">        10.000: 0.638, data looks normal (fail to reject H0)</span>
<span class="sd">        5.000: 0.765, data looks normal (fail to reject H0)</span>
<span class="sd">        2.500: 0.892, data looks normal (fail to reject H0)</span>
<span class="sd">        1.000: 1.061, data looks normal (fail to reject H0)</span>
<span class="sd">        ```</span>

<span class="sd">        In this case, the Anderson-Darling test statistic is 0.161. The critical values and significance levels are also printed. The null hypothesis is that the data is drawn from a normal distribution. Based on the output, we can see that the statistic value is less than all of the critical values for the chosen significance levels, meaning we fail to reject the null hypothesis. Therefore, we can conclude that the sine wave data generated from NumPy is normally distributed.</span>

<span class="sd">        ---</span>

<span class="sd">        Example three, using the `FractionalGaussianNoise` random data generated from the `stochastic` package.</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Python&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.noise import FractionalGaussianNoise</span>
<span class="sd">        &gt;&gt;&gt; from scipy.stats import anderson</span>

<span class="sd">        &gt;&gt;&gt; # generate fractional Gaussian noise</span>
<span class="sd">        &gt;&gt;&gt; fgn = FractionalGaussianNoise(t=1000, hurst=0.5)</span>

<span class="sd">        &gt;&gt;&gt; # calculate the anderson-darling test</span>
<span class="sd">        &gt;&gt;&gt; result = anderson(fgn.fgn(), dist=&quot;norm&quot;)</span>

<span class="sd">        &gt;&gt;&gt; # print the result</span>
<span class="sd">        &gt;&gt;&gt; print(&quot;Statistic: %.3f&quot; % result.statistic)</span>
<span class="sd">        &gt;&gt;&gt; p = 0</span>
<span class="sd">        &gt;&gt;&gt; for i in range(len(result.critical_values)):</span>
<span class="sd">        ...     sl, cv = result.significance_level[i], result.critical_values[i]</span>
<span class="sd">        ...     if result.statistic &lt; result.critical_values[i]:</span>
<span class="sd">        ...         print(&quot;%.3f: %.3f, data looks normal (fail to reject H0)&quot; % (sl, cv))</span>
<span class="sd">        ...     else:</span>
<span class="sd">        ...         print(&quot;%.3f: %.3f, data does not look normal (reject H0)&quot; % (sl, cv))</span>
<span class="sd">        ...</span>
<span class="sd">        ```</span>

<span class="sd">        In this example, the test statistic is 1.171, and the critical values at different significance levels are 0.570, 0.648, 0.777, 0.906, and 1.076. Since the test statistic is greater than all of the critical values, we can reject the null hypothesis and conclude that the data is not normally distributed.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        Critical values provided are for the following significance levels:</span>

<span class="sd">        - normal/exponential</span>
<span class="sd">            - 15%, 10%, 5%, 2.5%, 1%</span>
<span class="sd">        - logistic</span>
<span class="sd">            - 25%, 10%, 5%, 2.5%, 1%, 0.5%</span>
<span class="sd">        - Gumbel</span>
<span class="sd">            - 25%, 10%, 5%, 2.5%, 1%</span>

<span class="sd">        If the returned statistic is larger than these critical values then for the corresponding significance level, the null hypothesis that the data come from the chosen distribution can be rejected. The returned statistic is referred to as &#39;A2&#39; in the references.</span>

<span class="sd">        The Anderson-Darling test is a statistical test used to determine whether a dataset, including time series data, is normally distributed. The test is based on the deviations of the sample distribution from the theoretical normal distribution. The mathematical equation for the Anderson-Darling test is:</span>

<span class="sd">        $$</span>
<span class="sd">        A^2 = -n - \\sum_{i=1}^{n} \\left( \\left( \\frac{2 \\times i - 1}{n} \\right) \\times (log(F(x_i)) + log(1-F(n-i+1))) \\right)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $A^2$ is the test statistic</span>
<span class="sd">        - $n$ is the sample size</span>
<span class="sd">        - $F(x_i)$ is the empirical distribution function of the sample at $x_i$</span>
<span class="sd">        - $log$ is a natural logarithm</span>

<span class="sd">        To calculate the Anderson-Darling test statistic for time series data, we need to perform the following steps:</span>

<span class="sd">        1. Estimate the residuals of the forecasting model: The residuals are the difference between the actual values and the predicted values of the time series model.</span>

<span class="sd">        1. Calculate the sample mean and standard deviation of the residuals: These are the mean and standard deviation of the residuals, respectively.</span>

<span class="sd">        1. Standardize the residuals: The standardized residuals are the residuals divided by their sample standard deviation.</span>

<span class="sd">        1. Sort the standardized residuals in ascending order.</span>

<span class="sd">        1. Calculate the empirical distribution function (EDF) of the residuals: The EDF is the proportion of the standardized residuals that are less than or equal to a given value. It is calculated as:</span>

<span class="sd">            $$</span>
<span class="sd">            F(x_i) = \\left( \\frac{1}{n} \\right) \\times \\sum_{j=1}^{n} \\left( I(x_i &lt;= x_j) \\right)</span>
<span class="sd">            $$</span>

<span class="sd">            where:</span>

<span class="sd">            - $x_i$ are the sorted standardized residuals,</span>
<span class="sd">            - $x_j$ are the sample values, and</span>
<span class="sd">            - $I()$ is the indicator function.</span>

<span class="sd">        1. Calculate the test statistic: The test statistic is calculated using the formula:</span>

<span class="sd">            $$</span>
<span class="sd">            A^2 = -n - \\sum_{i=1}^{n} \\left( \\left( \\frac{2 \\times i - 1}{n} \\right) \\times (log(F(x_i)) + log(1-F(n-i+1))) \\right)</span>
<span class="sd">            $$</span>

<span class="sd">            where:</span>

<span class="sd">            - $x_i$ are the sorted standardized residuals.</span>

<span class="sd">        1. Compare the test statistic to a critical value: If the test statistic is less than the critical value, we cannot reject the null hypothesis of normality and can conclude that the residuals follow a normal distribution. If the test statistic is greater than the critical value, we reject the null hypothesis of normality and conclude that the residuals do not follow a normal distribution.</span>

<span class="sd">        In summary, the Anderson-Darling test is a statistical test that evaluates normality of time series residuals by comparing the empirical distribution function of the sample data to the cumulative distribution function of the normal distribution. The test statistic is calculated by summing the product of weights and logarithms of the empirical distribution function and the complement of the normal distribution CDF. Finally, we compare the test statistic to a critical value to determine whether the residuals follow a normal distribution or not.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        - All credit goes to the [`scipy`](https://docs.scipy.org/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</span>
<span class="sd">        - Stephens, M. A. (1974). EDF Statistics for Goodness of Fit and Some Comparisons, Journal of the American Statistical Association, Vol. 69, pp. 730-737.</span>
<span class="sd">        - Stephens, M. A. (1976). Asymptotic Results for Goodness-of-Fit Statistics with Unknown Parameters, Annals of Statistics, Vol. 4, pp. 357-369.</span>
<span class="sd">        - Stephens, M. A. (1977). Goodness of Fit for the Extreme Value Distribution, Biometrika, Vol. 64, pp. 583-588.</span>
<span class="sd">        - Stephens, M. A. (1977). Goodness of Fit with Special Reference to Tests for Exponentiality , Technical Report No. 262, Department of Statistics, Stanford University, Stanford, CA.</span>
<span class="sd">        - Stephens, M. A. (1979). Tests of Fit for the Logistic Distribution Based on the Empirical Distribution Function, Biometrika, Vol. 66, pp. 591-595.</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`jb()`][ts_stat_tests.algorithms.normality.jb]</span>
<span class="sd">        - [`ob()`][ts_stat_tests.algorithms.normality.ob]</span>
<span class="sd">        - [`sw()`][ts_stat_tests.algorithms.normality.sw]</span>
<span class="sd">        - [`dp()`][ts_stat_tests.algorithms.normality.dp]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_ad</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.instant", "search.highlight", "search.suggest", "toc.follow", "content.action.edit", "content.action.view"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>