
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A Python library for performing statistical tests on time series data.">
      
      
        <meta name="author" content="[Chris Mahoney](mailto:chris@mahoneyconsultingservices.com)">
      
      
      
        <link rel="prev" href="../correlation/">
      
      
        <link rel="next" href="../normality/">
      
      
        
      
      
      <link rel="icon" href="../../assets/icons/1205526.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Regularity - Time Series Statistical Tests</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../assets/css/style.css">
    
      <link rel="stylesheet" href="../../assets/css/admonitions.css">
    
      <link rel="stylesheet" href="../../assets/css/code_chunks.css">
    
      <link rel="stylesheet" href="../../assets/css/shortcodes.css">
    
      <link rel="stylesheet" href="../../assets/css/progress_bar.css">
    
      <link rel="stylesheet" href="https://site-assets.fontawesome.com/releases/v6.4.2/css/all.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#test-the-regularity-of-a-given-time-series-dataset" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),base=new URL("../.."),outdated=__md_get("__outdated",sessionStorage,base);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Time Series Statistical Tests" class="md-header__button md-logo" aria-label="Time Series Statistical Tests" data-md-component="logo">
      
  <img src="../../assets/icons/1205526.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Time Series Statistical Tests
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Regularity
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/data-science-extensions/ts-stat-tests" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </div>
  <div class="md-source__repository">
    ts-stat-tests
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../usage/overview/" class="md-tabs__link">
          
  
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Modules

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="https://data-science-extensions.com/" class="md-tabs__link">
        
  
  
    
  
  Data Science Extensions

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Time Series Statistical Tests" class="md-nav__button md-logo" aria-label="Time Series Statistical Tests" data-md-component="logo">
      
  <img src="../../assets/icons/1205526.svg" alt="logo">

    </a>
    Time Series Statistical Tests
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/data-science-extensions/ts-stat-tests" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </div>
  <div class="md-source__repository">
    ts-stat-tests
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Usage
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Usage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/changelog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Change Log
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Modules
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Modules
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../correlation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Correlation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Regularity
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Regularity
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Tests
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;regularity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.is_regular" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_regular
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.approx_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;approx_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.sample_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sample_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.permutation_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;permutation_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.spectral_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;spectral_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.svd_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;svd_entropy
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../normality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Normality
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stationarity/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Stationarity
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../seasonality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Seasonality
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Utilities
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Utilities
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../errors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Errors
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://data-science-extensions.com/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Data Science Extensions
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Tests
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;regularity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.is_regular" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_regular
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.approx_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;approx_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.sample_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sample_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.permutation_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;permutation_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.spectral_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;spectral_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.svd_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;svd_entropy
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/data-science-extensions/ts-stat-tests/edit/main/docs/code/regularity.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/data-science-extensions/ts-stat-tests/raw/main/docs/code/regularity.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="test-the-regularity-of-a-given-time-series-dataset">Test the <code>regularity</code> of a given Time-Series Dataset<a class="headerlink" href="#test-the-regularity-of-a-given-time-series-dataset" title="Permanent link">ðŸ”—</a></h1>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">ðŸ”—</a></h2>
<div class="admonition abstract">
<p class="admonition-title">Summary</p>
<div class="admonition quote">
<p class="admonition-title">As stated by <a href="https://www.machinelearningplus.com/author/selva86/">Selva Prabhakaran</a>:</p>
<p>The more regular and repeatable patterns a time series has, the easier it is to forecast.</p>
<p>The 'Approximate Entropy' algorithm can be used to quantify the regularity and unpredictability of fluctuations in a time series.</p>
<p>The higher the approximate entropy, the more difficult it is to forecast it.</p>
<p>Another better alternate is the 'Sample Entropy'.</p>
<p>Sample Entropy is similar to approximate entropy but is more consistent in estimating the complexity even for smaller time series.</p>
<p>For example, a random time series with fewer data points can have a lower 'approximate entropy' than a more 'regular' time series, whereas, a longer random time series will have a higher 'approximate entropy'.</p>
<hr />
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 15V9h8V4.16L19.84 12 12 19.84V15z"/></svg></span> For more info, see: <a href="https://www.machinelearningplus.com/time-series/time-series-analysis-python/">Time Series Analysis in Python: A Comprehensive Guide with Examples</a>.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>To state that the data is 'regular' is to say that the data points are evenly spaced, regularly collected, and not missing data points (ie. do not contain excessive <code>NA</code> values). Logically, it is not always necessary to conduct the Test for Regularity on automatically collected data (like for example with Energy Prices, or Daily Temperature), however if this data was collected manually then it is highly recommended. If the data does not meet the requirements of Regularity, then it is necessary to return to the data collection plan, and revise the methodology used.</p>
<table>
<thead>
<tr>
<th>library</th>
<th>category</th>
<th>algorithm</th>
<th>short</th>
<th>import script</th>
<th>url</th>
</tr>
</thead>
<tbody>
<tr>
<td>antropy</td>
<td>Regularity</td>
<td>Approximate Entropy</td>
<td>AppEn</td>
<td><code>from antropy import app_entropy</code></td>
<td><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html">https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html</a></td>
</tr>
<tr>
<td>antropy</td>
<td>Regularity</td>
<td>Sample Entropy</td>
<td>SampEn</td>
<td><code>from antropy import sample_entropy</code></td>
<td><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html">https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html</a></td>
</tr>
<tr>
<td>antropy</td>
<td>Regularity</td>
<td>Permutation Entropy</td>
<td>PermEn</td>
<td><code>from antropy import perm_entropy</code></td>
<td><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html">https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html</a></td>
</tr>
<tr>
<td>antropy</td>
<td>Regularity</td>
<td>Spectral Entropy</td>
<td>SpecEn</td>
<td><code>from antropy import spectral_entropy</code></td>
<td><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html">https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html</a></td>
</tr>
<tr>
<td>antropy</td>
<td>Regularity</td>
<td>SVD Entropy</td>
<td>SvdEn</td>
<td><code>from antropy import svd_entropy</code></td>
<td><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html">https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html</a></td>
</tr>
</tbody>
</table>
<hr />
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 15V9h8V4.16L19.84 12 12 19.84V15z"/></svg></span> For more info, see: <a href="https://chrimaho.medium.com/ausenergyprices-737b9cbe5540">The Future of Australian Energy Prices: Time-Series Analysis of Historic Prices and Forecast for Future Prices</a>.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Source Library</p>
<p>The <a href="https://raphaelvallat.com/antropy/build/html/index.html"><code>AntroPy</code></a> package was chosen because it provides well-tested and efficient implementations of approximate entropy, sample entropy, and related complexity measures for time-series data, is built on top of the scientific Python stack (NumPy/SciPy), and is actively maintained and open source, making it a reliable choice for reproducible statistical analysis.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Source Module</p>
<p>All of the source code can be found within the modules:</p>
<ul>
<li><a href="https://github.com/chrimaho/ts-stat-tests/blob/main/src/ts_stat_tests/algorithms/regularity.py"><code>ts_stat_tests.algorithms.regularity</code></a>.</li>
<li><a href="https://github.com/chrimaho/ts-stat-tests/blob/main/src/ts_stat_tests/tests/regularity.py"><code>ts_stat_tests.tests.regularity</code></a>.</li>
</ul>
</div>
</div>
<h2 id="regularity-tests">Regularity Tests<a class="headerlink" href="#regularity-tests" title="Permanent link">ðŸ”—</a></h2>


<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.tests.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.tests.regularity</span>


<a href="#ts_stat_tests.tests.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains convenience functions and tests for regularity measures, allowing for easy access to different entropy algorithms.</p>
</div>










  <div class="doc doc-children">























































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">entropy</span>


<a href="#ts_stat_tests.tests.regularity.entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test for the entropy of a given data set.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is a convenience wrapper around the five underlying algorithms:<br>
- <a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>When the given value for <code>algorithm</code> is not valid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.NDArray">NDArray</span>[<span title="numpy.float64">float64</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The calculated entropy value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">entropy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normal</span> <span class="o">=</span> <span class="n">data_normal</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Sample Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">))</span>
<span class="go">2.2374...</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Approx Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">))</span>
<span class="go">1.6643...</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 3: Spectral Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">0.9329...</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            regularity" href="#ts_stat_tests.tests.regularity.regularity"><code>regularity()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test for the entropy of a given data set.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function is a convenience wrapper around the five underlying algorithms:&lt;br&gt;</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]&lt;br&gt;</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]&lt;br&gt;</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]&lt;br&gt;</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]&lt;br&gt;</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        (ValueError):</span>
<span class="sd">            When the given value for `algorithm` is not valid.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[float, NDArray[np.float64]]):</span>
<span class="sd">            The calculated entropy value.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import entropy</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_normal</span>
<span class="sd">        &gt;&gt;&gt; normal = data_normal</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Sample Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(entropy(x=normal, algorithm=&quot;sample&quot;))</span>
<span class="sd">        2.2374...</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Approx Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(entropy(x=normal, algorithm=&quot;approx&quot;))</span>
<span class="sd">        1.6643...</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 3: Spectral Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(entropy(x=normal, algorithm=&quot;spectral&quot;, sf=1))</span>
<span class="sd">        0.9329...</span>

<span class="sd">        ```</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`regularity()`][ts_stat_tests.tests.regularity.regularity]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;sampl&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="s2">&quot;sampl&quot;</span><span class="p">,</span> <span class="s2">&quot;samp&quot;</span><span class="p">),</span>
        <span class="s2">&quot;approx&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;app&quot;</span><span class="p">,</span> <span class="s2">&quot;approx&quot;</span><span class="p">),</span>
        <span class="s2">&quot;spect&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;spec&quot;</span><span class="p">,</span> <span class="s2">&quot;spect&quot;</span><span class="p">,</span> <span class="s2">&quot;spectral&quot;</span><span class="p">),</span>
        <span class="s2">&quot;perm&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;perm&quot;</span><span class="p">,</span> <span class="s2">&quot;permutation&quot;</span><span class="p">),</span>
        <span class="s2">&quot;svd&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span> <span class="s2">&quot;svd_entropy&quot;</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;sampl&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;approx&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;spect&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;svd&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">svd_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="n">generate_error_message</span><span class="p">(</span>
            <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;algorithm&quot;</span><span class="p">,</span>
            <span class="n">value_parsed</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">regularity</span>


<a href="#ts_stat_tests.tests.regularity.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">regularity</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test for the regularity of a given data set.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This is a pass-through, convenience wrapper around the <a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a> function.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.NDArray">NDArray</span>[<span title="numpy.float64">float64</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The calculated regularity (entropy) value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normal</span> <span class="o">=</span> <span class="n">data_normal</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Sample Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">))</span>
<span class="go">2.2374...</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Approx Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">))</span>
<span class="go">1.6643...</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 3: Spectral Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">0.9329...</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">regularity</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test for the regularity of a given data set.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This is a pass-through, convenience wrapper around the [`entropy()`][ts_stat_tests.tests.regularity.entropy] function.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[float, NDArray[np.float64]]):</span>
<span class="sd">            The calculated regularity (entropy) value.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_normal</span>
<span class="sd">        &gt;&gt;&gt; normal = data_normal</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Sample Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(regularity(x=normal, algorithm=&quot;sample&quot;))</span>
<span class="sd">        2.2374...</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Approx Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(regularity(x=normal, algorithm=&quot;approx&quot;))</span>
<span class="sd">        1.6643...</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 3: Spectral Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(regularity(x=normal, algorithm=&quot;spectral&quot;, sf=1))</span>
<span class="sd">        0.9329...</span>

<span class="sd">        ```</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`entropy()`][ts_stat_tests.tests.regularity.entropy]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.is_regular" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">is_regular</span>


<a href="#ts_stat_tests.tests.regularity.is_regular" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">is_regular</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test whether a given data set is <code>regular</code> or not.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function implements the given algorithm (defined in the parameter <code>algorithm</code>), and returns a dictionary containing the relevant data:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The result of the test. Will be `True` if `entropy&lt;tolerance`, and `False` otherwise</span>
    <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># A `float` value, the result of the `entropy()` function</span>
    <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># A `float` value, which is the tolerance used for determining whether or not the `entropy` is `regular` or not</span>
<span class="p">}</span>
</code></pre></div></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="float">float</span>, <span title="int">int</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tolerance value used to determine whether or not the result is <code>regular</code> or not.<br>
- If <code>tolerance</code> is either type <code>int</code> or <code>float</code>, then this value will be used.<br>
- If <code>tolerance</code> is either <code>"default"</code> or <code>None</code>, then <code>tolerance</code> will be derived from <code>x</code> using the calculation:
    <div class="highlight"><pre><span></span><code><span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
- If any other value is given, then a <code>ValueError</code> error will be raised.<br>
Defaults to <code>"default"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;default&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the given <code>tolerance</code> parameter is invalid.</p>
<p>Valid options are:</p>
<ul>
<li>A number with type <code>float</code> or <code>int</code>, or</li>
<li>A string with value <code>default</code>, or</li>
<li>The value <code>None</code>.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="float">float</span>, <span title="bool">bool</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing the test results:</p>
<ul>
<li><code>result</code> (bool): <code>True</code> if <code>entropy &lt; tolerance</code>.</li>
<li><code>entropy</code> (float): The calculated entropy value.</li>
<li><code>tolerance</code> (float): The threshold used for regularity.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_regular</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_normal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normal</span> <span class="o">=</span> <span class="n">data_normal</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Sample Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">))</span>
<span class="go">{&#39;result&#39;: False, &#39;entropy&#39;: 2.23743099781426, &#39;tolerance&#39;: 0.20294652904313437}</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Approx Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">normal</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
<span class="go">{&#39;result&#39;: False, &#39;entropy&#39;: 1.6643808251518548, &#39;tolerance&#39;: 0.5}</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            regularity" href="#ts_stat_tests.tests.regularity.regularity"><code>regularity()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_regular</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test whether a given data set is `regular` or not.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function implements the given algorithm (defined in the parameter `algorithm`), and returns a dictionary containing the relevant data:</span>
<span class="sd">        ```python</span>
<span class="sd">        {</span>
<span class="sd">            &quot;result&quot;: ...,  # The result of the test. Will be `True` if `entropy&lt;tolerance`, and `False` otherwise</span>
<span class="sd">            &quot;entropy&quot;: ...,  # A `float` value, the result of the `entropy()` function</span>
<span class="sd">            &quot;tolerance&quot;: ...,  # A `float` value, which is the tolerance used for determining whether or not the `entropy` is `regular` or not</span>
<span class="sd">        }</span>
<span class="sd">        ```</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>
<span class="sd">        tolerance (Union[str, float, int, None], optional):</span>
<span class="sd">            The tolerance value used to determine whether or not the result is `regular` or not.&lt;br&gt;</span>
<span class="sd">            - If `tolerance` is either type `int` or `float`, then this value will be used.&lt;br&gt;</span>
<span class="sd">            - If `tolerance` is either `&quot;default&quot;` or `None`, then `tolerance` will be derived from `x` using the calculation:</span>
<span class="sd">                ```python</span>
<span class="sd">                tolerance = 0.2 * np.std(a=x)</span>
<span class="sd">                ```</span>
<span class="sd">            - If any other value is given, then a `ValueError` error will be raised.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;default&quot;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        (ValueError):</span>
<span class="sd">            If the given `tolerance` parameter is invalid.</span>

<span class="sd">            Valid options are:</span>

<span class="sd">            - A number with type `float` or `int`, or</span>
<span class="sd">            - A string with value `default`, or</span>
<span class="sd">            - The value `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (dict[str, Union[str, float, bool]]):</span>
<span class="sd">            A dictionary containing the test results:</span>

<span class="sd">            - `result` (bool): `True` if `entropy &lt; tolerance`.</span>
<span class="sd">            - `entropy` (float): The calculated entropy value.</span>
<span class="sd">            - `tolerance` (float): The threshold used for regularity.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import is_regular</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_normal</span>
<span class="sd">        &gt;&gt;&gt; normal = data_normal</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Sample Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(is_regular(x=normal, algorithm=&quot;sample&quot;))</span>
<span class="sd">        {&#39;result&#39;: False, &#39;entropy&#39;: 2.23743099781426, &#39;tolerance&#39;: 0.20294652904313437}</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Approx Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(is_regular(x=normal, algorithm=&quot;approx&quot;, tolerance=0.5))</span>
<span class="sd">        {&#39;result&#39;: False, &#39;entropy&#39;: 1.6643808251518548, &#39;tolerance&#39;: 0.5}</span>

<span class="sd">        ```</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`entropy()`][ts_stat_tests.tests.regularity.entropy]</span>
<span class="sd">        - [`regularity()`][ts_stat_tests.tests.regularity.regularity]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tolerance</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="n">tolerance</span>
    <span class="k">elif</span> <span class="n">tolerance</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid option for `tolerance` parameter: </span><span class="si">{</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Valid options are:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- A number with type `float` or `int`,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- A string with value `default`,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- The value `None`.&quot;</span>
        <span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="n">tol</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">result</span><span class="p">),</span>
        <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">),</span>
        <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">tol</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div><h2 id="regularity-algorithms">Regularity Algorithms<a class="headerlink" href="#regularity-algorithms" title="Permanent link">ðŸ”—</a></h2>


<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.algorithms.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.algorithms.regularity</span>


<a href="#ts_stat_tests.algorithms.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains algorithms to compute regularity measures for time series data, including approximate entropy, sample entropy, spectral entropy, and permutation entropy.</p>
</div>










  <div class="doc doc-children">































































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.approx_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">approx_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.approx_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">approx_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Approximate entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data.</p>
<p>This function implements the <a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>app_entropy()</code></a> function from the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Approximate entropy is a technique used to quantify the amount of regularity and the unpredictability of fluctuations over time-series data. Smaller values indicate that the data is more regular and predictable.</p>
<p>To calculate approximate entropy, we first need to define a window size or scale factor, which determines the length of the subsequences that are used to compare the similarity of the time series. We then compare all possible pairs of subsequences within the time series and calculate the probability that two subsequences are within a certain tolerance level of each other, where the tolerance level is usually expressed as a percentage of the standard deviation of the time series.</p>
<p>The approximate entropy is then defined as the negative natural logarithm of the average probability of similarity across all possible pairs of subsequences, normalized by the length of the time series and the scale factor.</p>
<p>The approximate entropy measure is useful in a variety of applications, such as the analysis of physiological signals, financial time series, and climate data. It can be used to detect changes in the regularity or predictability of a time series over time, and can provide insights into the underlying dynamics or mechanisms that generate the signal.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape <code>(n_times,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tolerance level or similarity criterion. If <code>None</code> (default), it is set to <span class="arithmatex">\(0.2 \times \text{std}(x)\)</span>.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>. For a full list of all available metrics, see <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise.distance_metrics</code></a> and <a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a><br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The approximate entropy score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.algorithms.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">approx_entropy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_airline</span><span class="p">,</span> <span class="n">data_random</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">airline</span> <span class="o">=</span> <span class="n">data_airline</span><span class="o">.</span><span class="n">values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random</span> <span class="o">=</span> <span class="n">data_random</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Airline Passengers Data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">airline</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.6451</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Random Data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">random</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">1.8177</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="equation">
<summary>Calculation</summary>
<p>The equation for ApEn is:</p>
<div class="arithmatex">\[
\text{ApEn}(m, r, N) = \phi_m(r) - \phi_{m+1}(r)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(m\)</span> is the embedding dimension,</li>
<li><span class="arithmatex">\(r\)</span> is the tolerance or similarity criterion,</li>
<li><span class="arithmatex">\(N\)</span> is the length of the time series, and</li>
<li><span class="arithmatex">\(\phi_m(r)\)</span> and <span class="arithmatex">\(\phi_{m+1}(r)\)</span> are the logarithms of the probabilities that two sequences of <span class="arithmatex">\(m\)</span> data points in the time series that are similar to each other within a tolerance <span class="arithmatex">\(r\)</span> remain similar for the next data point, for <span class="arithmatex">\(m\)</span> and <span class="arithmatex">\(m+1\)</span>, respectively.</li>
</ul>
</details>
<details class="note">
<summary>Notes</summary>
<ul>
<li><strong>Inputs</strong>: <code>x</code> is a 1-dimensional array. It represents time-series data, ideally with each element in the array being a measurement or value taken at regular time intervals.</li>
<li><strong>Settings</strong>: <code>order</code> is used for determining the number of values that are used to construct each permutation pattern. If the embedding dimension is too small, we may miss important patterns. If it's too large, we may overfit noise.</li>
<li><strong>Metric</strong>: The Chebyshev metric is often used because it is a robust and computationally efficient way to measure the distance between two time series.</li>
</ul>
</details>
<details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039">Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049</a></li>
<li><a href="https://scikit-learn.org/stable/modules/metrics.html#metrics">SK-Learn: Pairwise metrics, Affinities and Kernels</a></li>
<li><a href="https://docs.scipy.org/doc/scipy/tutorial/spatial.html">Spatial data structures and algorithms</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">approx_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Approximate entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data.</span>

<span class="sd">        This function implements the [`app_entropy()`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html) function from the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Approximate entropy is a technique used to quantify the amount of regularity and the unpredictability of fluctuations over time-series data. Smaller values indicate that the data is more regular and predictable.</span>

<span class="sd">        To calculate approximate entropy, we first need to define a window size or scale factor, which determines the length of the subsequences that are used to compare the similarity of the time series. We then compare all possible pairs of subsequences within the time series and calculate the probability that two subsequences are within a certain tolerance level of each other, where the tolerance level is usually expressed as a percentage of the standard deviation of the time series.</span>

<span class="sd">        The approximate entropy is then defined as the negative natural logarithm of the average probability of similarity across all possible pairs of subsequences, normalized by the length of the time series and the scale factor.</span>

<span class="sd">        The approximate entropy measure is useful in a variety of applications, such as the analysis of physiological signals, financial time series, and climate data. It can be used to detect changes in the regularity or predictability of a time series over time, and can provide insights into the underlying dynamics or mechanisms that generate the signal.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape `(n_times,)`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        tolerance (Optional[float], optional):</span>
<span class="sd">            Tolerance level or similarity criterion. If `None` (default), it is set to $0.2 \times \text{std}(x)$.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS, optional):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance). For a full list of all available metrics, see [`sklearn.metrics.pairwise.distance_metrics`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html) and [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The approximate entropy score.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.algorithms.regularity import approx_entropy</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_airline, data_random</span>
<span class="sd">        &gt;&gt;&gt; airline = data_airline.values</span>
<span class="sd">        &gt;&gt;&gt; random = data_random</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Airline Passengers Data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{approx_entropy(x=airline):.4f}&quot;)</span>
<span class="sd">        0.6451</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Random Data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{approx_entropy(x=random):.4f}&quot;)</span>
<span class="sd">        1.8177</span>

<span class="sd">        ```</span>

<span class="sd">    ??? equation &quot;Calculation&quot;</span>
<span class="sd">        The equation for ApEn is:</span>

<span class="sd">        $$</span>
<span class="sd">        \text{ApEn}(m, r, N) = \phi_m(r) - \phi_{m+1}(r)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $m$ is the embedding dimension,</span>
<span class="sd">        - $r$ is the tolerance or similarity criterion,</span>
<span class="sd">        - $N$ is the length of the time series, and</span>
<span class="sd">        - $\phi_m(r)$ and $\phi_{m+1}(r)$ are the logarithms of the probabilities that two sequences of $m$ data points in the time series that are similar to each other within a tolerance $r$ remain similar for the next data point, for $m$ and $m+1$, respectively.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        - **Inputs**: `x` is a 1-dimensional array. It represents time-series data, ideally with each element in the array being a measurement or value taken at regular time intervals.</span>
<span class="sd">        - **Settings**: `order` is used for determining the number of values that are used to construct each permutation pattern. If the embedding dimension is too small, we may miss important patterns. If it&#39;s too large, we may overfit noise.</span>
<span class="sd">        - **Metric**: The Chebyshev metric is often used because it is a robust and computationally efficient way to measure the distance between two time series.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - [Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049](https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039)</span>
<span class="sd">        - [SK-Learn: Pairwise metrics, Affinities and Kernels](https://scikit-learn.org/stable/modules/metrics.html#metrics)</span>
<span class="sd">        - [Spatial data structures and algorithms](https://docs.scipy.org/doc/scipy/tutorial/spatial.html)</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_app_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.sample_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">sample_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.sample_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">sample_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Sample entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data.</p>
<p>This function implements the <a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>sample_entropy()</code></a> function from the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Sample entropy is a modification of approximate entropy, used for assessing the complexity of physiological time-series signals. It has two advantages over approximate entropy: data length independence and a relatively trouble-free implementation. Large values indicate high complexity whereas smaller values characterize more self-similar and regular signals.</p>
<p>The value of SampEn ranges from zero (<span class="arithmatex">\(0\)</span>) to infinity (<span class="arithmatex">\(\infty\)</span>), with lower values indicating higher regularity or predictability in the time series. A time series with high <span class="arithmatex">\(SampEn\)</span> is more unpredictable or irregular, whereas a time series with low <span class="arithmatex">\(SampEn\)</span> is more regular or predictable.</p>
<p>Sample entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks.</p>
<p>Choosing an appropriate embedding dimension is crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape <code>(n_times,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tolerance level or similarity criterion. If <code>None</code> (default), it is set to <span class="arithmatex">\(0.2 \times \text{std}(x)\)</span>.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>. For a full list of all available metrics, see <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise.distance_metrics</code></a> and <a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a><br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The sample entropy score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.algorithms.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">sample_entropy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_airline</span><span class="p">,</span> <span class="n">data_random</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">airline</span> <span class="o">=</span> <span class="n">data_airline</span><span class="o">.</span><span class="n">values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random</span> <span class="o">=</span> <span class="n">data_random</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Airline Passengers Data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">airline</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.6177</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Random Data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">random</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.2017</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="equation">
<summary>Calculation</summary>
<p>The equation for sample entropy (SampEn) is as follows:</p>
<div class="arithmatex">\[
\text{SampEn}(m, r, N) = - \log \left( \frac {C_m(r)} {C_{m+1}(r)} \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(m\)</span> is the embedding dimension,</li>
<li><span class="arithmatex">\(r\)</span> is the tolerance or similarity criterion,</li>
<li><span class="arithmatex">\(N\)</span> is the length of the time series, and</li>
<li><span class="arithmatex">\(C_m(r)\)</span> and <span class="arithmatex">\(C_{m+1}(r)\)</span> are the number of <span class="arithmatex">\(m\)</span>-tuples (vectors of <span class="arithmatex">\(m\)</span> consecutive data points) that have a distance less than or equal to <span class="arithmatex">\(r\)</span>, and <span class="arithmatex">\((m+1)\)</span>-tuples with the same property, respectively.</li>
</ul>
<p>The calculation of sample entropy involves the following steps:</p>
<ol>
<li>Choose the values of <span class="arithmatex">\(m\)</span> and <span class="arithmatex">\(r\)</span>.</li>
<li>Construct <span class="arithmatex">\(m\)</span>-tuples from the time series data.</li>
<li>Compute the number of <span class="arithmatex">\(m\)</span>-tuples that are within a distance <span class="arithmatex">\(r\)</span> of each other (<span class="arithmatex">\(C_m(r)\)</span>).</li>
<li>Compute the number of <span class="arithmatex">\((m+1)\)</span>-tuples that are within a distance <span class="arithmatex">\(r\)</span> of each other (<span class="arithmatex">\(C_{m+1}(r)\)</span>).</li>
<li>Compute the value of <span class="arithmatex">\(SampEn\)</span> using the formula above.</li>
</ol>
</details>
<details class="note">
<summary>Notes</summary>
<ul>
<li>Note that if <code>metric == 'chebyshev'</code> and <code>len(x) &lt; 5000</code> points, then the sample entropy is computed using a fast custom Numba script. For other distance metric or longer time-series, the sample entropy is computed using a code from the <a href="https://mne.tools/mne-features/"><code>mne-features</code></a> package by Jean-Baptiste Schiratti and Alexandre Gramfort (requires sklearn).</li>
<li>The embedding dimension is important in the calculation of sample entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations. If it is too large, we may overfit the data.</li>
</ul>
</details>
<details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039">Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049</a></li>
<li><a href="https://scikit-learn.org/stable/modules/metrics.html#metrics">SK-Learn: Pairwise metrics, Affinities and Kernels</a></li>
<li><a href="https://docs.scipy.org/doc/scipy/tutorial/spatial.html">Spatial data structures and algorithms</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html"><code>sklearn.neighbors.KDTree</code></a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise_distances</code></a></li>
<li><a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Sample entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data.</span>

<span class="sd">        This function implements the [`sample_entropy()`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html) function from the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Sample entropy is a modification of approximate entropy, used for assessing the complexity of physiological time-series signals. It has two advantages over approximate entropy: data length independence and a relatively trouble-free implementation. Large values indicate high complexity whereas smaller values characterize more self-similar and regular signals.</span>

<span class="sd">        The value of SampEn ranges from zero ($0$) to infinity ($\infty$), with lower values indicating higher regularity or predictability in the time series. A time series with high $SampEn$ is more unpredictable or irregular, whereas a time series with low $SampEn$ is more regular or predictable.</span>

<span class="sd">        Sample entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks.</span>

<span class="sd">        Choosing an appropriate embedding dimension is crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape `(n_times,)`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        tolerance (Optional[float], optional):</span>
<span class="sd">            Tolerance level or similarity criterion. If `None` (default), it is set to $0.2 \times \text{std}(x)$.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS, optional):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance). For a full list of all available metrics, see [`sklearn.metrics.pairwise.distance_metrics`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html) and [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The sample entropy score.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.algorithms.regularity import sample_entropy</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_airline, data_random</span>
<span class="sd">        &gt;&gt;&gt; airline = data_airline.values</span>
<span class="sd">        &gt;&gt;&gt; random = data_random</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Airline Passengers Data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=airline):.4f}&quot;)</span>
<span class="sd">        0.6177</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Random Data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=random):.4f}&quot;)</span>
<span class="sd">        2.2017</span>

<span class="sd">        ```</span>

<span class="sd">    ??? equation &quot;Calculation&quot;</span>
<span class="sd">        The equation for sample entropy (SampEn) is as follows:</span>

<span class="sd">        $$</span>
<span class="sd">        \text{SampEn}(m, r, N) = - \log \left( \frac {C_m(r)} {C_{m+1}(r)} \right)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $m$ is the embedding dimension,</span>
<span class="sd">        - $r$ is the tolerance or similarity criterion,</span>
<span class="sd">        - $N$ is the length of the time series, and</span>
<span class="sd">        - $C_m(r)$ and $C_{m+1}(r)$ are the number of $m$-tuples (vectors of $m$ consecutive data points) that have a distance less than or equal to $r$, and $(m+1)$-tuples with the same property, respectively.</span>

<span class="sd">        The calculation of sample entropy involves the following steps:</span>

<span class="sd">        1. Choose the values of $m$ and $r$.</span>
<span class="sd">        2. Construct $m$-tuples from the time series data.</span>
<span class="sd">        3. Compute the number of $m$-tuples that are within a distance $r$ of each other ($C_m(r)$).</span>
<span class="sd">        4. Compute the number of $(m+1)$-tuples that are within a distance $r$ of each other ($C_{m+1}(r)$).</span>
<span class="sd">        5. Compute the value of $SampEn$ using the formula above.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        - Note that if `metric == &#39;chebyshev&#39;` and `len(x) &lt; 5000` points, then the sample entropy is computed using a fast custom Numba script. For other distance metric or longer time-series, the sample entropy is computed using a code from the [`mne-features`](https://mne.tools/mne-features/) package by Jean-Baptiste Schiratti and Alexandre Gramfort (requires sklearn).</span>
<span class="sd">        - The embedding dimension is important in the calculation of sample entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations. If it is too large, we may overfit the data.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - [Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049](https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039)</span>
<span class="sd">        - [SK-Learn: Pairwise metrics, Affinities and Kernels](https://scikit-learn.org/stable/modules/metrics.html#metrics)</span>
<span class="sd">        - [Spatial data structures and algorithms](https://docs.scipy.org/doc/scipy/tutorial/spatial.html)</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">        - [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html)</span>
<span class="sd">        - [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html)</span>
<span class="sd">        - [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_sample_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.permutation_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">permutation_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.permutation_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">permutation_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">int64</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Permutation entropy is a measure of the complexity or randomness of a time series. It is based on the idea of permuting the order of the values in the time series and calculating the entropy of the resulting permutation patterns.</p>
<p>This function implements the <a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>perm_entropy()</code></a> function from the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The permutation entropy is a complexity measure for time-series first introduced by Bandt and Pompe in 2002.</p>
<p>It is particularly useful for detecting nonlinear dynamics and nonstationarity in the data. The value of permutation entropy ranges from <span class="arithmatex">\(0\)</span> to <span class="arithmatex">\(\log_2(\text{order}!)\)</span>, where the lower bound is attained for an increasing or decreasing sequence of values, and the upper bound for a completely random system where all possible permutations appear with the same probability.</p>
<p>Choosing an appropriate embedding dimension is crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape <code>(n_times,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Order of permutation entropy.<br>
Defaults to <code>3</code>.</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="list">list</span>, <span title="numpy.typing.NDArray">NDArray</span>[<span title="numpy.int64">int64</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Time delay (lag). If multiple values are passed, the average permutation entropy across all these delays is calculated.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(\log_2(\text{order}!)\)</span> to normalize the entropy between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the permutation entropy in bits.<br>
Defaults to <code>False</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.NDArray">NDArray</span>[<span title="numpy.float64">float64</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The permutation entropy of the data set.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.algorithms.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">permutation_entropy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_airline</span><span class="p">,</span> <span class="n">data_random</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">airline</span> <span class="o">=</span> <span class="n">data_airline</span><span class="o">.</span><span class="n">values</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random</span> <span class="o">=</span> <span class="n">data_random</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Airline Passengers Data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">airline</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.3601</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Random Data (Normalized)</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">random</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9997</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="equation">
<summary>Calculation</summary>
<p>The formula for permutation entropy (<span class="arithmatex">\(PE\)</span>) is as follows:</p>
<div class="arithmatex">\[
PE(n) = - \sum_{i=0}^{n!} p(i) \times \log_2(p(i))
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(n\)</span> is the embedding dimension (<code>order</code>),</li>
<li><span class="arithmatex">\(p(i)\)</span> is the probability of the <span class="arithmatex">\(i\)</span>-th ordinal pattern.</li>
</ul>
<p>The embedded matrix <span class="arithmatex">\(Y\)</span> is created by:</p>
<div class="arithmatex">\[
\begin{align}
    y(i) &amp;= [x_i, x_{i+\text{delay}}, \dots, x_{i+(\text{order}-1) \times \text{delay}}] \\
    Y &amp;= [y(1), y(2), \dots, y(N-(\text{order}-1) \times \text{delay})]^T
\end{align}
\]</div>
</details>
<details class="note">
<summary>Notes</summary>
<ul>
<li>The embedding dimension (<code>order</code>) determines the number of values used to construct each permutation pattern. If too small, patterns may be missed. If too large, overfitting to noise may occur.</li>
</ul>
</details>
<details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="http://materias.df.uba.ar/dnla2019c1/files/2019/03/permutation_entropy.pdf">Bandt, Christoph, and Bernd Pompe. "Permutation entropy: a natural complexity measure for time series." Physical review letters 88.17 (2002): 174102</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">permutation_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Permutation entropy is a measure of the complexity or randomness of a time series. It is based on the idea of permuting the order of the values in the time series and calculating the entropy of the resulting permutation patterns.</span>

<span class="sd">        This function implements the [`perm_entropy()`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html) function from the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The permutation entropy is a complexity measure for time-series first introduced by Bandt and Pompe in 2002.</span>

<span class="sd">        It is particularly useful for detecting nonlinear dynamics and nonstationarity in the data. The value of permutation entropy ranges from $0$ to $\log_2(\text{order}!)$, where the lower bound is attained for an increasing or decreasing sequence of values, and the upper bound for a completely random system where all possible permutations appear with the same probability.</span>

<span class="sd">        Choosing an appropriate embedding dimension is crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape `(n_times,)`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Order of permutation entropy.&lt;br&gt;</span>
<span class="sd">            Defaults to `3`.</span>
<span class="sd">        delay (Union[int, list, NDArray[np.int64]], optional):</span>
<span class="sd">            Time delay (lag). If multiple values are passed, the average permutation entropy across all these delays is calculated.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $\log_2(\text{order}!)$ to normalize the entropy between $0$ and $1$. Otherwise, return the permutation entropy in bits.&lt;br&gt;</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[float, NDArray[np.float64]]):</span>
<span class="sd">            The permutation entropy of the data set.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.algorithms.regularity import permutation_entropy</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_airline, data_random</span>
<span class="sd">        &gt;&gt;&gt; airline = data_airline.values</span>
<span class="sd">        &gt;&gt;&gt; random = data_random</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Airline Passengers Data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=airline):.4f}&quot;)</span>
<span class="sd">        2.3601</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Random Data (Normalized)&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=random, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9997</span>

<span class="sd">        ```</span>

<span class="sd">    ??? equation &quot;Calculation&quot;</span>
<span class="sd">        The formula for permutation entropy ($PE$) is as follows:</span>

<span class="sd">        $$</span>
<span class="sd">        PE(n) = - \sum_{i=0}^{n!} p(i) \times \log_2(p(i))</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $n$ is the embedding dimension (`order`),</span>
<span class="sd">        - $p(i)$ is the probability of the $i$-th ordinal pattern.</span>

<span class="sd">        The embedded matrix $Y$ is created by:</span>

<span class="sd">        $$</span>
<span class="sd">        \begin{align}</span>
<span class="sd">            y(i) &amp;= [x_i, x_{i+\text{delay}}, \dots, x_{i+(\text{order}-1) \times \text{delay}}] \\</span>
<span class="sd">            Y &amp;= [y(1), y(2), \dots, y(N-(\text{order}-1) \times \text{delay})]^T</span>
<span class="sd">        \end{align}</span>
<span class="sd">        $$</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        - The embedding dimension (`order`) determines the number of values used to construct each permutation pattern. If too small, patterns may be missed. If too large, overfitting to noise may occur.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - [Bandt, Christoph, and Bernd Pompe. &quot;Permutation entropy: a natural complexity measure for time series.&quot; Physical review letters 88.17 (2002): 174102](http://materias.df.uba.ar/dnla2019c1/files/2019/03/permutation_entropy.pdf)</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_perm_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]  # antropy function can handle Union[int, list[int], NDArray[np.int64]], however the function signature is not annotated as such</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.spectral_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">spectral_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.spectral_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">spectral_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;fft&quot;</span><span class="p">,</span>
    <span class="n">nperseg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Spectral entropy is a measure of the amount of complexity or unpredictability in a signal's frequency domain representation. It is used to quantify the degree of randomness or regularity in the power spectrum of a signal.</p>
<p>This function implements the <a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>spectral_entropy()</code></a> function from the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Spectral Entropy is defined to be the Shannon entropy of the power spectral density (PSD) of the data. It is based on the Shannon entropy, which is a measure of the uncertainty or information content of a probability distribution.</p>
<p>The value of spectral entropy ranges from <span class="arithmatex">\(0\)</span> to <span class="arithmatex">\(\log_2(N)\)</span>, where <span class="arithmatex">\(N\)</span> is the number of frequency bands. Lower values indicate a more concentrated or regular distribution of power, while higher values indicate a more spread-out or irregular distribution.</p>
<p>Spectral entropy is particularly useful for detecting periodicity and cyclical patterns, as well as changes in the frequency distribution over time.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional or N-dimensional data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS">VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Spectral estimation method: <code>'fft'</code> or <code>'welch'</code>.<br>
- <code>'fft'</code>: Fourier Transformation (<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html#scipy.signal.periodogram"><code>scipy.signal.periodogram()</code></a>)<br>
- <code>'welch'</code>: Welch periodogram (<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch"><code>scipy.signal.welch()</code></a>)<br>
Defaults to <code>"fft"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;fft&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nperseg</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of each FFT segment for Welch method. If <code>None</code>, uses <code>scipy</code>'s default of 256 samples.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(\log_2(\text{psd.size})\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bits.<br>
Defaults to <code>False</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The axis along which the entropy is calculated. Default is the last axis.<br>
Defaults to <code>-1</code>.</p>
              </div>
            </td>
            <td>
                  <code>-1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="float">float</span>, <span title="numpy.typing.NDArray">NDArray</span>[<span title="numpy.float64">float64</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The spectral entropy score. Returned as a float for 1D input, or a numpy array for N-dimensional input.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.algorithms.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">spectral_entropy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">airline</span> <span class="o">=</span> <span class="n">data_airline</span><span class="o">.</span><span class="n">values</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Airline Passengers Data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">airline</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.6538</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: Welch method for spectral entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">data_sine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">400</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_sine</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;welch&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">1.2938</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="equation">
<summary>Calculation</summary>
<p>The spectral entropy (<span class="arithmatex">\(SE\)</span>) is defined as:</p>
<div class="arithmatex">\[
H(x, f_s) = - \sum_{i=0}^{f_s/2} P(i) \times \log_2(P(i))
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(P(i)\)</span> is the normalized power spectral density (PSD) at the <span class="arithmatex">\(i\)</span>-th frequency band,</li>
<li><span class="arithmatex">\(f_s\)</span> is the sampling frequency.</li>
</ul>
</details>
<details class="note">
<summary>Notes</summary>
<ul>
<li>The power spectrum represents the energy of the signal at different frequencies. High spectral entropy indicates multiple sources or processes with different frequencies, while low spectral entropy suggests a dominant frequency or periodicity.</li>
</ul>
</details>
<details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/1714811/">Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</a></li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">Wikipedia: Spectral density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">Wikipedia: Welch's method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">spectral_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;fft&quot;</span><span class="p">,</span>
    <span class="n">nperseg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Spectral entropy is a measure of the amount of complexity or unpredictability in a signal&#39;s frequency domain representation. It is used to quantify the degree of randomness or regularity in the power spectrum of a signal.</span>

<span class="sd">        This function implements the [`spectral_entropy()`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html) function from the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Spectral Entropy is defined to be the Shannon entropy of the power spectral density (PSD) of the data. It is based on the Shannon entropy, which is a measure of the uncertainty or information content of a probability distribution.</span>

<span class="sd">        The value of spectral entropy ranges from $0$ to $\log_2(N)$, where $N$ is the number of frequency bands. Lower values indicate a more concentrated or regular distribution of power, while higher values indicate a more spread-out or irregular distribution.</span>

<span class="sd">        Spectral entropy is particularly useful for detecting periodicity and cyclical patterns, as well as changes in the frequency distribution over time.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional or N-dimensional data array.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        method (VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS, optional):</span>
<span class="sd">            Spectral estimation method: `&#39;fft&#39;` or `&#39;welch&#39;`.&lt;br&gt;</span>
<span class="sd">            - `&#39;fft&#39;`: Fourier Transformation ([`scipy.signal.periodogram()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html#scipy.signal.periodogram))&lt;br&gt;</span>
<span class="sd">            - `&#39;welch&#39;`: Welch periodogram ([`scipy.signal.welch()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch))&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;fft&quot;`.</span>
<span class="sd">        nperseg (Optional[int], optional):</span>
<span class="sd">            Length of each FFT segment for Welch method. If `None`, uses `scipy`&#39;s default of 256 samples.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $\log_2(\text{psd.size})$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bits.&lt;br&gt;</span>
<span class="sd">            Defaults to `False`.</span>
<span class="sd">        axis (int, optional):</span>
<span class="sd">            The axis along which the entropy is calculated. Default is the last axis.&lt;br&gt;</span>
<span class="sd">            Defaults to `-1`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[float, NDArray[np.float64]]):</span>
<span class="sd">            The spectral entropy score. Returned as a float for 1D input, or a numpy array for N-dimensional input.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.algorithms.regularity import spectral_entropy</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_airline</span>
<span class="sd">        &gt;&gt;&gt; airline = data_airline.values</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Airline Passengers Data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=airline, sf=12):.4f}&quot;)</span>
<span class="sd">        2.6538</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 2: Welch method for spectral entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; data_sine = np.sin(2 * np.pi * 1 * np.arange(400) / 100)</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=data_sine, sf=100, method=&#39;welch&#39;):.4f}&quot;)</span>
<span class="sd">        1.2938</span>

<span class="sd">        ```</span>

<span class="sd">    ??? equation &quot;Calculation&quot;</span>
<span class="sd">        The spectral entropy ($SE$) is defined as:</span>

<span class="sd">        $$</span>
<span class="sd">        H(x, f_s) = - \sum_{i=0}^{f_s/2} P(i) \times \log_2(P(i))</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $P(i)$ is the normalized power spectral density (PSD) at the $i$-th frequency band,</span>
<span class="sd">        - $f_s$ is the sampling frequency.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        - The power spectrum represents the energy of the signal at different frequencies. High spectral entropy indicates multiple sources or processes with different frequencies, while low spectral entropy suggests a dominant frequency or periodicity.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - [Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.](https://pubmed.ncbi.nlm.nih.gov/1714811/)</span>
<span class="sd">        - [Wikipedia: Spectral density](https://en.wikipedia.org/wiki/Spectral_density)</span>
<span class="sd">        - [Wikipedia: Welch&#39;s method](https://en.wikipedia.org/wiki/Welch%27s_method)</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_spectral_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
        <span class="n">nperseg</span><span class="o">=</span><span class="n">nperseg</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.svd_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">svd_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.svd_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">svd_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>SVD entropy is a measure of the complexity or randomness of a time series based on Singular Value Decomposition (SVD).</p>
<p>This function implements the <a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html"><code>svd_entropy()</code></a> function from the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>SVD entropy is calculated by first embedding the time series into a matrix, then performing SVD on that matrix to obtain the singular values. The entropy is then calculated from the normalized singular values.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape <code>(n_times,)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Order of the SVD entropy (embedding dimension).<br>
Defaults to <code>3</code>.</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Time delay (lag).<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(\log_2(\text{order}!)\)</span> to normalize the entropy between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>.<br>
Defaults to <code>False</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SVD entropy of the data set.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Setup</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.algorithms.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">svd_entropy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">data_random</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random</span> <span class="o">=</span> <span class="n">data_random</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Basic SVD entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">svd_entropy</span><span class="p">(</span><span class="n">random</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">1.3514</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="equation">
<summary>Calculation</summary>
<p>The SVD entropy is calculated as the Shannon entropy of the singular values of the embedded matrix.</p>
</details>
<details class="note">
<summary>Notes</summary>
<ul>
<li>Singular Value Decomposition (SVD) is a factorization of a real or complex matrix. It is the generalization of the eigendecomposition of a positive semidefinite normal matrix.</li>
</ul>
</details>
<details class="success">
<summary>Credit</summary>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html"><code>antropy.svd_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.regularity.approx_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>ts_stat_tests.algorithms.regularity.sample_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>ts_stat_tests.algorithms.regularity.permutation_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>ts_stat_tests.algorithms.regularity.spectral_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">svd_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        SVD entropy is a measure of the complexity or randomness of a time series based on Singular Value Decomposition (SVD).</span>

<span class="sd">        This function implements the [`svd_entropy()`](https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html) function from the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        SVD entropy is calculated by first embedding the time series into a matrix, then performing SVD on that matrix to obtain the singular values. The entropy is then calculated from the normalized singular values.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape `(n_times,)`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Order of the SVD entropy (embedding dimension).&lt;br&gt;</span>
<span class="sd">            Defaults to `3`.</span>
<span class="sd">        delay (int, optional):</span>
<span class="sd">            Time delay (lag).&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $\log_2(\text{order}!)$ to normalize the entropy between $0$ and $1$.&lt;br&gt;</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The SVD entropy of the data set.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Setup&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.algorithms.regularity import svd_entropy</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.utils.data import data_random</span>
<span class="sd">        &gt;&gt;&gt; random = data_random</span>

<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Example 1: Basic SVD entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{svd_entropy(random):.4f}&quot;)</span>
<span class="sd">        1.3514</span>

<span class="sd">        ```</span>

<span class="sd">    ??? equation &quot;Calculation&quot;</span>
<span class="sd">        The SVD entropy is calculated as the Shannon entropy of the singular values of the embedded matrix.</span>

<span class="sd">    ??? note &quot;Notes&quot;</span>
<span class="sd">        - Singular Value Decomposition (SVD) is a factorization of a real or complex matrix. It is the generalization of the eigendecomposition of a positive semidefinite normal matrix.</span>

<span class="sd">    ??? success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.svd_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html)</span>
<span class="sd">        - [`ts_stat_tests.algorithms.regularity.approx_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.regularity.sample_entropy`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.regularity.permutation_entropy`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.regularity.spectral_entropy`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_svd_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.instant", "search.highlight", "search.suggest", "toc.follow", "content.action.edit", "content.action.view", "content.code.select", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../assets/js/mathjax.js"></script>
      
    
  </body>
</html>