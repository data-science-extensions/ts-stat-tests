
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A Python library for performing statistical tests on time series data.">
      
      
        <meta name="author" content="[Chris Mahoney](mailto:chris@mahoneyconsultingservices.com)">
      
      
      
        <link rel="prev" href="../correlation/">
      
      
        <link rel="next" href="../normality/">
      
      
        
      
      
      <link rel="icon" href="../../assets/icons/1205526.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Regularity - Time Series Statistical Tests</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/style.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/admonitions.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/code_chunks.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/shortcodes.css">
    
      <link rel="stylesheet" href="https://site-assets.fontawesome.com/releases/v6.4.2/css/all.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#test-the-regularity-of-a-given-time-series-dataset" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),base=new URL("../.."),outdated=__md_get("__outdated",sessionStorage,base);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Time Series Statistical Tests" class="md-header__button md-logo" aria-label="Time Series Statistical Tests" data-md-component="logo">
      
  <img src="../../assets/icons/1205526.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Time Series Statistical Tests
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Regularity
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/data-science-extensions/ts-stat-tests" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </div>
  <div class="md-source__repository">
    ts-stat-tests
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../usage/overview/" class="md-tabs__link">
          
  
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Modules

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Time Series Statistical Tests" class="md-nav__button md-logo" aria-label="Time Series Statistical Tests" data-md-component="logo">
      
  <img src="../../assets/icons/1205526.svg" alt="logo">

    </a>
    Time Series Statistical Tests
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/data-science-extensions/ts-stat-tests" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </div>
  <div class="md-source__repository">
    ts-stat-tests
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Usage
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Usage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/changelog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Change Log
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Modules
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Modules
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../correlation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Correlation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Regularity
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Regularity
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Tests
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;regularity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.is_regular" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_regular
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;regularity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.is_regular" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_regular
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.approx_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;approx_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.sample_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sample_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.permutation_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;permutation_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.spectral_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;spectral_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.svd_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;svd_entropy
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../normality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Normality
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Tests
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Tests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;regularity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.is_regular" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_regular
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regularity-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      
        Regularity Algorithms
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Regularity Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;regularity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.tests.regularity.is_regular" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_regular
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;regularity
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â regularity">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.approx_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;approx_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.sample_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;sample_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.permutation_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;permutation_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.spectral_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;spectral_entropy
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ts_stat_tests.algorithms.regularity.svd_entropy" class="md-nav__link">
    <span class="md-ellipsis">
      
        <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;svd_entropy
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/data-science-extensions/ts-stat-tests/edit/main/docs/code/regularity.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/data-science-extensions/ts-stat-tests/raw/main/docs/code/regularity.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="test-the-regularity-of-a-given-time-series-dataset">Test the <code>regularity</code> of a given Time-Series Dataset<a class="headerlink" href="#test-the-regularity-of-a-given-time-series-dataset" title="Permanent link">ðŸ”—</a></h1>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">ðŸ”—</a></h2>
<div class="admonition abstract">
<p class="admonition-title">Summary</p>
<div class="admonition quote">
<p class="admonition-title">As stated by <a href="https://www.machinelearningplus.com/author/selva86/">Selva Prabhakaran</a>:</p>
<p>The more regular and repeatable patterns a time series has, the easier it is to forecast.</p>
<p>The 'Approximate Entropy' algorithm can be used to quantify the regularity and unpredictability of fluctuations in a time series.</p>
<p>The higher the approximate entropy, the more difficult it is to forecast it.</p>
<p>Another better alternate is the 'Sample Entropy'.</p>
<p>Sample Entropy is similar to approximate entropy but is more consistent in estimating the complexity even for smaller time series.</p>
<p>For example, a random time series with fewer data points can have a lower 'approximate entropy' than a more 'regular' time series, whereas, a longer random time series will have a higher 'approximate entropy'.</p>
<hr />
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 15V9h8V4.16L19.84 12 12 19.84V15z"/></svg></span> For more info, see: <a href="https://www.machinelearningplus.com/time-series/time-series-analysis-python/">Time Series Analysis in Python: A Comprehensive Guide with Examples</a>.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>To state that the data is 'regular' is to say that the data points are evenly spaced, regularly collected, and not missing data points (ie. do not contain excessive <code>NA</code> values). Logically, it is not always necessary to conduct the Test for Regularity on automatically collected data (like for example with Energy Prices, or Daily Temperature), however if this data was collected manually then it is highly recommended. If the data does not meet the requirements of Regularity, then it is necessary to return to the data collection plan, and revise the methodology used.</p>
<hr />
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 15V9h8V4.16L19.84 12 12 19.84V15z"/></svg></span> For more info, see: <a href="https://chrimaho.medium.com/ausenergyprices-737b9cbe5540">The Future of Australian Energy Prices: Time-Series Analysis of Historic Prices and Forecast for Future Prices</a>.</p>
</div>
<div class="admonition question">
<p class="admonition-title">Source Library</p>
<p>The <a href="https://raphaelvallat.com/antropy/build/html/index.html"><code>AntroPy</code></a> package was chosen because it provides well-tested and efficient implementations of approximate entropy, sample entropy, and related complexity measures for time-series data, is built on top of the scientific Python stack (NumPy/SciPy), and is actively maintained and open source, making it a reliable choice for reproducible statistical analysis.</p>
</div>
<div class="admonition example">
<p class="admonition-title">Source Module</p>
<p>All of the source code can be found within the modules:</p>
<ul>
<li><a href="https://github.com/chrimaho/ts-stat-tests/blob/main/src/ts_stat_tests/algorithms/regularity.py"><code>ts_stat_tests.algorithms.regularity</code></a>.</li>
<li><a href="https://github.com/chrimaho/ts-stat-tests/blob/main/src/ts_stat_tests/tests/regularity.py"><code>ts_stat_tests.tests.regularity</code></a>.</li>
</ul>
</div>
</div>
<h2 id="regularity-tests">Regularity Tests<a class="headerlink" href="#regularity-tests" title="Permanent link">ðŸ”—</a></h2>


<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.tests.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.tests.regularity</span>


<a href="#ts_stat_tests.tests.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains convenience functions and tests for regularity measures, allowing for easy access to different entropy algorithms.</p>
</div>










  <div class="doc doc-children">























































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">entropy</span>


<a href="#ts_stat_tests.tests.regularity.entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test for the entropy of a given data set.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is a convenience wrapper around the five underlying algorithms:<br>
- <a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>When the given value for <code>algorithm</code> is not valid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Entropy value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>approx_entropy</code>:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">)</span>
<span class="go">0.6451264780416452</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>sample_entropy</code>:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="go">0.6177074729583698</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>spectral_entropy</code>:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">2.6538040647031726</span>
</code></pre></div></td></tr></table></div></p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Advanced usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;welch&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">0.3371369604224553</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            regularity" href="#ts_stat_tests.tests.regularity.regularity"><code>regularity()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test for the entropy of a given data set.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function is a convenience wrapper around the five underlying algorithms:&lt;br&gt;</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]&lt;br&gt;</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]&lt;br&gt;</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]&lt;br&gt;</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]&lt;br&gt;</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: When the given value for `algorithm` is not valid.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The Entropy value.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        `approx_entropy`:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; entropy(x=data, algorithm=&quot;approx&quot;)</span>
<span class="sd">        0.6451264780416452</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `sample_entropy`:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; entropy(x=data, algorithm=&quot;sample&quot;)</span>
<span class="sd">        0.6177074729583698</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `spectral_entropy`:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; entropy(x=data, algorithm=&quot;spectral&quot;, sf=1)</span>
<span class="sd">        2.6538040647031726</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Advanced usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; spectral_entropy(data, 2, &quot;welch&quot;, normalize=True)</span>
<span class="sd">        0.3371369604224553</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`regularity()`][ts_stat_tests.tests.regularity.regularity]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;sampl&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="s2">&quot;sampl&quot;</span><span class="p">,</span> <span class="s2">&quot;samp&quot;</span><span class="p">),</span>
        <span class="s2">&quot;approx&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;app&quot;</span><span class="p">,</span> <span class="s2">&quot;approx&quot;</span><span class="p">),</span>
        <span class="s2">&quot;spect&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;spec&quot;</span><span class="p">,</span> <span class="s2">&quot;spect&quot;</span><span class="p">,</span> <span class="s2">&quot;spectral&quot;</span><span class="p">),</span>
        <span class="s2">&quot;perm&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;perm&quot;</span><span class="p">,</span> <span class="s2">&quot;permutation&quot;</span><span class="p">),</span>
        <span class="s2">&quot;svd&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span> <span class="s2">&quot;svd_entropy&quot;</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;sampl&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;approx&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;spect&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;svd&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">svd_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="n">generate_error_message</span><span class="p">(</span>
            <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;algorithm&quot;</span><span class="p">,</span>
            <span class="n">value_parsed</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">regularity</span>


<a href="#ts_stat_tests.tests.regularity.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">regularity</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test for the regularity of a given data set.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This is a pass-through, convenience wrapper around the <a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a> function.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Regularity value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>regularity</code> with <code>approx_entropy</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx_entropy&quot;</span><span class="p">)</span>
<span class="go">0.6451264780416452</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>regularity</code> with <code>sample_entropy</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample_entropy&quot;</span><span class="p">)</span>
<span class="go">0.6177074729583698</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>regularity</code> with <code>spectral_entropy</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral_entropy&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">2.6538040647031726</span>
</code></pre></div></td></tr></table></div></p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Advanced usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral_entropy&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;welch&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">0.3371369604224553</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">regularity</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test for the regularity of a given data set.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This is a pass-through, convenience wrapper around the [`entropy()`][ts_stat_tests.tests.regularity.entropy] function.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The Regularity value.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        `regularity` with `approx_entropy` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(x=data, algorithm=&quot;approx_entropy&quot;)</span>
<span class="sd">        0.6451264780416452</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `regularity` with `sample_entropy` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(x=data, algorithm=&quot;sample_entropy&quot;)</span>
<span class="sd">        0.6177074729583698</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `regularity` with `spectral_entropy` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(x=data, algorithm=&quot;spectral_entropy&quot;, sf=1)</span>
<span class="sd">        2.6538040647031726</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Advanced usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(data, algorithm=&quot;spectral_entropy&quot;, sf=2, method=&quot;welch&quot;, normalize=True)</span>
<span class="sd">        0.3371369604224553</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`entropy()`][ts_stat_tests.tests.regularity.entropy]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.is_regular" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">is_regular</span>


<a href="#ts_stat_tests.tests.regularity.is_regular" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">is_regular</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test whether a given data set is <code>regular</code> or not.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function implements the given algorithm (defined in the parameter <code>algorithm</code>), and returns a dictionary containing the relevant data:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The result of the test. Will be `True` if `entropy&lt;tolerance`, and `False` otherwise</span>
    <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># A `float` value, the result of the `entropy()` function</span>
    <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># A `float` value, which is the tolerance used for determining whether or not the `entropy` is `regular` or not</span>
<span class="p">}</span>
</code></pre></div></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="float">float</span>, <span title="int">int</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tolerance value used to determine whether or not the result is <code>regular</code> or not.<br>
- If <code>tolerance</code> is either type <code>int</code> or <code>float</code>, then this value will be used.<br>
- If <code>tolerance</code> is either <code>"default"</code> or <code>None</code>, then <code>tolerance</code> will be derived from <code>x</code> using the calculation:
    <div class="highlight"><pre><span></span><code><span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
- If any other value is given, then a <code>ValueError</code> error will be raised.<br>
Defaults to <code>"default"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;default&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the given <code>tolerance</code> parameter is invalid.</p>
<p>Valid options are:</p>
<ul>
<li>A number with type <code>float</code> or <code>int</code>, or</li>
<li>A string with value <code>default</code>, or</li>
<li>The value <code>None</code>.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="float">float</span>, <span title="bool">bool</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary with only 3 keys containing the results of the test:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
    <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
    <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Sample Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="go">{&quot;entropy&quot;: 0.6177074729583698, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Approx Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="go">{&quot;entropy&quot;: 0.6451264780416452, &quot;tolerance&quot;: 20, &quot;result&quot;: True}</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Spectral Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">{&quot;entropy&quot;: 0.4287365561752448, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            regularity" href="#ts_stat_tests.tests.regularity.regularity"><code>regularity()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_regular</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test whether a given data set is `regular` or not.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function implements the given algorithm (defined in the parameter `algorithm`), and returns a dictionary containing the relevant data:</span>
<span class="sd">        ```python</span>
<span class="sd">        {</span>
<span class="sd">            &quot;result&quot;: ...,  # The result of the test. Will be `True` if `entropy&lt;tolerance`, and `False` otherwise</span>
<span class="sd">            &quot;entropy&quot;: ...,  # A `float` value, the result of the `entropy()` function</span>
<span class="sd">            &quot;tolerance&quot;: ...,  # A `float` value, which is the tolerance used for determining whether or not the `entropy` is `regular` or not</span>
<span class="sd">        }</span>
<span class="sd">        ```</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>
<span class="sd">        tolerance (Union[str, float, int, None], optional):</span>
<span class="sd">            The tolerance value used to determine whether or not the result is `regular` or not.&lt;br&gt;</span>
<span class="sd">            - If `tolerance` is either type `int` or `float`, then this value will be used.&lt;br&gt;</span>
<span class="sd">            - If `tolerance` is either `&quot;default&quot;` or `None`, then `tolerance` will be derived from `x` using the calculation:</span>
<span class="sd">                ```python</span>
<span class="sd">                tolerance = 0.2 * np.std(a=x)</span>
<span class="sd">                ```</span>
<span class="sd">            - If any other value is given, then a `ValueError` error will be raised.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;default&quot;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        (ValueError): If the given `tolerance` parameter is invalid.</span>

<span class="sd">            Valid options are:</span>

<span class="sd">            - A number with type `float` or `int`, or</span>
<span class="sd">            - A string with value `default`, or</span>
<span class="sd">            - The value `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Dict[str, Union[str, float, bool]]):</span>
<span class="sd">            A dictionary with only 3 keys containing the results of the test:</span>
<span class="sd">            ```python</span>
<span class="sd">            {</span>
<span class="sd">                &quot;result&quot;: ...,</span>
<span class="sd">                &quot;entropy&quot;: ...,</span>
<span class="sd">                &quot;tolerance&quot;: ...,</span>
<span class="sd">            }</span>
<span class="sd">            ```</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Sample Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; is_regular(x=data, algorithm=&quot;sample&quot;)</span>
<span class="sd">        {&quot;entropy&quot;: 0.6177074729583698, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Approx Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; is_regular(x=data, algorithm=&quot;approx&quot;, tolerance=20)</span>
<span class="sd">        {&quot;entropy&quot;: 0.6451264780416452, &quot;tolerance&quot;: 20, &quot;result&quot;: True}</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Spectral Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; is_regular(x=data, algorithm=&quot;spectral&quot;, sf=1)</span>
<span class="sd">        {&quot;entropy&quot;: 0.4287365561752448, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`entropy()`][ts_stat_tests.tests.regularity.entropy]</span>
<span class="sd">        - [`regularity()`][ts_stat_tests.tests.regularity.regularity]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tolerance</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="n">tolerance</span>
    <span class="k">elif</span> <span class="n">tolerance</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid option for `tolerance` parameter: </span><span class="si">{</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Valid options are:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- A number with type `float` or `int`,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- A string with value `default`,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- The value `None`.&quot;</span>
        <span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="n">tol</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">result</span><span class="p">),</span>
        <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">),</span>
        <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">tol</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div><h2 id="regularity-algorithms">Regularity Algorithms<a class="headerlink" href="#regularity-algorithms" title="Permanent link">ðŸ”—</a></h2>


<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.tests.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.tests.regularity</span>


<a href="#ts_stat_tests.tests.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains convenience functions and tests for regularity measures, allowing for easy access to different entropy algorithms.</p>
</div>










  <div class="doc doc-children">























































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">entropy</span>


<a href="#ts_stat_tests.tests.regularity.entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test for the entropy of a given data set.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is a convenience wrapper around the five underlying algorithms:<br>
- <a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a><br>
- <a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>When the given value for <code>algorithm</code> is not valid.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Entropy value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>approx_entropy</code>:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">)</span>
<span class="go">0.6451264780416452</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>sample_entropy</code>:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="go">0.6177074729583698</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>spectral_entropy</code>:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">2.6538040647031726</span>
</code></pre></div></td></tr></table></div></p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Advanced usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;welch&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">0.3371369604224553</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            regularity" href="#ts_stat_tests.tests.regularity.regularity"><code>regularity()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test for the entropy of a given data set.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function is a convenience wrapper around the five underlying algorithms:&lt;br&gt;</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]&lt;br&gt;</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]&lt;br&gt;</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]&lt;br&gt;</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]&lt;br&gt;</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: When the given value for `algorithm` is not valid.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The Entropy value.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        `approx_entropy`:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; entropy(x=data, algorithm=&quot;approx&quot;)</span>
<span class="sd">        0.6451264780416452</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `sample_entropy`:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; entropy(x=data, algorithm=&quot;sample&quot;)</span>
<span class="sd">        0.6177074729583698</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `spectral_entropy`:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; entropy(x=data, algorithm=&quot;spectral&quot;, sf=1)</span>
<span class="sd">        2.6538040647031726</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Advanced usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; spectral_entropy(data, 2, &quot;welch&quot;, normalize=True)</span>
<span class="sd">        0.3371369604224553</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`regularity()`][ts_stat_tests.tests.regularity.regularity]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">options</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;sampl&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="s2">&quot;sampl&quot;</span><span class="p">,</span> <span class="s2">&quot;samp&quot;</span><span class="p">),</span>
        <span class="s2">&quot;approx&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;app&quot;</span><span class="p">,</span> <span class="s2">&quot;approx&quot;</span><span class="p">),</span>
        <span class="s2">&quot;spect&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;spec&quot;</span><span class="p">,</span> <span class="s2">&quot;spect&quot;</span><span class="p">,</span> <span class="s2">&quot;spectral&quot;</span><span class="p">),</span>
        <span class="s2">&quot;perm&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;perm&quot;</span><span class="p">,</span> <span class="s2">&quot;permutation&quot;</span><span class="p">),</span>
        <span class="s2">&quot;svd&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span> <span class="s2">&quot;svd_entropy&quot;</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;sampl&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;approx&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;spect&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;perm&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="ow">in</span> <span class="n">options</span><span class="p">[</span><span class="s2">&quot;svd&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">svd_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="n">generate_error_message</span><span class="p">(</span>
            <span class="n">parameter_name</span><span class="o">=</span><span class="s2">&quot;algorithm&quot;</span><span class="p">,</span>
            <span class="n">value_parsed</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
            <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">regularity</span>


<a href="#ts_stat_tests.tests.regularity.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">regularity</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test for the regularity of a given data set.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This is a pass-through, convenience wrapper around the <a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a> function.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Regularity value.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<p><code>regularity</code> with <code>approx_entropy</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx_entropy&quot;</span><span class="p">)</span>
<span class="go">0.6451264780416452</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>regularity</code> with <code>sample_entropy</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample_entropy&quot;</span><span class="p">)</span>
<span class="go">0.6177074729583698</span>
</code></pre></div></td></tr></table></div></p>
<hr />
<p><code>regularity</code> with <code>spectral_entropy</code> algorithm:
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral_entropy&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">2.6538040647031726</span>
</code></pre></div></td></tr></table></div></p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Advanced usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ts_stat_tests.tests.regularity</span><span class="w"> </span><span class="kn">import</span> <span class="n">regularity</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regularity</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral_entropy&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;welch&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">0.3371369604224553</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">regularity</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test for the regularity of a given data set.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This is a pass-through, convenience wrapper around the [`entropy()`][ts_stat_tests.tests.regularity.entropy] function.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The Regularity value.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        `regularity` with `approx_entropy` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(x=data, algorithm=&quot;approx_entropy&quot;)</span>
<span class="sd">        0.6451264780416452</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `regularity` with `sample_entropy` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(x=data, algorithm=&quot;sample_entropy&quot;)</span>
<span class="sd">        0.6177074729583698</span>
<span class="sd">        ```</span>

<span class="sd">        ---</span>

<span class="sd">        `regularity` with `spectral_entropy` algorithm:</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(x=data, algorithm=&quot;spectral_entropy&quot;, sf=1)</span>
<span class="sd">        2.6538040647031726</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Advanced usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from ts_stat_tests.tests.regularity import regularity</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; regularity(data, algorithm=&quot;spectral_entropy&quot;, sf=2, method=&quot;welch&quot;, normalize=True)</span>
<span class="sd">        0.3371369604224553</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`entropy()`][ts_stat_tests.tests.regularity.entropy]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.tests.regularity.is_regular" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">is_regular</span>


<a href="#ts_stat_tests.tests.regularity.is_regular" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">is_regular</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Test whether a given data set is <code>regular</code> or not.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function implements the given algorithm (defined in the parameter <code>algorithm</code>), and returns a dictionary containing the relevant data:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># The result of the test. Will be `True` if `entropy&lt;tolerance`, and `False` otherwise</span>
    <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># A `float` value, the result of the `entropy()` function</span>
    <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>  <span class="c1"># A `float` value, which is the tolerance used for determining whether or not the `entropy` is `regular` or not</span>
<span class="p">}</span>
</code></pre></div></p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data to be checked. Should be a <code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>algorithm</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Which entropy algorithm to use.<br>
- <code>sample_entropy()</code>: <code>["sample", "sampl", "samp"]</code><br>
- <code>approx_entropy()</code>: <code>["app", "approx"]</code><br>
- <code>spectral_entropy()</code>: <code>["spec", "spect", "spectral"]</code><br>
- <code>permutation_entropy()</code>: <code>["perm", "permutation"]</code><br>
- <code>svd_entropy()</code>: <code>["svd", "svd_entropy"]</code><br>
Defaults to <code>"sample"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;sample&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>.<br>
Only relevant when <code>algorithm=sample</code> or <code>algorithm=approx</code>.<br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Only relevant when <code>algorithm=spectral</code>.<br>
Defaults to <code>True</code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="float">float</span>, <span title="int">int</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tolerance value used to determine whether or not the result is <code>regular</code> or not.<br>
- If <code>tolerance</code> is either type <code>int</code> or <code>float</code>, then this value will be used.<br>
- If <code>tolerance</code> is either <code>"default"</code> or <code>None</code>, then <code>tolerance</code> will be derived from <code>x</code> using the calculation:
    <div class="highlight"><pre><span></span><code><span class="n">tolerance</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
- If any other value is given, then a <code>ValueError</code> error will be raised.<br>
Defaults to <code>"default"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;default&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the given <code>tolerance</code> parameter is invalid.</p>
<p>Valid options are:</p>
<ul>
<li>A number with type <code>float</code> or <code>int</code>, or</li>
<li>A string with value <code>default</code>, or</li>
<li>The value <code>None</code>.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="Dict">Dict</span>[<span title="str">str</span>, <span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="float">float</span>, <span title="bool">bool</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary with only 3 keys containing the results of the test:
<div class="highlight"><pre><span></span><code><span class="p">{</span>
    <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
    <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
    <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Sample Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;sample&quot;</span><span class="p">)</span>
<span class="go">{&quot;entropy&quot;: 0.6177074729583698, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Approx Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;approx&quot;</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="go">{&quot;entropy&quot;: 0.6451264780416452, &quot;tolerance&quot;: 20, &quot;result&quot;: True}</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Spectral Entropy</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">is_regular</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;spectral&quot;</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">{&quot;entropy&quot;: 0.4287365561752448, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</a></li>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" title="            entropy" href="#ts_stat_tests.tests.regularity.entropy"><code>entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            regularity" href="#ts_stat_tests.tests.regularity.regularity"><code>regularity()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>approx_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>sample_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>spectral_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>permutation_entropy()</code></a></li>
<li><a class="autorefs autorefs-internal" title="            svd_entropy" href="#ts_stat_tests.algorithms.regularity.svd_entropy"><code>svd_entropy()</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/tests/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">is_regular</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Test whether a given data set is `regular` or not.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function implements the given algorithm (defined in the parameter `algorithm`), and returns a dictionary containing the relevant data:</span>
<span class="sd">        ```python</span>
<span class="sd">        {</span>
<span class="sd">            &quot;result&quot;: ...,  # The result of the test. Will be `True` if `entropy&lt;tolerance`, and `False` otherwise</span>
<span class="sd">            &quot;entropy&quot;: ...,  # A `float` value, the result of the `entropy()` function</span>
<span class="sd">            &quot;tolerance&quot;: ...,  # A `float` value, which is the tolerance used for determining whether or not the `entropy` is `regular` or not</span>
<span class="sd">        }</span>
<span class="sd">        ```</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            The data to be checked. Should be a `1-D` or `N-D` data array.</span>
<span class="sd">        algorithm (str, optional):</span>
<span class="sd">            Which entropy algorithm to use.&lt;br&gt;</span>
<span class="sd">            - `sample_entropy()`: `[&quot;sample&quot;, &quot;sampl&quot;, &quot;samp&quot;]`&lt;br&gt;</span>
<span class="sd">            - `approx_entropy()`: `[&quot;app&quot;, &quot;approx&quot;]`&lt;br&gt;</span>
<span class="sd">            - `spectral_entropy()`: `[&quot;spec&quot;, &quot;spect&quot;, &quot;spectral&quot;]`&lt;br&gt;</span>
<span class="sd">            - `permutation_entropy()`: `[&quot;perm&quot;, &quot;permutation&quot;]`&lt;br&gt;</span>
<span class="sd">            - `svd_entropy()`: `[&quot;svd&quot;, &quot;svd_entropy&quot;]`&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;sample&quot;`.</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance).&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=sample` or `algorithm=approx`.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Only relevant when `algorithm=spectral`.&lt;br&gt;</span>
<span class="sd">            Defaults to `True`.</span>
<span class="sd">        tolerance (Union[str, float, int, None], optional):</span>
<span class="sd">            The tolerance value used to determine whether or not the result is `regular` or not.&lt;br&gt;</span>
<span class="sd">            - If `tolerance` is either type `int` or `float`, then this value will be used.&lt;br&gt;</span>
<span class="sd">            - If `tolerance` is either `&quot;default&quot;` or `None`, then `tolerance` will be derived from `x` using the calculation:</span>
<span class="sd">                ```python</span>
<span class="sd">                tolerance = 0.2 * np.std(a=x)</span>
<span class="sd">                ```</span>
<span class="sd">            - If any other value is given, then a `ValueError` error will be raised.&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;default&quot;`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        (ValueError): If the given `tolerance` parameter is invalid.</span>

<span class="sd">            Valid options are:</span>

<span class="sd">            - A number with type `float` or `int`, or</span>
<span class="sd">            - A string with value `default`, or</span>
<span class="sd">            - The value `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Dict[str, Union[str, float, bool]]):</span>
<span class="sd">            A dictionary with only 3 keys containing the results of the test:</span>
<span class="sd">            ```python</span>
<span class="sd">            {</span>
<span class="sd">                &quot;result&quot;: ...,</span>
<span class="sd">                &quot;entropy&quot;: ...,</span>
<span class="sd">                &quot;tolerance&quot;: ...,</span>
<span class="sd">            }</span>
<span class="sd">            ```</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Sample Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; is_regular(x=data, algorithm=&quot;sample&quot;)</span>
<span class="sd">        {&quot;entropy&quot;: 0.6177074729583698, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Approx Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; is_regular(x=data, algorithm=&quot;approx&quot;, tolerance=20)</span>
<span class="sd">        {&quot;entropy&quot;: 0.6451264780416452, &quot;tolerance&quot;: 20, &quot;result&quot;: True}</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Spectral Entropy&quot;}</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; data = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; is_regular(x=data, algorithm=&quot;spectral&quot;, sf=1)</span>
<span class="sd">        {&quot;entropy&quot;: 0.4287365561752448, &quot;tolerance&quot;: 23.909808306554297, &quot;result&quot;: True}</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049.</span>
<span class="sd">        - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`entropy()`][ts_stat_tests.tests.regularity.entropy]</span>
<span class="sd">        - [`regularity()`][ts_stat_tests.tests.regularity.regularity]</span>
<span class="sd">        - [`approx_entropy()`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`sample_entropy()`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`spectral_entropy()`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`permutation_entropy()`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`svd_entropy()`][ts_stat_tests.algorithms.regularity.svd_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tolerance</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="n">tolerance</span>
    <span class="k">elif</span> <span class="n">tolerance</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid option for `tolerance` parameter: </span><span class="si">{</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Valid options are:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- A number with type `float` or `int`,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- A string with value `default`,</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;- The value `None`.&quot;</span>
        <span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">regularity</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="n">tol</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;result&quot;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">result</span><span class="p">),</span>
        <span class="s2">&quot;entropy&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">),</span>
        <span class="s2">&quot;tolerance&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">tol</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h3 id="ts_stat_tests.algorithms.regularity" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">ts_stat_tests.algorithms.regularity</span>


<a href="#ts_stat_tests.algorithms.regularity" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>This module contains algorithms to compute regularity measures for time series data, including approximate entropy, sample entropy, spectral entropy, and permutation entropy.</p>
</div>










  <div class="doc doc-children">



































































<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.approx_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">approx_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.approx_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">approx_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Approximate entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Approximate entropy is a technique used to quantify the amount of regularity and the unpredictability of fluctuations over time-series data. Smaller values indicates that the data is more regular and predictable.</p>
<p>The tolerance value (<span class="arithmatex">\(r\)</span>) is set to <span class="arithmatex">\(0.2 \times std(x)\)</span>.</p>
<p>To calculate approximate entropy, we first need to define a window size or scale factor, which determines the length of the subsequences that are used to compare the similarity of the time series. We then compare all possible pairs of subsequences within the time series and calculate the probability that two subsequences are within a certain tolerance level of each other, where the tolerance level is usually expressed as a percentage of the standard deviation of the time series.</p>
<p>The approximate entropy is then defined as the negative natural logarithm of the average probability of similarity across all possible pairs of subsequences, normalized by the length of the time series and the scale factor.</p>
<p>The approximate entropy measure is useful in a variety of applications, such as the analysis of physiological signals, financial time series, and climate data. It can be used to detect changes in the regularity or predictability of a time series over time, and can provide insights into the underlying dynamics or mechanisms that generate the signal. For example, a decrease in approximate entropy may indicate the onset of a disease or a shift in the underlying physiological state, while an increase in approximate entropy may suggest the presence of noise or other external influences on the system.</p>
<p>The equation for ApEn is:</p>
<div class="arithmatex">\[
ApEn(m, r, N) = Ï†m(r) - Ï†m+1(r)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(m\)</span> is the embedding dimension,</li>
<li><span class="arithmatex">\(r\)</span> is the tolerance or similarity criterion,</li>
<li><span class="arithmatex">\(N\)</span> is the length of the time series, and</li>
<li><span class="arithmatex">\(Ï†m(r)\)</span> and <span class="arithmatex">\(Ï†m+1(r)\)</span> are the logarithms of the probabilities that two sequences of m data points in the time series that are similar to each other within a tolerance <span class="arithmatex">\(r\)</span> remain similar for the next data point, for <span class="arithmatex">\(m\)</span> and <span class="arithmatex">\(m+1\)</span>, respectively.</li>
</ul>
<div class="highlight"><pre><span></span><code>ApEn(m, r, N) = Ï†m(r) - Ï†m+1(r)
</code></pre></div>
<p>The calculation of ApEn involves the following steps:</p>
<ol>
<li>Create a set of vectors, each containing <span class="arithmatex">\(m\)</span> data points from the time series, where <span class="arithmatex">\(m\)</span> is the embedding dimension.</li>
<li>Calculate the Euclidean distance between each pair of vectors and count the number of pairs that are within a distance <span class="arithmatex">\(r\)</span> of each other.</li>
<li>Compute the probabilities <span class="arithmatex">\(Ï†m(r)\)</span> and <span class="arithmatex">\(Ï†m+1(r)\)</span> using the counts from step 2.</li>
<li>Compute <span class="arithmatex">\(ApEn(m, r, N)\)</span> using the equation above.</li>
</ol>
<p>The value of ApEn ranges from zero (<span class="arithmatex">\(0\)</span>) to infinity (<span class="arithmatex">\(\infty\)</span>), with lower values indicating higher regularity or predictability in the time series. A time series with high ApEn is more unpredictable or irregular, whereas a time series with low ApEn is more regular or predictable.</p>
<p>ApEn is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks.</p>
<p>When calculating the Approximate entropy requires the specification of a set of parameters that determine the characteristics of the time series. One of these parameters is the <em>embedding dimension</em>, which determines the number of values that are used to construct each permutation pattern.</p>
<p>The embedding dimension is important in the calculation of permutation entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting permutation entropy value may not accurately reflect the underlying complexity of the signal. On the other hand, if the embedding dimension is too large, we may overfit the data and produce a permutation entropy value that is overly sensitive to noise or other random fluctuations.</p>
<p>Choosing an appropriate embedding dimension is therefore crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape (n_times).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tolerance level or similarity criterion. If <code>None</code> (default), it is set to <span class="arithmatex">\(0.2     imes std(x)\)</span>.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>. For a full list of all available metrics, see <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise.distance_metrics</code></a> and <a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a><br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Approximate Entropy score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="note" open="open">
<summary>Notes</summary>
<p><strong>Inputs</strong>:</p>
<ul>
<li><code>x</code> is a 1-dimensional array.<br>
    It represents time-series data, ideally with each element in the array being a measurement or value taken at regular time intervuls over the length of the array. The exact number of elements (or length of the array) can realistically be greater than 30 elements long, but ideally should be a few hundred elements long, and is even better when it is a few thousand elements long.</li>
</ul>
<p><strong>Settings</strong>:</p>
<ul>
<li>
<p><code>order</code> is used for determining the number of values that are used to construct each permutation pattern.</p>
<ul>
<li>If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting approximate entropy value may not accurately reflect the underlying complexity of the signal.</li>
<li>If the embedding dimension is too large, we may overfit the data and produce an approximate entropy value that is overly sensitive to noise or other random fluctuations.</li>
</ul>
</li>
<li>
<p><code>metric</code> is used for determining which distance metric to use for the underlying distance-space between two time series.</p>
<ul>
<li>The Chebyshev metric is often used when calculating approximate entropy because it is a robust and computationally efficient way to measure the distance between two time series. The Chebyshev distance between two vectors is defined as the maximum absolute difference between their corresponding components. When comparing two subsequences in the time series, the Chebyshev distance is calculated by taking the maximum absolute difference between their corresponding values at each point in time.</li>
<li>The use of the Chebyshev metric in approximate entropy calculation has been found to be effective in detecting the presence of patterns or regularities in a time series. This is because the Chebyshev metric is less sensitive to outliers and noise in the data than other metrics, such as Euclidean distance or Manhattan distance.</li>
<li>However, other metrics can also be used to calculate approximate entropy, depending on the specific characteristics of the time series being analyzed and the research question at hand. For example, the Euclidean distance can be used as an alternative to the Chebyshev metric, especially when the time series is relatively smooth and does not contain sharp spikes or discontinuities.</li>
<li>In addition, other metrics such as Hamming distance or Cosine distance can be used in cases where the time series represents binary or categorical data, or when the time series has a natural geometric interpretation, respectively.</li>
<li>Ultimately, the choice of metric depends on the specific application and the properties of the time series being analyzed. The use of different metrics can lead to different results and insights, and it is important to carefully consider the advantages and limitations of each approach before making a decision.</li>
</ul>
</li>
</ul>
<p><strong>Outputs</strong>:</p>
<ul>
<li>A single number is returned, which represents the entropy score. It will be a float value, where numbers close to <span class="arithmatex">\(0\)</span> indicate <em>less</em> entropy; meaning that it is <em>more</em> stable, regular and predictable.</li>
</ul>
<p><strong>Expectations</strong>:</p>
<ul>
<li>A returned value close to <span class="arithmatex">\(0\)</span> means that it is quite stable.</li>
<li>'close to zero' is highly interpretable and context specific. For example, if you generate a sequence of random numbers between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>, then 'close to zero' would need to be down to 5 or 6 decimal places. But if you're looking at a sequence of numbers which range between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1000\)</span>, then 'close to zero' would be anything less than, say, <span class="arithmatex">\(20\)</span>.</li>
<li>When using other available metrics (such as <code>'euclidean'</code>, '<code>hamming'</code>, <code>'cosine'</code>, etc), the results may be a little unexpected. So, it's best to do some research around which metric is best to use for the specific purposes at hand.</li>
</ul>
</details>
<div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Prepare data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.processes</span><span class="w"> </span><span class="kn">import</span> <span class="n">noise</span> <span class="k">as</span> <span class="n">sn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_airline</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_noise</span> <span class="o">=</span> <span class="n">sn</span><span class="o">.</span><span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_random</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_airline</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.6451</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Gaussian noise</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.1958</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Euclidean metric</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">1.5120</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Random data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">approx_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_random</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">1.8030</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039">Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049</a></li>
<li><a href="https://scikit-learn.org/stable/modules/metrics.html#metrics">SK-Learn: Pairwise metrics, Affinities and Kernels</a></li>
<li><a href="https://docs.scipy.org/doc/scipy/tutorial/spatial.html">Spatial data structures and algorithms</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.app_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.approx_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.perm_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>ts_stat_tests.algorithms.spectral_entropy</code></a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html"><code>sklearn.neighbors.KDTree</code></a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise_distances</code></a></li>
<li><a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">approx_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Approximate entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Approximate entropy is a technique used to quantify the amount of regularity and the unpredictability of fluctuations over time-series data. Smaller values indicates that the data is more regular and predictable.</span>

<span class="sd">        The tolerance value ($r$) is set to $0.2 \\times std(x)$.</span>

<span class="sd">        To calculate approximate entropy, we first need to define a window size or scale factor, which determines the length of the subsequences that are used to compare the similarity of the time series. We then compare all possible pairs of subsequences within the time series and calculate the probability that two subsequences are within a certain tolerance level of each other, where the tolerance level is usually expressed as a percentage of the standard deviation of the time series.</span>

<span class="sd">        The approximate entropy is then defined as the negative natural logarithm of the average probability of similarity across all possible pairs of subsequences, normalized by the length of the time series and the scale factor.</span>

<span class="sd">        The approximate entropy measure is useful in a variety of applications, such as the analysis of physiological signals, financial time series, and climate data. It can be used to detect changes in the regularity or predictability of a time series over time, and can provide insights into the underlying dynamics or mechanisms that generate the signal. For example, a decrease in approximate entropy may indicate the onset of a disease or a shift in the underlying physiological state, while an increase in approximate entropy may suggest the presence of noise or other external influences on the system.</span>

<span class="sd">        The equation for ApEn is:</span>

<span class="sd">        $$</span>
<span class="sd">        ApEn(m, r, N) = Ï†m(r) - Ï†m+1(r)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $m$ is the embedding dimension,</span>
<span class="sd">        - $r$ is the tolerance or similarity criterion,</span>
<span class="sd">        - $N$ is the length of the time series, and</span>
<span class="sd">        - $Ï†m(r)$ and $Ï†m+1(r)$ are the logarithms of the probabilities that two sequences of m data points in the time series that are similar to each other within a tolerance $r$ remain similar for the next data point, for $m$ and $m+1$, respectively.</span>

<span class="sd">        ```</span>
<span class="sd">        ApEn(m, r, N) = Ï†m(r) - Ï†m+1(r)</span>
<span class="sd">        ```</span>

<span class="sd">        The calculation of ApEn involves the following steps:</span>

<span class="sd">        1. Create a set of vectors, each containing $m$ data points from the time series, where $m$ is the embedding dimension.</span>
<span class="sd">        1. Calculate the Euclidean distance between each pair of vectors and count the number of pairs that are within a distance $r$ of each other.</span>
<span class="sd">        1. Compute the probabilities $Ï†m(r)$ and $Ï†m+1(r)$ using the counts from step 2.</span>
<span class="sd">        1. Compute $ApEn(m, r, N)$ using the equation above.</span>

<span class="sd">        The value of ApEn ranges from zero ($0$) to infinity ($\\infty$), with lower values indicating higher regularity or predictability in the time series. A time series with high ApEn is more unpredictable or irregular, whereas a time series with low ApEn is more regular or predictable.</span>

<span class="sd">        ApEn is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks.</span>

<span class="sd">        When calculating the Approximate entropy requires the specification of a set of parameters that determine the characteristics of the time series. One of these parameters is the _embedding dimension_, which determines the number of values that are used to construct each permutation pattern.</span>

<span class="sd">        The embedding dimension is important in the calculation of permutation entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting permutation entropy value may not accurately reflect the underlying complexity of the signal. On the other hand, if the embedding dimension is too large, we may overfit the data and produce a permutation entropy value that is overly sensitive to noise or other random fluctuations.</span>

<span class="sd">        Choosing an appropriate embedding dimension is therefore crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape (n_times).</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        tolerance (Optional[float]):</span>
<span class="sd">            Tolerance level or similarity criterion. If `None` (default), it is set to $0.2 \times std(x)$.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance). For a full list of all available metrics, see [`sklearn.metrics.pairwise.distance_metrics`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html) and [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            Approximate Entropy score.</span>

<span class="sd">    ???+ note &quot;Notes&quot;</span>

<span class="sd">        **Inputs**:</span>

<span class="sd">        - `x` is a 1-dimensional array.&lt;br&gt;</span>
<span class="sd">            It represents time-series data, ideally with each element in the array being a measurement or value taken at regular time intervuls over the length of the array. The exact number of elements (or length of the array) can realistically be greater than 30 elements long, but ideally should be a few hundred elements long, and is even better when it is a few thousand elements long.</span>

<span class="sd">        **Settings**:</span>

<span class="sd">        - `order` is used for determining the number of values that are used to construct each permutation pattern.</span>
<span class="sd">            - If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting approximate entropy value may not accurately reflect the underlying complexity of the signal.</span>
<span class="sd">            - If the embedding dimension is too large, we may overfit the data and produce an approximate entropy value that is overly sensitive to noise or other random fluctuations.</span>

<span class="sd">        - `metric` is used for determining which distance metric to use for the underlying distance-space between two time series.</span>
<span class="sd">            - The Chebyshev metric is often used when calculating approximate entropy because it is a robust and computationally efficient way to measure the distance between two time series. The Chebyshev distance between two vectors is defined as the maximum absolute difference between their corresponding components. When comparing two subsequences in the time series, the Chebyshev distance is calculated by taking the maximum absolute difference between their corresponding values at each point in time.</span>
<span class="sd">            - The use of the Chebyshev metric in approximate entropy calculation has been found to be effective in detecting the presence of patterns or regularities in a time series. This is because the Chebyshev metric is less sensitive to outliers and noise in the data than other metrics, such as Euclidean distance or Manhattan distance.</span>
<span class="sd">            - However, other metrics can also be used to calculate approximate entropy, depending on the specific characteristics of the time series being analyzed and the research question at hand. For example, the Euclidean distance can be used as an alternative to the Chebyshev metric, especially when the time series is relatively smooth and does not contain sharp spikes or discontinuities.</span>
<span class="sd">            - In addition, other metrics such as Hamming distance or Cosine distance can be used in cases where the time series represents binary or categorical data, or when the time series has a natural geometric interpretation, respectively.</span>
<span class="sd">            - Ultimately, the choice of metric depends on the specific application and the properties of the time series being analyzed. The use of different metrics can lead to different results and insights, and it is important to carefully consider the advantages and limitations of each approach before making a decision.</span>

<span class="sd">        **Outputs**:</span>

<span class="sd">        - A single number is returned, which represents the entropy score. It will be a float value, where numbers close to $0$ indicate _less_ entropy; meaning that it is _more_ stable, regular and predictable.</span>

<span class="sd">        **Expectations**:</span>

<span class="sd">        - A returned value close to $0$ means that it is quite stable.</span>
<span class="sd">        - &#39;close to zero&#39; is highly interpretable and context specific. For example, if you generate a sequence of random numbers between $0$ and $1$, then &#39;close to zero&#39; would need to be down to 5 or 6 decimal places. But if you&#39;re looking at a sequence of numbers which range between $0$ and $1000$, then &#39;close to zero&#39; would be anything less than, say, $20$.</span>
<span class="sd">        - When using other available metrics (such as `&#39;euclidean&#39;`, &#39;`hamming&#39;`, `&#39;cosine&#39;`, etc), the results may be a little unexpected. So, it&#39;s best to do some research around which metric is best to use for the specific purposes at hand.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Prepare data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.processes import noise as sn</span>
<span class="sd">        &gt;&gt;&gt; data_airline = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng(seed=42)</span>
<span class="sd">        &gt;&gt;&gt; data_noise = sn.FractionalGaussianNoise(hurst=0.5, rng=rng).sample(10000)</span>
<span class="sd">        &gt;&gt;&gt; data_random = rng.random(1000)</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{approx_entropy(x=data_airline):.4f}&quot;)</span>
<span class="sd">        0.6451</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Gaussian noise&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{approx_entropy(x=data_noise, order=2):.4f}&quot;)</span>
<span class="sd">        2.1958</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Euclidean metric&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{approx_entropy(x=data_noise, order=3, metric=&#39;euclidean&#39;):.4f}&quot;)</span>
<span class="sd">        1.5120</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Random data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{approx_entropy(x=data_random):.4f}&quot;)</span>
<span class="sd">        1.8030</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - [Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049](https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039)</span>
<span class="sd">        - [SK-Learn: Pairwise metrics, Affinities and Kernels](https://scikit-learn.org/stable/modules/metrics.html#metrics)</span>
<span class="sd">        - [Spatial data structures and algorithms](https://docs.scipy.org/doc/scipy/tutorial/spatial.html)</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">        - [`ts_stat_tests.algorithms.app_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.approx_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.perm_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.spectral_entropy`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html)</span>
<span class="sd">        - [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html)</span>
<span class="sd">        - [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_app_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.sample_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">sample_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.sample_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">sample_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Sample entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Sample entropy is a modification of approximate entropy, used for assessing the complexity of physiological time-series signals. It has two advantages over approximate entropy: data length independence and a relatively trouble-free implementation. Large values indicate high complexity whereas smaller values characterize more self-similar and regular signals.</p>
<p>The equation for sample entropy (SampEn) is as follows:</p>
<div class="arithmatex">\[
SampEn(m, r, N) = - \log \left( \frac {Cm(r)} {Cm+1(r)} \right)
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(m\)</span> is the embedding dimension,</li>
<li><span class="arithmatex">\(r\)</span> is the tolerance or similarity criterion,</li>
<li><span class="arithmatex">\(N\)</span> is the length of the time series, and</li>
<li><span class="arithmatex">\(Cm(r)\)</span> and <span class="arithmatex">\(Cm+1(r)\)</span> are the number of <span class="arithmatex">\(m\)</span>-tuples (vectors of <span class="arithmatex">\(m\)</span> consecutive data points) that have a distance less than or equal to <span class="arithmatex">\(r\)</span>, and <span class="arithmatex">\((m+1)\)</span>-tuples with the same property, respectively. The log function is the natural logarithm.</li>
</ul>
<div class="highlight"><pre><span></span><code>SampEn(m, r, N) = -log( Cm(r) / Cm+1(r) )
</code></pre></div>
<p>The calculation of sample entropy involves the following steps:</p>
<ol>
<li>Choose the values of <span class="arithmatex">\(m\)</span> and <span class="arithmatex">\(r\)</span>.</li>
<li>Construct <span class="arithmatex">\(m\)</span>-tuples from the time series data.</li>
<li>Compute the number of <span class="arithmatex">\(m\)</span>-tuples that are within a distance r of each other (<span class="arithmatex">\(Cm(r)\)</span>).</li>
<li>Compute the number of <span class="arithmatex">\((m+1)\)</span>-tuples that are within a distance r of each other (<span class="arithmatex">\(Cm+1(r)\)</span>).</li>
<li>Compute the value of <span class="arithmatex">\(SampEn\)</span> using the formula above.</li>
</ol>
<p>The value of SampEn ranges from zero (<span class="arithmatex">\(0\)</span>) to infinity (<span class="arithmatex">\(\infty\)</span>), with lower values indicating higher regularity or predictability in the time series. A time series with high <span class="arithmatex">\(SampEn\)</span> is more unpredictable or irregular, whereas a time series with low <span class="arithmatex">\(SampEn\)</span> is more regular or predictable.</p>
<p>Sample entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks.</p>
<p>Note that if <code>metric == 'chebyshev'</code> and <code>len(x) &lt; 5000</code> points, then the sample entropy is computed using a fast custom Numba script. For other distance metric or longer time-series, the sample entropy is computed using a code from the <a href="https://mne.tools/mne-features/"><code>mne-features</code></a> package by Jean-Baptiste Schiratti and Alexandre Gramfort (requires sklearn).</p>
<p>To calculate the Sample entropy requires the specification of a set of parameters that determine the characteristics of the time series. One of these parameters is the <em>embedding dimension</em>, which determines the number of values that are used to construct each permutation pattern.</p>
<p>The embedding dimension is important in the calculation of permutation entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting permutation entropy value may not accurately reflect the underlying complexity of the signal. On the other hand, if the embedding dimension is too large, we may overfit the data and produce a permutation entropy value that is overly sensitive to noise or other random fluctuations.</p>
<p>Choosing an appropriate embedding dimension is therefore crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape (n_times).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Embedding dimension.<br>
Defaults to <code>2</code>.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tolerance</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Tolerance level or similarity criterion. If <code>None</code> (default), it is set to <span class="arithmatex">\(0.2     imes std(x)\)</span>.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>metric</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_KDTREE_METRIC_OPTIONS">VALID_KDTREE_METRIC_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the distance metric function used with <a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree"><code>sklearn.neighbors.KDTree</code></a>. Default is to use the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">Chebyshev distance</a>. For a full list of all available metrics, see <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise.distance_metrics</code></a> and <a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a><br>
Defaults to <code>"chebyshev"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;chebyshev&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sample Entropy score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Prepare data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.processes</span><span class="w"> </span><span class="kn">import</span> <span class="n">noise</span> <span class="k">as</span> <span class="n">sn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_airline</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_noise</span> <span class="o">=</span> <span class="n">sn</span><span class="o">.</span><span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_random</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_sine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3000</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_airline</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.6177</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Gaussian noise</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.1819</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Euclidean metric</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.6806</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Random data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_random</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.1595</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Sine wave</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_sine</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.1633</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Straight line</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sample_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_line</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.0000</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039">Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049</a></li>
<li><a href="https://scikit-learn.org/stable/modules/metrics.html#metrics">SK-Learn: Pairwise metrics, Affinities and Kernels</a></li>
<li><a href="https://docs.scipy.org/doc/scipy/tutorial/spatial.html">Spatial data structures and algorithms</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.app_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.approx_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.perm_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>ts_stat_tests.algorithms.spectral_entropy</code></a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html"><code>sklearn.neighbors.KDTree</code></a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html"><code>sklearn.metrics.pairwise_distances</code></a></li>
<li><a href="https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"><code>scipy.spatial.distance</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">tolerance</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">VALID_KDTREE_METRIC_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;chebyshev&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Sample entropy is a measure of the amount of regularity or predictability in a time series. It is used to quantify the degree of self-similarity of a signal over different time scales, and can be useful for detecting underlying patterns or trends in data.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Sample entropy is a modification of approximate entropy, used for assessing the complexity of physiological time-series signals. It has two advantages over approximate entropy: data length independence and a relatively trouble-free implementation. Large values indicate high complexity whereas smaller values characterize more self-similar and regular signals.</span>

<span class="sd">        The equation for sample entropy (SampEn) is as follows:</span>

<span class="sd">        $$</span>
<span class="sd">        SampEn(m, r, N) = - \\log \\left( \\frac {Cm(r)} {Cm+1(r)} \\right)</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $m$ is the embedding dimension,</span>
<span class="sd">        - $r$ is the tolerance or similarity criterion,</span>
<span class="sd">        - $N$ is the length of the time series, and</span>
<span class="sd">        - $Cm(r)$ and $Cm+1(r)$ are the number of $m$-tuples (vectors of $m$ consecutive data points) that have a distance less than or equal to $r$, and $(m+1)$-tuples with the same property, respectively. The log function is the natural logarithm.</span>

<span class="sd">        ```</span>
<span class="sd">        SampEn(m, r, N) = -log( Cm(r) / Cm+1(r) )</span>
<span class="sd">        ```</span>

<span class="sd">        The calculation of sample entropy involves the following steps:</span>

<span class="sd">        1. Choose the values of $m$ and $r$.</span>
<span class="sd">        1. Construct $m$-tuples from the time series data.</span>
<span class="sd">        1. Compute the number of $m$-tuples that are within a distance r of each other ($Cm(r)$).</span>
<span class="sd">        1. Compute the number of $(m+1)$-tuples that are within a distance r of each other ($Cm+1(r)$).</span>
<span class="sd">        1. Compute the value of $SampEn$ using the formula above.</span>

<span class="sd">        The value of SampEn ranges from zero ($0$) to infinity ($\\infty$), with lower values indicating higher regularity or predictability in the time series. A time series with high $SampEn$ is more unpredictable or irregular, whereas a time series with low $SampEn$ is more regular or predictable.</span>

<span class="sd">        Sample entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks.</span>

<span class="sd">        Note that if `metric == &#39;chebyshev&#39;` and `len(x) &lt; 5000` points, then the sample entropy is computed using a fast custom Numba script. For other distance metric or longer time-series, the sample entropy is computed using a code from the [`mne-features`](https://mne.tools/mne-features/) package by Jean-Baptiste Schiratti and Alexandre Gramfort (requires sklearn).</span>

<span class="sd">        To calculate the Sample entropy requires the specification of a set of parameters that determine the characteristics of the time series. One of these parameters is the _embedding dimension_, which determines the number of values that are used to construct each permutation pattern.</span>

<span class="sd">        The embedding dimension is important in the calculation of permutation entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting permutation entropy value may not accurately reflect the underlying complexity of the signal. On the other hand, if the embedding dimension is too large, we may overfit the data and produce a permutation entropy value that is overly sensitive to noise or other random fluctuations.</span>

<span class="sd">        Choosing an appropriate embedding dimension is therefore crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape (n_times).</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Embedding dimension.&lt;br&gt;</span>
<span class="sd">            Defaults to `2`.</span>
<span class="sd">        tolerance (Optional[float]):</span>
<span class="sd">            Tolerance level or similarity criterion. If `None` (default), it is set to $0.2 \times std(x)$.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        metric (VALID_KDTREE_METRIC_OPTIONS):</span>
<span class="sd">            Name of the distance metric function used with [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree). Default is to use the [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance). For a full list of all available metrics, see [`sklearn.metrics.pairwise.distance_metrics`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html) and [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;chebyshev&quot;`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            Sample Entropy score.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Prepare data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.processes import noise as sn</span>
<span class="sd">        &gt;&gt;&gt; data_airline = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng(seed=42)</span>
<span class="sd">        &gt;&gt;&gt; data_noise = sn.FractionalGaussianNoise(hurst=0.5, rng=rng).sample(10000)</span>
<span class="sd">        &gt;&gt;&gt; data_random = rng.random(1000)</span>
<span class="sd">        &gt;&gt;&gt; data_sine = np.sin(2 * np.pi * 1 * np.arange(3000) / 100)</span>
<span class="sd">        &gt;&gt;&gt; data_line = np.arange(1000)</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=data_airline):.4f}&quot;)</span>
<span class="sd">        0.6177</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Gaussian noise&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=data_noise, order=2):.4f}&quot;)</span>
<span class="sd">        2.1819</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Euclidean metric&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=data_noise, order=3, metric=&#39;euclidean&#39;):.4f}&quot;)</span>
<span class="sd">        2.6806</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Random data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=data_random):.4f}&quot;)</span>
<span class="sd">        2.1595</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Sine wave&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=data_sine):.4f}&quot;)</span>
<span class="sd">        0.1633</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Straight line&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{sample_entropy(x=data_line):.4f}&quot;)</span>
<span class="sd">        0.0000</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - [Richman, J. S. et al. (2000). Physiological time-series analysis using approximate entropy and sample entropy. American Journal of Physiology-Heart and Circulatory Physiology, 278(6), H2039-H2049](https://journals.physiology.org/doi/epdf/10.1152/ajpheart.2000.278.6.H2039)</span>
<span class="sd">        - [SK-Learn: Pairwise metrics, Affinities and Kernels](https://scikit-learn.org/stable/modules/metrics.html#metrics)</span>
<span class="sd">        - [Spatial data structures and algorithms](https://docs.scipy.org/doc/scipy/tutorial/spatial.html)</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">        - [`ts_stat_tests.algorithms.app_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.approx_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.perm_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.spectral_entropy`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">        - [`sklearn.neighbors.KDTree`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html)</span>
<span class="sd">        - [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html)</span>
<span class="sd">        - [`scipy.spatial.distance`](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_sample_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.permutation_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">permutation_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.permutation_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">permutation_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Permutation entropy is a measure of the complexity or randomness of a time series. It is based on the idea of permuting the order of the values in the time series and calculating the entropy of the resulting permutation patterns.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The permutation entropy is a complexity measure for time-series first introduced by Bandt and Pompe in 2002.</p>
<p>The formula for permutation entropy is as follows:</p>
<div class="arithmatex">\[
PE(n) = - \sum_{n=0}^{n!} \times p(i) \times \text{log2}(p(i))
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(n\)</span> is the length of the sliding window,</li>
<li><span class="arithmatex">\(p(i)\)</span> is the probability of the i-th ordinal pattern, and</li>
<li>the sum is taken over all possible ordinal patterns.</li>
<li>The logarithm function is base 2.</li>
</ul>
<div class="highlight"><pre><span></span><code>PE(n) = - âˆ‘ p(i) * log2(p(i))
</code></pre></div>
<p>The calculation of permutation entropy involves the following steps:</p>
<ol>
<li>Choose the length of the sliding window (<span class="arithmatex">\(n\)</span>).</li>
<li>Construct the set of all possible ordinal patterns of length <span class="arithmatex">\(n\)</span>.</li>
<li>Compute the frequency of occurrence of each ordinal pattern in the time series.</li>
<li>Compute the probability of occurrence of each ordinal pattern by dividing its frequency by the total number of ordinal patterns.</li>
<li>Compute the value of permutation entropy using the formula above.</li>
</ol>
<p>The value of permutation entropy ranges from <span class="arithmatex">\(0\)</span> to <span class="arithmatex">\(log2(n!)\)</span>, with lower values indicating higher regularity or predictability in the time series. A time series with high permutation entropy is more unpredictable or irregular, whereas a time series with low permutation entropy is more regular or predictable.</p>
<p>Permutation entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks. It is particularly useful for detecting nonlinear dynamics and nonstationarity in the data.</p>
<p>This is the information contained in comparing <span class="arithmatex">\(n\)</span> consecutive values of the time series. It is clear that <span class="arithmatex">\(0 â‰¤ H (n) â‰¤ \text{log2}(n!)\)</span> where the lower bound is attained for an increasing or decreasing sequence of values, and the upper bound for a completely random system where all <span class="arithmatex">\(n!\)</span> possible permutations appear with the same probability.</p>
<p>To calculate the Permutation entropy requires the specification of a set of parameters that determine the characteristics of the time series. One of these parameters is the <em>embedding dimension</em>, which determines the number of values that are used to construct each permutation pattern.</p>
<p>The embedding dimension is important in the calculation of permutation entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting permutation entropy value may not accurately reflect the underlying complexity of the signal. On the other hand, if the embedding dimension is too large, we may overfit the data and produce a permutation entropy value that is overly sensitive to noise or other random fluctuations.</p>
<p>Choosing an appropriate embedding dimension is therefore crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</p>
<p>The embedded matrix <span class="arithmatex">\(Y\)</span> is created by:</p>
<div class="arithmatex">\[
\begin{align}
    y(i) &amp;= [x_i,x_{i+\text{delay}}, ...,x_{i+(\text{order}-1) * \text{delay}}] \\
    Y &amp;= [y(1),y(2),...,y(N-(\text{order}-1))*\text{delay})]^T
\end{align}
\]</div>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape (n_times).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Order of permutation entropy.<br>
Defaults to <code>3</code>.</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="list">list</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Time delay (lag). If multiple values are passed (e.g. [1, 2, 3]), AntroPy will calculate the average permutation entropy across all these delays.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, divide by <span class="arithmatex">\(log2(order!)\)</span> to normalize the entropy between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the permutation entropy in bit.<br>
Defaults to <code>False</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The entropy of the data set.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<ul>
<li>All credit goes to the <a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>entropy.perm_entropy</code></a> library.</li>
</ul>
</div>
<div class="admonition example">
<p class="admonition-title">Examples</p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Prepare data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.processes</span><span class="w"> </span><span class="kn">import</span> <span class="n">noise</span> <span class="k">as</span> <span class="n">sn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_airline</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_noise</span> <span class="o">=</span> <span class="n">sn</span><span class="o">.</span><span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_random</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_sine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3000</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_airline</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.3601</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Simple series</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9183</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Normalised series</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9183</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Gaussian noise</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9999</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Normalized noise</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9999</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Multiple delays</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">delay</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9999</span>
</code></pre></div></td></tr></table></div>
<p><div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Random data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_random</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9991</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Sine wave</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_sine</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.4463</span>
</code></pre></div></td></tr></table></div></p>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Straight line</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">permutation_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_line</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.0000</span>
</code></pre></div></td></tr></table></div>
</div>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="http://materias.df.uba.ar/dnla2019c1/files/2019/03/permutation_entropy.pdf">Bandt, Christoph, and Bernd Pompe. "Permutation entropy: a natural complexity measure for time series." Physical review letters 88.17 (2002): 174102</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.app_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.approx_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.perm_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>ts_stat_tests.algorithms.spectral_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">permutation_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Permutation entropy is a measure of the complexity or randomness of a time series. It is based on the idea of permuting the order of the values in the time series and calculating the entropy of the resulting permutation patterns.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The permutation entropy is a complexity measure for time-series first introduced by Bandt and Pompe in 2002.</span>

<span class="sd">        The formula for permutation entropy is as follows:</span>

<span class="sd">        $$</span>
<span class="sd">        PE(n) = - \\sum_{n=0}^{n!} \\times p(i) \\times \\text{log2}(p(i))</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $n$ is the length of the sliding window,</span>
<span class="sd">        - $p(i)$ is the probability of the i-th ordinal pattern, and</span>
<span class="sd">        - the sum is taken over all possible ordinal patterns.</span>
<span class="sd">        - The logarithm function is base 2.</span>

<span class="sd">        ```</span>
<span class="sd">        PE(n) = - âˆ‘ p(i) * log2(p(i))</span>
<span class="sd">        ```</span>

<span class="sd">        The calculation of permutation entropy involves the following steps:</span>

<span class="sd">        1. Choose the length of the sliding window ($n$).</span>
<span class="sd">        1. Construct the set of all possible ordinal patterns of length $n$.</span>
<span class="sd">        1. Compute the frequency of occurrence of each ordinal pattern in the time series.</span>
<span class="sd">        1. Compute the probability of occurrence of each ordinal pattern by dividing its frequency by the total number of ordinal patterns.</span>
<span class="sd">        1. Compute the value of permutation entropy using the formula above.</span>

<span class="sd">        The value of permutation entropy ranges from $0$ to $log2(n!)$, with lower values indicating higher regularity or predictability in the time series. A time series with high permutation entropy is more unpredictable or irregular, whereas a time series with low permutation entropy is more regular or predictable.</span>

<span class="sd">        Permutation entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as ARIMA or neural networks. It is particularly useful for detecting nonlinear dynamics and nonstationarity in the data.</span>

<span class="sd">        This is the information contained in comparing $n$ consecutive values of the time series. It is clear that $0 â‰¤ H (n) â‰¤ \\text{log2}(n!)$ where the lower bound is attained for an increasing or decreasing sequence of values, and the upper bound for a completely random system where all $n!$ possible permutations appear with the same probability.</span>

<span class="sd">        To calculate the Permutation entropy requires the specification of a set of parameters that determine the characteristics of the time series. One of these parameters is the _embedding dimension_, which determines the number of values that are used to construct each permutation pattern.</span>

<span class="sd">        The embedding dimension is important in the calculation of permutation entropy because it affects the sensitivity of the measure to different patterns in the data. If the embedding dimension is too small, we may miss important patterns or variations in the time series, and the resulting permutation entropy value may not accurately reflect the underlying complexity of the signal. On the other hand, if the embedding dimension is too large, we may overfit the data and produce a permutation entropy value that is overly sensitive to noise or other random fluctuations.</span>

<span class="sd">        Choosing an appropriate embedding dimension is therefore crucial in ensuring that the permutation entropy calculation is robust and reliable, and captures the essential features of the time series in a meaningful way. This allows us to make more accurate and informative inferences about the behavior of the system that generated the data, and can be useful in a wide range of applications, from signal processing to data analysis and beyond.</span>

<span class="sd">        The embedded matrix $Y$ is created by:</span>

<span class="sd">        $$</span>
<span class="sd">        \\begin{align}</span>
<span class="sd">            y(i) &amp;= [x_i,x_{i+\\text{delay}}, ...,x_{i+(\\text{order}-1) * \\text{delay}}] \\\\</span>
<span class="sd">            Y &amp;= [y(1),y(2),...,y(N-(\\text{order}-1))*\\text{delay})]^T</span>
<span class="sd">        \\end{align}</span>
<span class="sd">        $$</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape (n_times).</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Order of permutation entropy.&lt;br&gt;</span>
<span class="sd">            Defaults to `3`.</span>
<span class="sd">        delay (Union[int, list, np.ndarray], optional):</span>
<span class="sd">            Time delay (lag). If multiple values are passed (e.g. [1, 2, 3]), AntroPy will calculate the average permutation entropy across all these delays.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If True, divide by $log2(order!)$ to normalize the entropy between $0$ and $1$. Otherwise, return the permutation entropy in bit.&lt;br&gt;</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The entropy of the data set.</span>

<span class="sd">    !!! success &quot;Credit&quot;</span>
<span class="sd">        - All credit goes to the [`entropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html) library.</span>

<span class="sd">    !!! example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Prepare data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.processes import noise as sn</span>
<span class="sd">        &gt;&gt;&gt; x = [4, 7, 9, 10, 6, 11, 3]</span>
<span class="sd">        &gt;&gt;&gt; data_airline = load_airline()</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng(seed=42)</span>
<span class="sd">        &gt;&gt;&gt; data_noise = sn.FractionalGaussianNoise(hurst=0.5, rng=rng).sample(10000)</span>
<span class="sd">        &gt;&gt;&gt; data_random = rng.random(1000)</span>
<span class="sd">        &gt;&gt;&gt; data_sine = np.sin(2 * np.pi * 1 * np.arange(3000) / 100)</span>
<span class="sd">        &gt;&gt;&gt; data_line = np.arange(1000)</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_airline):.4f}&quot;)</span>
<span class="sd">        2.3601</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Simple series&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=x, order=2):.4f}&quot;)</span>
<span class="sd">        0.9183</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Normalised series&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=x, order=2, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9183</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Gaussian noise&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_noise, order=2):.4f}&quot;)</span>
<span class="sd">        0.9999</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Normalized noise&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_noise, order=2, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9999</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Multiple delays&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_noise, delay=[1, 2, 3], normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9999</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Random data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_random, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9991</span>
<span class="sd">        ```</span>
<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Sine wave&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_sine, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.4463</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Straight line&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{permutation_entropy(x=data_line, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.0000</span>
<span class="sd">        ```</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - [Bandt, Christoph, and Bernd Pompe. &quot;Permutation entropy: a natural complexity measure for time series.&quot; Physical review letters 88.17 (2002): 174102](http://materias.df.uba.ar/dnla2019c1/files/2019/03/permutation_entropy.pdf)</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">        - [`ts_stat_tests.algorithms.app_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.approx_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.perm_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.spectral_entropy`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span>
        <span class="nb">float</span><span class="p">,</span>
        <span class="n">a_perm_entropy</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
            <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
            <span class="n">delay</span><span class="o">=</span><span class="n">cast</span><span class="p">(</span><span class="n">Any</span><span class="p">,</span> <span class="n">delay</span><span class="p">),</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.spectral_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">spectral_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.spectral_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">spectral_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;fft&quot;</span><span class="p">,</span>
    <span class="n">nperseg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Spectral entropy is a measure of the amount of complexity or unpredictability in a signal's frequency domain representation. It is used to quantify the degree of randomness or regularity in the power spectrum of a signal, which is a graphical representation of the distribution of power across different frequencies.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Spectral Entropy is also a measure of the distribution of power or energy in the frequency domain of a time series. It is based on the Shannon entropy, which is a measure of the uncertainty or information content of a probability distribution</p>
<p>Spectral Entropy is defined to be the Shannon entropy of the power spectral density (<span class="arithmatex">\(PSD\)</span>) of the data:</p>
<div class="arithmatex">\[
H(x,f_s) =  -\sum_{i=0}^{f_s/2} \times P(i) \times \text{log2}(P(i))
\]</div>
<p>where:</p>
<ul>
<li><span class="arithmatex">\(P\)</span> is the normalised <span class="arithmatex">\(PSD\)</span>, which is the proportion of power or energy at the <span class="arithmatex">\(i\)</span>-th frequency band, and</li>
<li><span class="arithmatex">\(f_s\)</span> is the sampling frequency.</li>
<li>The logarithm function is base 2.</li>
</ul>
<div class="highlight"><pre><span></span><code>SE = - âˆ‘ p(i) * log2(p(i))
</code></pre></div>
<p>The calculation of spectral entropy involves the following steps:</p>
<ol>
<li>Compute the power or energy spectral density of the time series using a spectral analysis technique, such as the fast Fourier transform (FFT).</li>
<li>Divide the frequency range of interest into non-overlapping frequency bands.</li>
<li>Compute the proportion of power or energy in each frequency band by integrating the spectral density over the band.</li>
<li>Compute the value of spectral entropy using the formula above.</li>
</ol>
<p>The value of spectral entropy ranges from <span class="arithmatex">\(0\)</span> to <span class="arithmatex">\(\text{log2}(N)\)</span>, where <span class="arithmatex">\(N\)</span> is the number of frequency bands. Lower values indicate a more concentrated or regular distribution of power or energy in the frequency domain, while higher values indicate a more spread-out or irregular distribution.</p>
<p>Spectral entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as spectral analysis or machine learning algorithms. It is particularly useful for detecting periodicity and cyclical patterns in the data, as well as changes in the frequency distribution over time.</p>
<p>To calculate spectral entropy, we first need to compute the power spectrum of the signal using a Fourier transform or other spectral analysis method. The power spectrum represents the energy of the signal at different frequencies, and can be visualized as a graph of power versus frequency.</p>
<p>Once we have the power spectrum, we can calculate the spectral entropy by applying Shannon entropy to the distribution of power across different frequencies. Shannon entropy is a measure of the amount of information or uncertainty in a probability distribution, and is given by the negative sum of the product of the probability of each frequency bin and the logarithm of that probability.</p>
<p>Spectral entropy is useful in a variety of applications, such as signal processing, acoustics, and neuroscience. It can be used to characterize the complexity or regularity of a signal's frequency content, and can provide insights into the underlying processes or mechanisms that generated the signal. For example, high spectral entropy may indicate the presence of multiple sources or processes with different frequencies, while low spectral entropy may suggest the presence of a single dominant frequency or periodicity.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p><code>1-D</code> or <code>N-D</code> data array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sf</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Sampling frequency, in Hz.<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="ts_stat_tests.algorithms.regularity.VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS">VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Spectral estimation method:<br>
- <code>'fft'</code>: Fourier Transformation (<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html#scipy.signal.periodogram"><code>scipy.signal.periodogram()</code></a>)<br>
- <code>'welch'</code>: Welch periodogram (<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch"><code>scipy.signal.welch()</code></a>)<br>
Defaults to <code>"fft"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;fft&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nperseg</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Length of each FFT segment for Welch method. If <code>None</code>, uses <code>scipy</code>'s default of 256 samples.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>True</code>, divide by <span class="arithmatex">\(log2(psd.size)\)</span> to normalize the spectral entropy to be between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>. Otherwise, return the spectral entropy in bit.<br>
Defaults to <code>False</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>axis</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The axis along which the entropy is calculated. Default is the last axis.<br>
Defaults to <code>-1</code>.</p>
              </div>
            </td>
            <td>
                  <code>-1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Spectral Entropy score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="example" open="open">
<summary>Examples</summary>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Prepare data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sktime.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_airline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">stochastic.processes</span><span class="w"> </span><span class="kn">import</span> <span class="n">noise</span> <span class="k">as</span> <span class="n">sn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sf</span><span class="p">,</span> <span class="n">dur</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">N</span> <span class="o">=</span> <span class="n">sf</span> <span class="o">*</span> <span class="n">dur</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_sine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">data_time</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_noise</span> <span class="o">=</span> <span class="n">sn</span><span class="o">.</span><span class="n">FractionalGaussianNoise</span><span class="p">(</span><span class="n">hurst</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_2d</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3000</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data_airline</span> <span class="o">=</span> <span class="n">load_airline</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Basic usage</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_airline</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">2.6538</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Sine wave</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_sine</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;fft&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">6.2329</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Welch method</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_sine</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;welch&#39;</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">1.2924</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Normalised calculation</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_sine</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;welch&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9956</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">2D data</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_2d</span><span class="p">,</span> <span class="n">sf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="go">[0.9426, 0.9382, 0.9410, 0.9376]</span>
</code></pre></div></td></tr></table></div>
<div class="py python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Gaussian noise</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">spectral_entropy</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data_noise</span><span class="p">,</span><span class="w"> </span><span class="n">sf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">0.9505</span>
</code></pre></div></td></tr></table></div>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li>Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</li>
<li><a href="https://en.wikipedia.org/wiki/Spectral_density">https://en.wikipedia.org/wiki/Spectral_density</a></li>
<li><a href="https://en.wikipedia.org/wiki/Welch%27s_method">https://en.wikipedia.org/wiki/Welch%27s_method</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html"><code>antropy.app_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html"><code>antropy.sample_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html"><code>antropy.perm_entropy</code></a></li>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html"><code>antropy.spectral_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.app_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.approx_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.perm_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>ts_stat_tests.algorithms.spectral_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">spectral_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">sf</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS</span> <span class="o">=</span> <span class="s2">&quot;fft&quot;</span><span class="p">,</span>
    <span class="n">nperseg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>

<span class="sd">        Spectral entropy is a measure of the amount of complexity or unpredictability in a signal&#39;s frequency domain representation. It is used to quantify the degree of randomness or regularity in the power spectrum of a signal, which is a graphical representation of the distribution of power across different frequencies.</span>


<span class="sd">    ???+ abstract &quot;Details&quot;</span>

<span class="sd">        Spectral Entropy is also a measure of the distribution of power or energy in the frequency domain of a time series. It is based on the Shannon entropy, which is a measure of the uncertainty or information content of a probability distribution</span>

<span class="sd">        Spectral Entropy is defined to be the Shannon entropy of the power spectral density ($PSD$) of the data:</span>

<span class="sd">        $$</span>
<span class="sd">        H(x,f_s) =  -\\sum_{i=0}^{f_s/2} \\times P(i) \\times \\text{log2}(P(i))</span>
<span class="sd">        $$</span>

<span class="sd">        where:</span>

<span class="sd">        - $P$ is the normalised $PSD$, which is the proportion of power or energy at the $i$-th frequency band, and</span>
<span class="sd">        - $f_s$ is the sampling frequency.</span>
<span class="sd">        - The logarithm function is base 2.</span>

<span class="sd">        ```</span>
<span class="sd">        SE = - âˆ‘ p(i) * log2(p(i))</span>
<span class="sd">        ```</span>

<span class="sd">        The calculation of spectral entropy involves the following steps:</span>

<span class="sd">        1. Compute the power or energy spectral density of the time series using a spectral analysis technique, such as the fast Fourier transform (FFT).</span>
<span class="sd">        1. Divide the frequency range of interest into non-overlapping frequency bands.</span>
<span class="sd">        1. Compute the proportion of power or energy in each frequency band by integrating the spectral density over the band.</span>
<span class="sd">        1. Compute the value of spectral entropy using the formula above.</span>

<span class="sd">        The value of spectral entropy ranges from $0$ to $\\text{log2}(N)$, where $N$ is the number of frequency bands. Lower values indicate a more concentrated or regular distribution of power or energy in the frequency domain, while higher values indicate a more spread-out or irregular distribution.</span>

<span class="sd">        Spectral entropy is often used in time series forecasting to assess the complexity of the data and to determine whether a time series is suitable for modeling with a particular forecasting method, such as spectral analysis or machine learning algorithms. It is particularly useful for detecting periodicity and cyclical patterns in the data, as well as changes in the frequency distribution over time.</span>

<span class="sd">        To calculate spectral entropy, we first need to compute the power spectrum of the signal using a Fourier transform or other spectral analysis method. The power spectrum represents the energy of the signal at different frequencies, and can be visualized as a graph of power versus frequency.</span>

<span class="sd">        Once we have the power spectrum, we can calculate the spectral entropy by applying Shannon entropy to the distribution of power across different frequencies. Shannon entropy is a measure of the amount of information or uncertainty in a probability distribution, and is given by the negative sum of the product of the probability of each frequency bin and the logarithm of that probability.</span>

<span class="sd">        Spectral entropy is useful in a variety of applications, such as signal processing, acoustics, and neuroscience. It can be used to characterize the complexity or regularity of a signal&#39;s frequency content, and can provide insights into the underlying processes or mechanisms that generated the signal. For example, high spectral entropy may indicate the presence of multiple sources or processes with different frequencies, while low spectral entropy may suggest the presence of a single dominant frequency or periodicity.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            `1-D` or `N-D` data array.</span>
<span class="sd">        sf (float, optional):</span>
<span class="sd">            Sampling frequency, in Hz.&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        method (VALID_SPECTRAL_ENTROPY_METHOD_OPTIONS):</span>
<span class="sd">            Spectral estimation method:&lt;br&gt;</span>
<span class="sd">            - `&#39;fft&#39;`: Fourier Transformation ([`scipy.signal.periodogram()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.periodogram.html#scipy.signal.periodogram))&lt;br&gt;</span>
<span class="sd">            - `&#39;welch&#39;`: Welch periodogram ([`scipy.signal.welch()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch))&lt;br&gt;</span>
<span class="sd">            Defaults to `&quot;fft&quot;`.</span>
<span class="sd">        nperseg (Optional[int]):</span>
<span class="sd">            Length of each FFT segment for Welch method. If `None`, uses `scipy`&#39;s default of 256 samples.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If `True`, divide by $log2(psd.size)$ to normalize the spectral entropy to be between $0$ and $1$. Otherwise, return the spectral entropy in bit.&lt;br&gt;</span>
<span class="sd">            Defaults to `False`.</span>
<span class="sd">        axis (int, optional):</span>
<span class="sd">            The axis along which the entropy is calculated. Default is the last axis.&lt;br&gt;</span>
<span class="sd">            Defaults to `-1`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            Spectral Entropy score.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ???+ Example &quot;Examples&quot;</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Prepare data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from sktime.datasets import load_airline</span>
<span class="sd">        &gt;&gt;&gt; from stochastic.processes import noise as sn</span>
<span class="sd">        &gt;&gt;&gt; sf, dur = 100, 4</span>
<span class="sd">        &gt;&gt;&gt; N = sf * dur</span>
<span class="sd">        &gt;&gt;&gt; data_time = np.arange(N)</span>
<span class="sd">        &gt;&gt;&gt; data_sine = np.sin(2 * np.pi * 1 * data_time)</span>
<span class="sd">        &gt;&gt;&gt; rng = np.random.default_rng(seed=42)</span>
<span class="sd">        &gt;&gt;&gt; data_noise = sn.FractionalGaussianNoise(hurst=0.5, rng=rng).sample(10000)</span>
<span class="sd">        &gt;&gt;&gt; data_2d = rng.normal(size=(4, 3000))</span>
<span class="sd">        &gt;&gt;&gt; data_airline = load_airline()</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Basic usage&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=data_airline, sf=12):.4f}&quot;)</span>
<span class="sd">        2.6538</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot; title=&quot;Sine wave&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=data_sine, sf=100, method=&#39;fft&#39;):.4f}&quot;)</span>
<span class="sd">        6.2329</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Welch method&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=data_sine, sf=100, method=&#39;welch&#39;):.4f}&quot;)</span>
<span class="sd">        1.2924</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Normalised calculation&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=data_sine, sf=100, method=&#39;welch&#39;, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9956</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;2D data&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(spectral_entropy(x=data_2d, sf=100, normalize=True).tolist())</span>
<span class="sd">        [0.9426, 0.9382, 0.9410, 0.9376]</span>
<span class="sd">        ```</span>

<span class="sd">        ```pycon {.py .python linenums=&quot;1&quot;  title=&quot;Gaussian noise&quot;}</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;{spectral_entropy(x=data_noise, sf=100, normalize=True):.4f}&quot;)</span>
<span class="sd">        0.9505</span>
<span class="sd">        ```</span>

<span class="sd">    ??? Question &quot;References&quot;</span>
<span class="sd">        - Inouye, T. et al. (1991). Quantification of EEG irregularity by use of the entropy of the power spectrum. Electroencephalography and clinical neurophysiology, 79(3), 204-210.</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Spectral_density</span>
<span class="sd">        - https://en.wikipedia.org/wiki/Welch%27s_method</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.app_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.app_entropy.html)</span>
<span class="sd">        - [`antropy.sample_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.sample_entropy.html)</span>
<span class="sd">        - [`antropy.perm_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.perm_entropy.html)</span>
<span class="sd">        - [`antropy.spectral_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.spectral_entropy.html)</span>
<span class="sd">        - [`ts_stat_tests.algorithms.app_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.approx_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.perm_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.spectral_entropy`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_spectral_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">sf</span><span class="o">=</span><span class="n">sf</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
        <span class="n">nperseg</span><span class="o">=</span><span class="n">nperseg</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="ts_stat_tests.algorithms.regularity.svd_entropy" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">svd_entropy</span>


<a href="#ts_stat_tests.algorithms.regularity.svd_entropy" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">svd_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>SVD entropy is a measure of the complexity or randomness of a time series based on Singular Value Decomposition (SVD).</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>SVD entropy is calculated by first embedding the time series into a matrix, then performing SVD on that matrix to obtain the singular values. The entropy is then calculated from the normalized singular values.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>x</code>
            </td>
            <td>
                  <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>One-dimensional time series of shape (n_times).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Order of the SVD entropy (embedding dimension).<br>
Defaults to <code>3</code>.</p>
              </div>
            </td>
            <td>
                  <code>3</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Time delay (lag).<br>
Defaults to <code>1</code>.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, divide by <span class="arithmatex">\(log2(order!)\)</span> to normalize the entropy between <span class="arithmatex">\(0\)</span> and <span class="arithmatex">\(1\)</span>.<br>
Defaults to <code>False</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SVD entropy of the data set.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="admonition success">
<p class="admonition-title">Credit</p>
<p>All credit goes to the <a href="https://raphaelvallat.com/antropy/"><code>AntroPy</code></a> library.</p>
</div>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a href="https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html"><code>antropy.svd_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            approx_entropy" href="#ts_stat_tests.algorithms.regularity.approx_entropy"><code>ts_stat_tests.algorithms.approx_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            sample_entropy" href="#ts_stat_tests.algorithms.regularity.sample_entropy"><code>ts_stat_tests.algorithms.sample_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            permutation_entropy" href="#ts_stat_tests.algorithms.regularity.permutation_entropy"><code>ts_stat_tests.algorithms.perm_entropy</code></a></li>
<li><a class="autorefs autorefs-internal" title="            spectral_entropy" href="#ts_stat_tests.algorithms.regularity.spectral_entropy"><code>ts_stat_tests.algorithms.spectral_entropy</code></a></li>
</ul>
</details>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>src/ts_stat_tests/algorithms/regularity.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">svd_entropy</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">order</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">delay</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        SVD entropy is a measure of the complexity or randomness of a time series based on Singular Value Decomposition (SVD).</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        SVD entropy is calculated by first embedding the time series into a matrix, then performing SVD on that matrix to obtain the singular values. The entropy is then calculated from the normalized singular values.</span>

<span class="sd">    Params:</span>
<span class="sd">        x (ArrayLike):</span>
<span class="sd">            One-dimensional time series of shape (n_times).</span>
<span class="sd">        order (int, optional):</span>
<span class="sd">            Order of the SVD entropy (embedding dimension).&lt;br&gt;</span>
<span class="sd">            Defaults to `3`.</span>
<span class="sd">        delay (int, optional):</span>
<span class="sd">            Time delay (lag).&lt;br&gt;</span>
<span class="sd">            Defaults to `1`.</span>
<span class="sd">        normalize (bool, optional):</span>
<span class="sd">            If True, divide by $log2(order!)$ to normalize the entropy between $0$ and $1$.&lt;br&gt;</span>
<span class="sd">            Defaults to `False`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float):</span>
<span class="sd">            The SVD entropy of the data set.</span>

<span class="sd">    !!! Success &quot;Credit&quot;</span>
<span class="sd">        All credit goes to the [`AntroPy`](https://raphaelvallat.com/antropy/) library.</span>

<span class="sd">    ??? Tip &quot;See Also&quot;</span>
<span class="sd">        - [`antropy.svd_entropy`](https://raphaelvallat.com/antropy/build/html/generated/antropy.svd_entropy.html)</span>
<span class="sd">        - [`ts_stat_tests.algorithms.approx_entropy`][ts_stat_tests.algorithms.regularity.approx_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.sample_entropy`][ts_stat_tests.algorithms.regularity.sample_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.perm_entropy`][ts_stat_tests.algorithms.regularity.permutation_entropy]</span>
<span class="sd">        - [`ts_stat_tests.algorithms.spectral_entropy`][ts_stat_tests.algorithms.regularity.spectral_entropy]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a_svd_entropy</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
        <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.instant", "search.highlight", "search.suggest", "toc.follow", "content.action.edit", "content.action.view"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>